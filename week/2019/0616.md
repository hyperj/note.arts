# ARTS - 2019 Week 6-3

20190616~20190622

## Algorithm



## Review

### [A Deep Dive into Query Execution Engine of Spark SQL](https://databricks.com/session/a-deep-dive-into-query-execution-engine-of-spark-sql)

Spark SQL enables Spark to perform efficient and fault-tolerant relational query processing with analytics database technologies. The relational queries are compiled to the executable physical plans consisting of transformations and actions on RDDs with the generated Java code. The code is compiled to Java bytecode, executed at runtime by JVM and optimized by JIT to native machine code at runtime. This talk will take a deep dive into Spark SQL execution engine. The talk includes pipelined execution, whole-stage code generation, UDF execution, memory management, vectorized readers, lineage based RDD transformation and action.

**[【PDF】A Deep Dive into Query Execution Engine of Spark SQL](../../asset/pdf/a-deep-dive-into-query-execution-engine-of-spark-sql.pdf)**

#### Review

**基础介绍**

- Spark

    - Spark Core、Data Source Connectors
    - Catalyst Optimization & Tungsten Execution
    - SparkSession / DataFrame / Dataset APIs
    - SQL、Spark ML、Spark Streaming、Spark Graph、3rd-party Libraries

- SQL

Parser -> Analysis -> Logical Optimization -> Physical Planning -> Code Generation -> Execution


## Tip

### JVM 常用参数

-Dproperty=value

设置系统属性，通过System.getProperty获取

-verbose:gc

展示每个GC事件的信息

-Xms6g 
-Xmx6g 
-XX:MetaspaceSize=96m 
-XX:+UseG1GC 
-XX:MaxGCPauseMillis=20
-XX:InitiatingHeapOccupancyPercent=35 
-XX:G1HeapRegionSize=16M
-XX:MinMetaspaceFreeRatio=50 
-XX:MaxMetaspaceFreeRatio=80
-XX:+PrintGCDetails

## Share

### [Spark 作业执行流程（Cluster Mode On YARN）](../../share/2019/06/spark-job-execution-process.md)

## Reference
