{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ARTS Note \u00b6 Mark. 20190613 - HyperJ 2019 \u00b6 Month 01 02 03 04 05 October -- -- -- -- -- September Week 9-1 Week 9-2 Week 9-3 Week 9-4 Week 9-5 August Week 8-1 Week 8-2 Week 8-3 Week 8-4 -- July Week 7-1 Week 7-2 Week 7-3 Week 7-4 -- June -- Week 6-2 Week 6-3 Week 6-4 Week 6-5 Share \u00b6 Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Spark Shuffle Service Spark \u6e90\u7801\u8c03\u8bd5 \u6f2b\u8c08\u6570\u636e\u8d28\u91cf Spark SQL \u89c4\u5219 Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Flink \u5f00\u53d1\u5b9e\u8df5 \u5143\u6570\u636e\u96c6\u6210 \u5143\u6570\u636e\u4ed3\u5e93 \u65e5\u5fd7\u91c7\u96c6 \u6570\u636e\u96c6\u6210 Arts \u00b6 \u53d1\u8d77ARTS\u7684\u539f\u56e0 \u00b6 \u6211\u4eec\u6574\u4e2a\u4e16\u754c\u8fdb\u5165\u4e86\u524d\u6240\u672a\u6709\u7684\u4fe1\u606f\u7206\u70b8\u65f6\u4ee3\uff0c\u4eba\u4eec\u62c5\u5fe7\u7684\u4e0d\u518d\u662f\u65e0\u77e5\u8bc6\u53ef\u5b66\uff0c\u800c\u662f\u6709\u5b66\u4e0d\u5b8c\u7684\u77e5\u8bc6\u3002\u800c\u4e14\u65f6\u4ee3\u7684\u8282\u594f\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\uff0c\u4f60\u53ef\u80fd\u518d\u4e5f\u4e0d\u50cf 20 \u5e74\u524d\uff0c\u53ef\u4ee5\u6c89\u7740\u4f18\u96c5\u5e73\u548c\u5730\u6ce1\u4e0a\u4e00\u676f\u8336\uff0c\u5750\u5728\u4e00\u4e2a\u8fdc\u79bb\u55a7\u56a3\u7684\u73af\u5883\u4e0b\uff0c\u8ba4\u8ba4\u771f\u771f\u5730\u770b\u672c\u4e66\u3002 \u8fd9\u4e2a\u65f6\u4ee3\uff0c\u4f60\u518d\u4e5f\u4e0d\u4f1a\u6709\u5927\u5757\u5927\u5757\u7684\u65f6\u95f4\uff0c\u4f60\u7684\u65f6\u95f4\u90fd\u88ab\u6253\u6210\u788e\u7247\u4e86\uff0c\u4e0d\u77e5\u4e0d\u89c9\u4f60\u4e5f\u6210\u4e3a\u4e86\u5feb\u9910\u6587\u5316\u7684\u62e5\u8db8\u2026\u2026\u5728\u8fd9\u6837\u4e00\u4e2a\u65f6\u4ee3\u4e0b\uff0c\u5feb\u901f\u3001\u7b80\u5355\u3001\u8f7b\u677e\u7684\u65b9\u5f0f\u7ed9\u4eba\u5e26\u6765\u7684\u5feb\u611f\u66f4\u5f3a\u70c8\uff0c\u800c\u9ad8\u5c42\u6b21\u7684\u601d\u8003\u3001\u601d\u8fa8\u548c\u903b\u8f91\u5219\u88ab\u8fd9\u4e9b\u9891\u5ea6\u9ad8\u7684\u5feb\u9910\u4fe1\u606f\u611f\u6240\u5f31\u5316\u3002\u5546\u5bb6\u4eec\u770b\u5230\u5728\u8fd9\u6837\u7684\u65f6\u4ee3\u91cc\u600e\u4e48\u6cbb\u6108\u8fd9\u4e9b\u4eba\u5728\u5b66\u4e60\u4e0a\u7684\u7126\u8651\u7684\u5546\u673a\uff0c\u4ed6\u4eec\u5728\u60f3\u65b9\u8bbe\u6cd5\u5730\u7528\u4e00\u4e9b\u624b\u6bb5\u63a8\u51fa\u5404\u79cd\u4ee3\u8bfb\u3001\u9886\u8bfb\u548c\u542c\u8bfb\u7c7b\u4ea7\u54c1\uff0c\u8ba9\u4eba\u4eec\u53ef\u4ee5\u5728\u77ed\u65f6\u95f4\u5185\u4f53\u4f1a\u5230\u8f7b\u677e\u83b7\u53d6\u77e5\u8bc6\u7684\u5feb\u611f\uff0c\u5e76\u4ea7\u751f\u52e4\u594b\u597d\u5b66\u548c\u6210\u957f\u7684\u5e7b\u89c9\uff08\u8001\u5b9e\u8bf4\uff0c\u50cf\u6211\u8fd9\u79cd\u4ed8\u8d39\u4e13\u680f\u6216\u662f\u5f97\u5230\u7b49\u77e5\u8bc6\u4ed8\u8d39\u4ea7\u54c1\u57fa\u672c\u4e0a\u5c31\u662f\u7c7b\u4f3c\u7684\u4ea7\u7269\uff09\u3002 \u8fd9\u4e9b\u6240\u8c13\u7684\u201c\u5feb\u9910\u6587\u5316\u201d\u53ef\u4ee5\u8ba9\u4f60\u6709\u77ed\u6682\u7684\u6ee1\u8db3\u611f\uff0c\u4f46\u662f\u65e0\u6cd5\u8ba9\u4f60\u6709\u66f4\u6df1\u5c42\u6b21\u7684\u601d\u8003\u548c\u628a\u77e5\u8bc6\u8f6c\u6362\u6210\u81ea\u5df1\u7684\u6280\u80fd\u7684\u6709\u6548\u8def\u5f84\uff0c\u56e0\u4e3a\u90a3\u4e9b\u90fd\u662f\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u7cbe\u529b\u7684\u4ed8\u51fa\uff0c\u4e0d\u7b26\u5408\u73b0\u4ee3\u4eba\u7684\u751f\u6d3b\u8282\u594f\u3002\u4eba\u4eec\u5f00\u59cb\u5728\u670b\u53cb\u5708\u3001\u516c\u4f17\u53f7\u3001\u5f97\u5230\u7b49\u8fd9\u6837\u7684\u5730\u65b9\u8fdb\u884c\u5b66\u4e60\uff0c\u5bfc\u81f4\u4ed6\u4eec\u8d8a\u5b66\u8d8a\u7126\u8651\uff0c\u8d8a\u5b66\u8d8a\u6d6e\u71e5\uff0c\u8d8a\u5b66\u8d8a\u4e0d\u4f1a\u601d\u8003\u3002\u4e8e\u662f\uff0c\u4ed6\u4eec\u6210\u4e86\u201c\u4ec0\u4e48\u90fd\u61c2\uff0c\u4f46\u4f9d\u7136\u8fc7\u4e0d\u597d\u8fd9\u4e00\u751f\u201d\u7684\u72b6\u6001\u3002 \u4f60\u6709\u6ca1\u6709\u53d1\u73b0\uff0c\u5728\u77e5\u8bc6\u7684\u9886\u57df\u4e5f\u6709\u9636\u5c42\u4e4b\u5206\uff0c\u90a3\u4e9b\u957f\u671f\u5728\u5e95\u5c42\u77e5\u8bc6\u9636\u5c42\u7684\u4eba\uff0c\u9700\u8981\u7b49\u7740\u9ad8\u5c42\u7684\u4eba\u6765\u5582\u517b\uff0c\u4ed6\u4eec\u957f\u671f\u9677\u4e8e\u5404\u79cd\u8c23\u8a00\u548c\u4e0d\u51c6\u786e\u7684\u4fe1\u606f\u73af\u5883\u4e2d\uff0c\u4e8e\u662f\u5c31\u5bfc\u81f4\u9519\u8bef\u6216\u5e7c\u7a1a\u7684\u8ba4\u77e5\uff0c\u5e76\u4e60\u60ef\u4e8e\u90a3\u4e9b\u4e0d\u8d39\u52b2\u513f\u7684\u8f7b\u5ea6\u5b66\u4e60\u65b9\u5f0f\uff0c\u4ece\u800c\u4e00\u70b9\u70b9\u5730\u4e27\u5931\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u72ec\u7acb\u601d\u8003\u80fd\u529b\uff0c\u4ece\u800c\u518d\u4e5f\u6ca1\u6709\u80fd\u529b\u6253\u7834\u77e5\u8bc6\u9636\u5c42\u7684\u9650\u5236\uff0c\u88ab\u56f0\u5728\u8ba4\u77e5\u5e95\u5c42\u7ffb\u4e0d\u4e86\u8eab\u3002 \u9ad8\u6548\u5b66\u4e60 \u00b6 \u5176\u4e2d\uff0c\u6211\u8fd8\u5f15\u7528\u4e86\u4e00\u5f20\u5b66\u4e60\u91d1\u5b57\u5854 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u4f60\u542c\u522b\u4eba\u8bb2\uff0c\u6216\u662f\u81ea\u5df1\u770b\u4e66\uff0c\u6216\u662f\u8ba9\u522b\u4eba\u6f14\u793a\u7ed9\u4f60\uff0c\u8fd9\u4e9b\u90fd\u4e0d\u80fd\u8ba9\u4f60\u771f\u6b63\u83b7\u5f97\u5b66\u4e60\u80fd\u529b\uff0c\u56e0\u4e3a\u4f60\u662f\u5728\u88ab\u522b\u4eba\u704c\u8f93\uff0c\u5728\u542c\u522b\u4eba\u8bf4\u3002 \u53ea\u6709\u4f60\u5f00\u59cb\u81ea\u5df1\u601d\u8003\uff0c\u5f00\u59cb\u81ea\u5df1\u603b\u7ed3\u548c\u5f52\u7eb3\uff0c\u5f00\u59cb\u627e\u4eba\u4ea4\u6d41\u8ba8\u8bba\uff0c\u5f00\u59cb\u8df5\u884c\uff0c\u5e76\u5f00\u59cb\u5bf9\u5916\u8f93\u51fa\uff0c\u4f60\u624d\u4f1a\u638c\u63e1\u5230\u771f\u6b63\u7684\u5b66\u4e60\u80fd\u529b\u3002 \u6240\u4ee5\uff0c\u5b66\u4e60\u4e0d\u662f\u52aa\u529b\u8bfb\u66f4\u591a\u7684\u4e66\uff0c\u76f2\u76ee\u8ffd\u6c42\u9605\u8bfb\u7684\u901f\u5ea6\u548c\u6570\u91cf\uff0c\u8fd9\u4f1a\u8ba9\u4eba\u4ea7\u751f\u4f4e\u5c42\u6b21\u7684\u52e4\u594b\u548c\u6210\u957f\u7684\u611f\u89c9\uff0c\u8fd9\u53ea\u662f\u5728\u4f7f\u86ee\u529b\u3002\u8981\u601d\u8fa8\uff0c\u8981\u8df5\u884c\uff0c\u8981\u603b\u7ed3\u548c\u5f52\u7eb3\uff0c\u5426\u5219\uff0c\u4f60\u53ea\u662f\u5728\u673a\u68b0\u5730\u91cd\u590d\u67d0\u4ef6\u4e8b\uff08\u8bb0\u5fc6\u77e5\u8bc6\uff09\uff0c\u800c\u4e0d\u4f1a\u6709\u8d28\u7684\u6210\u957f\u7684\u3002 ARTS\u7684\u521d\u8877 \u00b6 Algorithm\u3002\u4e3b\u8981\u662f\u4e3a\u4e86\u7f16\u7a0b\u8bad\u7ec3\u548c\u5b66\u4e60\u3002\u6bcf\u5468\u81f3\u5c11\u505a\u4e00\u4e2a leetcode \u7684\u7b97\u6cd5\u9898\uff08\u5148\u4eceEasy\u5f00\u59cb\uff0c\u7136\u540e\u518dMedium\uff0c\u6700\u540e\u624dHard\uff09\u3002\u8fdb\u884c\u7f16\u7a0b\u8bad\u7ec3\uff0c\u5982\u679c\u4e0d\u8bad\u7ec3\u4f60\u770b\u518d\u591a\u7684\u7b97\u6cd5\u4e66\uff0c\u4f60\u4f9d\u7136\u4e0d\u4f1a\u505a\u7b97\u6cd5\u9898\uff0c\u770b\u5b8c\u4e66\u540e\uff0c\u4f60\u9700\u8981\u8bad\u7ec3\u3002\u5173\u4e8e\u505aLeetcode\u7684\u7684\u4f18\u52bf\uff0c\u4f60\u53ef\u4ee5\u770b\u4e00\u4e0b\u6211\u5728coolshell\u4e0a\u7684\u6587\u7ae0 Leetcode \u7f16\u7a0b\u8bad\u7ec3 \u3002 Review\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u5b66\u4e60\u82f1\u6587\uff0c\u5982\u679c\u4f60\u7684\u82f1\u6587\u4e0d\u884c\uff0c\u4f60\u57fa\u672c\u4e0a\u65e0\u7f18\u6280\u672f\u9ad8\u624b\u3002\u6240\u4ee5\uff0c\u9700\u8981\u4f60\u9605\u8bfb\u5e76\u70b9\u8bc4\u81f3\u5c11\u4e00\u7bc7\u82f1\u6587\u6280\u672f\u6587\u7ae0\uff0c\u6211\u4e2a\u4eba\u6700\u559c\u6b22\u53bb\u7684\u5730\u65b9\u662f Medium.com\uff08\u9700\u8981\u68af\u5b50\uff09 \u4ee5\u53ca\u5404\u4e2a\u516c\u53f8\u7684\u6280\u672fblog\uff0c\u5982Netflix\u7684\u3002 Tip\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u603b\u7ed3\u548c\u5f52\u7eb3\u4f60\u5728\u662f\u5e38\u5de5\u4f5c\u4e2d\u6240\u9047\u5230\u7684\u77e5\u8bc6\u70b9\u3002\u5b66\u4e60\u81f3\u5c11\u4e00\u4e2a\u6280\u672f\u6280\u5de7\u3002\u4f60\u5728\u5de5\u4f5c\u4e2d\u9047\u5230\u7684\u95ee\u9898\uff0c\u8e29\u8fc7\u7684\u5751\uff0c\u5b66\u4e60\u7684\u70b9\u6ef4\u77e5\u8bc6\u3002 Share\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u5efa\u7acb\u4f60\u7684\u5f71\u54cd\u529b\uff0c\u80fd\u591f\u8f93\u51fa\u4ef7\u503c\u89c2\u3002\u5206\u4eab\u4e00\u7bc7\u6709\u89c2\u70b9\u548c\u601d\u8003\u7684\u6280\u672f\u6587\u7ae0\u3002 \u8fd9\u5c31\u662fARTS\u7684\u5168\u90e8\u52a8\u673a\u3002 \u4e3a\u4ec0\u4e48\u8981\u5199\u4e0b\u6765 \u00b6 \u56e0\u4e3a\u5199\u4f5c\u662f\u4e00\u79cd\u975e\u5e38\u91cd\u8981\u7684\u6280\u80fd\uff0c\u5199\u4f5c\u4e0d\u4ec5\u4ec5\u53ef\u4ee5\u5e2e\u4f60\u7ec4\u7ec7\u4f60\u7684\u601d\u8def\u548c\u8bed\u8a00\uff0c\u5e2e\u4f60\u68b3\u7406\u4f60\u7684\u77e5\u8bc6\uff0c\u66f4\u91cd\u8981\u7684\u662f\u5199\u4f5c\u5176\u5b9e\u662f\u4e00\u79cd\u81ea\u5df1\u5bf9\u81ea\u5df1\u7684\u601d\u8003\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u6269\u6563\u5e76\u5f15\u5165\u5176\u5b83\u4eba\u7684\u8ba8\u8bba\u3001\u6307\u6b63\u3001\u6279\u8bc4\uff0c\u8fd9\u5bf9\u4e2a\u4eba\u6765\u8bf4\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002 Reference \u00b6 \u6781\u5ba2\u65f6\u95f4\u300a\u5de6\u8033\u542c\u98ce\u300b\u53d1\u8d77\u7684ARTS\u6311\u6218\u600e\u4e48\u53c2\u52a0\uff1f","title":"\u9996\u9875"},{"location":"#arts-note","text":"Mark. 20190613 - HyperJ","title":"ARTS Note"},{"location":"#2019","text":"Month 01 02 03 04 05 October -- -- -- -- -- September Week 9-1 Week 9-2 Week 9-3 Week 9-4 Week 9-5 August Week 8-1 Week 8-2 Week 8-3 Week 8-4 -- July Week 7-1 Week 7-2 Week 7-3 Week 7-4 -- June -- Week 6-2 Week 6-3 Week 6-4 Week 6-5","title":"2019"},{"location":"#share","text":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Spark Shuffle Service Spark \u6e90\u7801\u8c03\u8bd5 \u6f2b\u8c08\u6570\u636e\u8d28\u91cf Spark SQL \u89c4\u5219 Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Flink \u5f00\u53d1\u5b9e\u8df5 \u5143\u6570\u636e\u96c6\u6210 \u5143\u6570\u636e\u4ed3\u5e93 \u65e5\u5fd7\u91c7\u96c6 \u6570\u636e\u96c6\u6210","title":"Share"},{"location":"#arts","text":"","title":"Arts"},{"location":"#arts_1","text":"\u6211\u4eec\u6574\u4e2a\u4e16\u754c\u8fdb\u5165\u4e86\u524d\u6240\u672a\u6709\u7684\u4fe1\u606f\u7206\u70b8\u65f6\u4ee3\uff0c\u4eba\u4eec\u62c5\u5fe7\u7684\u4e0d\u518d\u662f\u65e0\u77e5\u8bc6\u53ef\u5b66\uff0c\u800c\u662f\u6709\u5b66\u4e0d\u5b8c\u7684\u77e5\u8bc6\u3002\u800c\u4e14\u65f6\u4ee3\u7684\u8282\u594f\u53d8\u5f97\u8d8a\u6765\u8d8a\u5feb\uff0c\u4f60\u53ef\u80fd\u518d\u4e5f\u4e0d\u50cf 20 \u5e74\u524d\uff0c\u53ef\u4ee5\u6c89\u7740\u4f18\u96c5\u5e73\u548c\u5730\u6ce1\u4e0a\u4e00\u676f\u8336\uff0c\u5750\u5728\u4e00\u4e2a\u8fdc\u79bb\u55a7\u56a3\u7684\u73af\u5883\u4e0b\uff0c\u8ba4\u8ba4\u771f\u771f\u5730\u770b\u672c\u4e66\u3002 \u8fd9\u4e2a\u65f6\u4ee3\uff0c\u4f60\u518d\u4e5f\u4e0d\u4f1a\u6709\u5927\u5757\u5927\u5757\u7684\u65f6\u95f4\uff0c\u4f60\u7684\u65f6\u95f4\u90fd\u88ab\u6253\u6210\u788e\u7247\u4e86\uff0c\u4e0d\u77e5\u4e0d\u89c9\u4f60\u4e5f\u6210\u4e3a\u4e86\u5feb\u9910\u6587\u5316\u7684\u62e5\u8db8\u2026\u2026\u5728\u8fd9\u6837\u4e00\u4e2a\u65f6\u4ee3\u4e0b\uff0c\u5feb\u901f\u3001\u7b80\u5355\u3001\u8f7b\u677e\u7684\u65b9\u5f0f\u7ed9\u4eba\u5e26\u6765\u7684\u5feb\u611f\u66f4\u5f3a\u70c8\uff0c\u800c\u9ad8\u5c42\u6b21\u7684\u601d\u8003\u3001\u601d\u8fa8\u548c\u903b\u8f91\u5219\u88ab\u8fd9\u4e9b\u9891\u5ea6\u9ad8\u7684\u5feb\u9910\u4fe1\u606f\u611f\u6240\u5f31\u5316\u3002\u5546\u5bb6\u4eec\u770b\u5230\u5728\u8fd9\u6837\u7684\u65f6\u4ee3\u91cc\u600e\u4e48\u6cbb\u6108\u8fd9\u4e9b\u4eba\u5728\u5b66\u4e60\u4e0a\u7684\u7126\u8651\u7684\u5546\u673a\uff0c\u4ed6\u4eec\u5728\u60f3\u65b9\u8bbe\u6cd5\u5730\u7528\u4e00\u4e9b\u624b\u6bb5\u63a8\u51fa\u5404\u79cd\u4ee3\u8bfb\u3001\u9886\u8bfb\u548c\u542c\u8bfb\u7c7b\u4ea7\u54c1\uff0c\u8ba9\u4eba\u4eec\u53ef\u4ee5\u5728\u77ed\u65f6\u95f4\u5185\u4f53\u4f1a\u5230\u8f7b\u677e\u83b7\u53d6\u77e5\u8bc6\u7684\u5feb\u611f\uff0c\u5e76\u4ea7\u751f\u52e4\u594b\u597d\u5b66\u548c\u6210\u957f\u7684\u5e7b\u89c9\uff08\u8001\u5b9e\u8bf4\uff0c\u50cf\u6211\u8fd9\u79cd\u4ed8\u8d39\u4e13\u680f\u6216\u662f\u5f97\u5230\u7b49\u77e5\u8bc6\u4ed8\u8d39\u4ea7\u54c1\u57fa\u672c\u4e0a\u5c31\u662f\u7c7b\u4f3c\u7684\u4ea7\u7269\uff09\u3002 \u8fd9\u4e9b\u6240\u8c13\u7684\u201c\u5feb\u9910\u6587\u5316\u201d\u53ef\u4ee5\u8ba9\u4f60\u6709\u77ed\u6682\u7684\u6ee1\u8db3\u611f\uff0c\u4f46\u662f\u65e0\u6cd5\u8ba9\u4f60\u6709\u66f4\u6df1\u5c42\u6b21\u7684\u601d\u8003\u548c\u628a\u77e5\u8bc6\u8f6c\u6362\u6210\u81ea\u5df1\u7684\u6280\u80fd\u7684\u6709\u6548\u8def\u5f84\uff0c\u56e0\u4e3a\u90a3\u4e9b\u90fd\u662f\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u7cbe\u529b\u7684\u4ed8\u51fa\uff0c\u4e0d\u7b26\u5408\u73b0\u4ee3\u4eba\u7684\u751f\u6d3b\u8282\u594f\u3002\u4eba\u4eec\u5f00\u59cb\u5728\u670b\u53cb\u5708\u3001\u516c\u4f17\u53f7\u3001\u5f97\u5230\u7b49\u8fd9\u6837\u7684\u5730\u65b9\u8fdb\u884c\u5b66\u4e60\uff0c\u5bfc\u81f4\u4ed6\u4eec\u8d8a\u5b66\u8d8a\u7126\u8651\uff0c\u8d8a\u5b66\u8d8a\u6d6e\u71e5\uff0c\u8d8a\u5b66\u8d8a\u4e0d\u4f1a\u601d\u8003\u3002\u4e8e\u662f\uff0c\u4ed6\u4eec\u6210\u4e86\u201c\u4ec0\u4e48\u90fd\u61c2\uff0c\u4f46\u4f9d\u7136\u8fc7\u4e0d\u597d\u8fd9\u4e00\u751f\u201d\u7684\u72b6\u6001\u3002 \u4f60\u6709\u6ca1\u6709\u53d1\u73b0\uff0c\u5728\u77e5\u8bc6\u7684\u9886\u57df\u4e5f\u6709\u9636\u5c42\u4e4b\u5206\uff0c\u90a3\u4e9b\u957f\u671f\u5728\u5e95\u5c42\u77e5\u8bc6\u9636\u5c42\u7684\u4eba\uff0c\u9700\u8981\u7b49\u7740\u9ad8\u5c42\u7684\u4eba\u6765\u5582\u517b\uff0c\u4ed6\u4eec\u957f\u671f\u9677\u4e8e\u5404\u79cd\u8c23\u8a00\u548c\u4e0d\u51c6\u786e\u7684\u4fe1\u606f\u73af\u5883\u4e2d\uff0c\u4e8e\u662f\u5c31\u5bfc\u81f4\u9519\u8bef\u6216\u5e7c\u7a1a\u7684\u8ba4\u77e5\uff0c\u5e76\u4e60\u60ef\u4e8e\u90a3\u4e9b\u4e0d\u8d39\u52b2\u513f\u7684\u8f7b\u5ea6\u5b66\u4e60\u65b9\u5f0f\uff0c\u4ece\u800c\u4e00\u70b9\u70b9\u5730\u4e27\u5931\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u72ec\u7acb\u601d\u8003\u80fd\u529b\uff0c\u4ece\u800c\u518d\u4e5f\u6ca1\u6709\u80fd\u529b\u6253\u7834\u77e5\u8bc6\u9636\u5c42\u7684\u9650\u5236\uff0c\u88ab\u56f0\u5728\u8ba4\u77e5\u5e95\u5c42\u7ffb\u4e0d\u4e86\u8eab\u3002","title":"\u53d1\u8d77ARTS\u7684\u539f\u56e0"},{"location":"#_1","text":"\u5176\u4e2d\uff0c\u6211\u8fd8\u5f15\u7528\u4e86\u4e00\u5f20\u5b66\u4e60\u91d1\u5b57\u5854 \u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u4f60\u542c\u522b\u4eba\u8bb2\uff0c\u6216\u662f\u81ea\u5df1\u770b\u4e66\uff0c\u6216\u662f\u8ba9\u522b\u4eba\u6f14\u793a\u7ed9\u4f60\uff0c\u8fd9\u4e9b\u90fd\u4e0d\u80fd\u8ba9\u4f60\u771f\u6b63\u83b7\u5f97\u5b66\u4e60\u80fd\u529b\uff0c\u56e0\u4e3a\u4f60\u662f\u5728\u88ab\u522b\u4eba\u704c\u8f93\uff0c\u5728\u542c\u522b\u4eba\u8bf4\u3002 \u53ea\u6709\u4f60\u5f00\u59cb\u81ea\u5df1\u601d\u8003\uff0c\u5f00\u59cb\u81ea\u5df1\u603b\u7ed3\u548c\u5f52\u7eb3\uff0c\u5f00\u59cb\u627e\u4eba\u4ea4\u6d41\u8ba8\u8bba\uff0c\u5f00\u59cb\u8df5\u884c\uff0c\u5e76\u5f00\u59cb\u5bf9\u5916\u8f93\u51fa\uff0c\u4f60\u624d\u4f1a\u638c\u63e1\u5230\u771f\u6b63\u7684\u5b66\u4e60\u80fd\u529b\u3002 \u6240\u4ee5\uff0c\u5b66\u4e60\u4e0d\u662f\u52aa\u529b\u8bfb\u66f4\u591a\u7684\u4e66\uff0c\u76f2\u76ee\u8ffd\u6c42\u9605\u8bfb\u7684\u901f\u5ea6\u548c\u6570\u91cf\uff0c\u8fd9\u4f1a\u8ba9\u4eba\u4ea7\u751f\u4f4e\u5c42\u6b21\u7684\u52e4\u594b\u548c\u6210\u957f\u7684\u611f\u89c9\uff0c\u8fd9\u53ea\u662f\u5728\u4f7f\u86ee\u529b\u3002\u8981\u601d\u8fa8\uff0c\u8981\u8df5\u884c\uff0c\u8981\u603b\u7ed3\u548c\u5f52\u7eb3\uff0c\u5426\u5219\uff0c\u4f60\u53ea\u662f\u5728\u673a\u68b0\u5730\u91cd\u590d\u67d0\u4ef6\u4e8b\uff08\u8bb0\u5fc6\u77e5\u8bc6\uff09\uff0c\u800c\u4e0d\u4f1a\u6709\u8d28\u7684\u6210\u957f\u7684\u3002","title":"\u9ad8\u6548\u5b66\u4e60"},{"location":"#arts_2","text":"Algorithm\u3002\u4e3b\u8981\u662f\u4e3a\u4e86\u7f16\u7a0b\u8bad\u7ec3\u548c\u5b66\u4e60\u3002\u6bcf\u5468\u81f3\u5c11\u505a\u4e00\u4e2a leetcode \u7684\u7b97\u6cd5\u9898\uff08\u5148\u4eceEasy\u5f00\u59cb\uff0c\u7136\u540e\u518dMedium\uff0c\u6700\u540e\u624dHard\uff09\u3002\u8fdb\u884c\u7f16\u7a0b\u8bad\u7ec3\uff0c\u5982\u679c\u4e0d\u8bad\u7ec3\u4f60\u770b\u518d\u591a\u7684\u7b97\u6cd5\u4e66\uff0c\u4f60\u4f9d\u7136\u4e0d\u4f1a\u505a\u7b97\u6cd5\u9898\uff0c\u770b\u5b8c\u4e66\u540e\uff0c\u4f60\u9700\u8981\u8bad\u7ec3\u3002\u5173\u4e8e\u505aLeetcode\u7684\u7684\u4f18\u52bf\uff0c\u4f60\u53ef\u4ee5\u770b\u4e00\u4e0b\u6211\u5728coolshell\u4e0a\u7684\u6587\u7ae0 Leetcode \u7f16\u7a0b\u8bad\u7ec3 \u3002 Review\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u5b66\u4e60\u82f1\u6587\uff0c\u5982\u679c\u4f60\u7684\u82f1\u6587\u4e0d\u884c\uff0c\u4f60\u57fa\u672c\u4e0a\u65e0\u7f18\u6280\u672f\u9ad8\u624b\u3002\u6240\u4ee5\uff0c\u9700\u8981\u4f60\u9605\u8bfb\u5e76\u70b9\u8bc4\u81f3\u5c11\u4e00\u7bc7\u82f1\u6587\u6280\u672f\u6587\u7ae0\uff0c\u6211\u4e2a\u4eba\u6700\u559c\u6b22\u53bb\u7684\u5730\u65b9\u662f Medium.com\uff08\u9700\u8981\u68af\u5b50\uff09 \u4ee5\u53ca\u5404\u4e2a\u516c\u53f8\u7684\u6280\u672fblog\uff0c\u5982Netflix\u7684\u3002 Tip\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u603b\u7ed3\u548c\u5f52\u7eb3\u4f60\u5728\u662f\u5e38\u5de5\u4f5c\u4e2d\u6240\u9047\u5230\u7684\u77e5\u8bc6\u70b9\u3002\u5b66\u4e60\u81f3\u5c11\u4e00\u4e2a\u6280\u672f\u6280\u5de7\u3002\u4f60\u5728\u5de5\u4f5c\u4e2d\u9047\u5230\u7684\u95ee\u9898\uff0c\u8e29\u8fc7\u7684\u5751\uff0c\u5b66\u4e60\u7684\u70b9\u6ef4\u77e5\u8bc6\u3002 Share\uff1a\u4e3b\u8981\u662f\u4e3a\u4e86\u5efa\u7acb\u4f60\u7684\u5f71\u54cd\u529b\uff0c\u80fd\u591f\u8f93\u51fa\u4ef7\u503c\u89c2\u3002\u5206\u4eab\u4e00\u7bc7\u6709\u89c2\u70b9\u548c\u601d\u8003\u7684\u6280\u672f\u6587\u7ae0\u3002 \u8fd9\u5c31\u662fARTS\u7684\u5168\u90e8\u52a8\u673a\u3002","title":"ARTS\u7684\u521d\u8877"},{"location":"#_2","text":"\u56e0\u4e3a\u5199\u4f5c\u662f\u4e00\u79cd\u975e\u5e38\u91cd\u8981\u7684\u6280\u80fd\uff0c\u5199\u4f5c\u4e0d\u4ec5\u4ec5\u53ef\u4ee5\u5e2e\u4f60\u7ec4\u7ec7\u4f60\u7684\u601d\u8def\u548c\u8bed\u8a00\uff0c\u5e2e\u4f60\u68b3\u7406\u4f60\u7684\u77e5\u8bc6\uff0c\u66f4\u91cd\u8981\u7684\u662f\u5199\u4f5c\u5176\u5b9e\u662f\u4e00\u79cd\u81ea\u5df1\u5bf9\u81ea\u5df1\u7684\u601d\u8003\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u6269\u6563\u5e76\u5f15\u5165\u5176\u5b83\u4eba\u7684\u8ba8\u8bba\u3001\u6307\u6b63\u3001\u6279\u8bc4\uff0c\u8fd9\u5bf9\u4e2a\u4eba\u6765\u8bf4\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002","title":"\u4e3a\u4ec0\u4e48\u8981\u5199\u4e0b\u6765"},{"location":"#reference","text":"\u6781\u5ba2\u65f6\u95f4\u300a\u5de6\u8033\u542c\u98ce\u300b\u53d1\u8d77\u7684ARTS\u6311\u6218\u600e\u4e48\u53c2\u52a0\uff1f","title":"Reference"},{"location":"share/2019/","text":"Share \u00b6 Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Spark Shuffle Service Spark \u6e90\u7801\u8c03\u8bd5 \u6f2b\u8c08\u6570\u636e\u8d28\u91cf Spark SQL \u89c4\u5219 Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Flink \u5f00\u53d1\u5b9e\u8df5 \u5143\u6570\u636e\u96c6\u6210 \u5143\u6570\u636e\u4ed3\u5e93 \u65e5\u5fd7\u91c7\u96c6 \u6570\u636e\u96c6\u6210","title":2019},{"location":"share/2019/#share","text":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Spark Shuffle Service Spark \u6e90\u7801\u8c03\u8bd5 \u6f2b\u8c08\u6570\u636e\u8d28\u91cf Spark SQL \u89c4\u5219 Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 Flink \u5f00\u53d1\u5b9e\u8df5 \u5143\u6570\u636e\u96c6\u6210 \u5143\u6570\u636e\u4ed3\u5e93 \u65e5\u5fd7\u91c7\u96c6 \u6570\u636e\u96c6\u6210","title":"Share"},{"location":"share/2019/data-integration/","text":"\u6570\u636e\u96c6\u6210 \u00b6 Reference \u00b6","title":"\u6570\u636e\u96c6\u6210"},{"location":"share/2019/data-integration/#_1","text":"","title":"\u6570\u636e\u96c6\u6210"},{"location":"share/2019/data-integration/#reference","text":"","title":"Reference"},{"location":"share/2019/flink-development-practice/","text":"Flink \u5f00\u53d1\u5b9e\u8df5 \u00b6 \u57fa\u7840\u6982\u5ff5 \u00b6 Source\u3001Transformation\u3001Sink Window\uff1aTumbling Window\u3001Sliding Window\u3001Session Window\u3001Global Window State\uff1aKeyed State\u3001Operator State\uff1bManaged State\u3001Raw State StateBackend\uff1aMemory\u3001Fs\u3001RocksDB Checkpoint\u3001Savepoint \u5f00\u53d1\u4f18\u5316 \u00b6 \u53c2\u6570\u5316\u914d\u7f6e\u4fe1\u606f \u8bbe\u7f6e parallelism\u3001name\u3001uid \u5904\u7406\u665a\u5230\u6570\u636e \u83b7\u53d6\u4e22\u5f03\u6570\u636e \u5e76\u53d1\u5ea6\u63a7\u5236 TM\u6570\u91cf\u3001\u5185\u5b58 \u95ee\u9898\u6392\u67e5 \u00b6 \u5ef6\u8fdf\uff1a\u6162\u8282\u70b9\u3001\u5927\u6d88\u606f\u3001\u8d44\u6e90\u4e0d\u8db3\u3001\u6570\u636e\u589e\u957f\u3001\u8282\u70b9\u5f02\u5e38\u3001\u5904\u7406\u5f02\u5e38\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38 \u5931\u8d25\uff1a\u8d44\u6e90\u4e0d\u8db3/\u8d85\u989d\u3001\u73af\u5883\u5f02\u5e38\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38\u3001\u8282\u70b9\u6545\u969c\u3001\u5904\u7406\u5931\u8d25\u3001OOM \u6392\u67e5 UI Metrics Log Reference \u00b6","title":"Flink \u5f00\u53d1\u5b9e\u8df5"},{"location":"share/2019/flink-development-practice/#flink","text":"","title":"Flink \u5f00\u53d1\u5b9e\u8df5"},{"location":"share/2019/flink-development-practice/#_1","text":"Source\u3001Transformation\u3001Sink Window\uff1aTumbling Window\u3001Sliding Window\u3001Session Window\u3001Global Window State\uff1aKeyed State\u3001Operator State\uff1bManaged State\u3001Raw State StateBackend\uff1aMemory\u3001Fs\u3001RocksDB Checkpoint\u3001Savepoint","title":"\u57fa\u7840\u6982\u5ff5"},{"location":"share/2019/flink-development-practice/#_2","text":"\u53c2\u6570\u5316\u914d\u7f6e\u4fe1\u606f \u8bbe\u7f6e parallelism\u3001name\u3001uid \u5904\u7406\u665a\u5230\u6570\u636e \u83b7\u53d6\u4e22\u5f03\u6570\u636e \u5e76\u53d1\u5ea6\u63a7\u5236 TM\u6570\u91cf\u3001\u5185\u5b58","title":"\u5f00\u53d1\u4f18\u5316"},{"location":"share/2019/flink-development-practice/#_3","text":"\u5ef6\u8fdf\uff1a\u6162\u8282\u70b9\u3001\u5927\u6d88\u606f\u3001\u8d44\u6e90\u4e0d\u8db3\u3001\u6570\u636e\u589e\u957f\u3001\u8282\u70b9\u5f02\u5e38\u3001\u5904\u7406\u5f02\u5e38\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38 \u5931\u8d25\uff1a\u8d44\u6e90\u4e0d\u8db3/\u8d85\u989d\u3001\u73af\u5883\u5f02\u5e38\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38\u3001\u8282\u70b9\u6545\u969c\u3001\u5904\u7406\u5931\u8d25\u3001OOM \u6392\u67e5 UI Metrics Log","title":"\u95ee\u9898\u6392\u67e5"},{"location":"share/2019/flink-development-practice/#reference","text":"","title":"Reference"},{"location":"share/2019/flink-job-execution-process/","text":"Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u00b6 flink \u83b7\u53d6\u6267\u884c\u8def\u5f84\uff0c\u83b7\u53d6\u914d\u7f6e\u4fe1\u606f\uff0c\u73af\u5883\u53d8\u91cf\uff0c\u65e5\u5fd7\u914d\u7f6e\uff0c\u6267\u884c\u547d\u4ee4\uff0c\u63d0\u4ea4\u7ed9 CliFrontend CliFrontend \u52a0\u8f7d\u73af\u5883\u53ca\u914d\u7f6e\u4fe1\u606f\uff0c\u521d\u59cb\u5316\uff0c\u89e3\u6790\u5e76\u6267\u884c\u8bf7\u6c42 run \u89e3\u6790\u914d\u7f6e\u4fe1\u606f\uff0c\u751f\u6210\u8fd0\u884c\u65f6\u4fe1\u606f \u6784\u5efa PackagedProgram \u6267\u884c runProgram\uff0c\u83b7\u53d6 ClusterDescriptor\uff0c\u8ba1\u7b97\u5e76\u884c\u5ea6\uff0c\u751f\u6210 JobGraph\uff0c\u63d0\u4ea4\u4f5c\u4e1a \u6e05\u7406\u8d44\u6e90\u53ca\u6587\u4ef6 build code -> transformations List StreamGraphGenerator -> StreamGraph StreamingJobGraphGenerator -> JobGraph ExecutionGraphBuilder -> ExecutionGraph resource \u67e5\u627e\u5df2\u5206\u914d slot \u662f\u5426\u7b26\u5408\u6761\u4ef6 \u67e5\u627e slotPool \u662f\u5426\u6709\u7a7a\u95f2\u7684 \u5411 RM \u7ec4\u4ef6\u7533\u8bf7 slot\uff0c\u5411 YARN \u7684 RM \u7533\u8bf7 container YARN \u521d\u59cb\u5316 container\uff0c\u901a\u77e5 container \u7533\u8bf7\u6210\u529f \u90e8\u7f72 TM \uff0c\u5411 RM \u6ce8\u518c RM \u5411 TM \u7533\u8bf7 slot TM \u5411 JM \u6ce8\u518c\uff0c\u5e76\u63d0\u4f9b slot JM \u5411 TM \u7684 slot \u90e8\u7f72 task Reference \u00b6","title":"Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"share/2019/flink-job-execution-process/#flink-cluster-mode-on-yarn","text":"flink \u83b7\u53d6\u6267\u884c\u8def\u5f84\uff0c\u83b7\u53d6\u914d\u7f6e\u4fe1\u606f\uff0c\u73af\u5883\u53d8\u91cf\uff0c\u65e5\u5fd7\u914d\u7f6e\uff0c\u6267\u884c\u547d\u4ee4\uff0c\u63d0\u4ea4\u7ed9 CliFrontend CliFrontend \u52a0\u8f7d\u73af\u5883\u53ca\u914d\u7f6e\u4fe1\u606f\uff0c\u521d\u59cb\u5316\uff0c\u89e3\u6790\u5e76\u6267\u884c\u8bf7\u6c42 run \u89e3\u6790\u914d\u7f6e\u4fe1\u606f\uff0c\u751f\u6210\u8fd0\u884c\u65f6\u4fe1\u606f \u6784\u5efa PackagedProgram \u6267\u884c runProgram\uff0c\u83b7\u53d6 ClusterDescriptor\uff0c\u8ba1\u7b97\u5e76\u884c\u5ea6\uff0c\u751f\u6210 JobGraph\uff0c\u63d0\u4ea4\u4f5c\u4e1a \u6e05\u7406\u8d44\u6e90\u53ca\u6587\u4ef6 build code -> transformations List StreamGraphGenerator -> StreamGraph StreamingJobGraphGenerator -> JobGraph ExecutionGraphBuilder -> ExecutionGraph resource \u67e5\u627e\u5df2\u5206\u914d slot \u662f\u5426\u7b26\u5408\u6761\u4ef6 \u67e5\u627e slotPool \u662f\u5426\u6709\u7a7a\u95f2\u7684 \u5411 RM \u7ec4\u4ef6\u7533\u8bf7 slot\uff0c\u5411 YARN \u7684 RM \u7533\u8bf7 container YARN \u521d\u59cb\u5316 container\uff0c\u901a\u77e5 container \u7533\u8bf7\u6210\u529f \u90e8\u7f72 TM \uff0c\u5411 RM \u6ce8\u518c RM \u5411 TM \u7533\u8bf7 slot TM \u5411 JM \u6ce8\u518c\uff0c\u5e76\u63d0\u4f9b slot JM \u5411 TM \u7684 slot \u90e8\u7f72 task","title":"Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"share/2019/flink-job-execution-process/#reference","text":"","title":"Reference"},{"location":"share/2019/log-collection/","text":"\u65e5\u5fd7\u91c7\u96c6 \u00b6 \u7c7b\u578b \u00b6 \u884c\u4e3a\u65e5\u5fd7 \u4ee3\u7801\u65e5\u5fd7 \u7f51\u7edc\u65e5\u5fd7 \u63a8\u9001\u65e5\u5fd7 \u5d29\u6e83\u65e5\u5fd7 \u4f18\u5316 \u00b6 \u683c\u5f0f\u5316 \u5206\u7247 \u538b\u7f29 \u52a0\u5bc6 \u7f13\u5b58 Reference \u00b6 Logan\uff1a\u7f8e\u56e2\u70b9\u8bc4\u7684\u5f00\u6e90\u79fb\u52a8\u7aef\u57fa\u7840\u65e5\u5fd7\u5e93","title":"\u65e5\u5fd7\u91c7\u96c6"},{"location":"share/2019/log-collection/#_1","text":"","title":"\u65e5\u5fd7\u91c7\u96c6"},{"location":"share/2019/log-collection/#_2","text":"\u884c\u4e3a\u65e5\u5fd7 \u4ee3\u7801\u65e5\u5fd7 \u7f51\u7edc\u65e5\u5fd7 \u63a8\u9001\u65e5\u5fd7 \u5d29\u6e83\u65e5\u5fd7","title":"\u7c7b\u578b"},{"location":"share/2019/log-collection/#_3","text":"\u683c\u5f0f\u5316 \u5206\u7247 \u538b\u7f29 \u52a0\u5bc6 \u7f13\u5b58","title":"\u4f18\u5316"},{"location":"share/2019/log-collection/#reference","text":"Logan\uff1a\u7f8e\u56e2\u70b9\u8bc4\u7684\u5f00\u6e90\u79fb\u52a8\u7aef\u57fa\u7840\u65e5\u5fd7\u5e93","title":"Reference"},{"location":"share/2019/metadata-integration/","text":"\u5143\u6570\u636e\u96c6\u6210 \u00b6 \u7c7b\u578b \u5ba1\u8ba1 \u64cd\u4f5c \u76d1\u63a7 \u5ea6\u91cf \u673a\u5236 Hook & Bridge \u673a\u5236 Metrics \u673a\u5236 \u4e2d\u95f4\u4ef6\u3001\u7f51\u5173\u3001\u5de5\u5177\u94fe \u62c9\u53d6\u3001\u63a8\u9001 \u589e\u91cf\u3001\u5168\u91cf \u5b9e\u65f6\u3001\u79bb\u7ebf HDFS \u00b6 \u57fa\u4e8e HDFS Checkpoint \u673a\u5236 \u57fa\u4e8e QJM \u67b6\u6784\uff0c\u4ece JournalNode \u62c9\u53d6\u6570\u636e Hive \u00b6 \u589e\u91cf\uff1aHive \u63d0\u4f9b\u7684 Hook \u673a\u5236 HBase \u00b6 \u589e\u91cf\uff1aHBase \u63d0\u4f9b\u7684 Coprocessor \u673a\u5236 Kafka \u00b6 Kafka \u63d0\u4f9b\u7684 ZkUtils \u5de5\u5177 Kylin \u00b6 Kylin \u63d0\u4f9b\u7684 ResourceTool \u5de5\u5177 Druid \u00b6 \u901a\u8fc7 MySQL \u96c6\u6210\u65b9\u5f0f\uff0c\u53c2\u8003 SQLMetadataConnector ElasticSearch \u00b6 \u901a\u8fc7 REST APIs \u65b9\u5f0f MySQL \u00b6 \u901a\u8fc7 Canal \u8fdb\u884c binlog \u589e\u91cf\u8ba2\u9605&\u6d88\u8d39 Other \u00b6 Impala Redis TiDB Tair YARN Spark Flink Oozie ZooKeeper Reference \u00b6 Apache Atlas Navigator Metadata Server Management How to write a Hive Hook","title":"\u5143\u6570\u636e\u96c6\u6210"},{"location":"share/2019/metadata-integration/#_1","text":"\u7c7b\u578b \u5ba1\u8ba1 \u64cd\u4f5c \u76d1\u63a7 \u5ea6\u91cf \u673a\u5236 Hook & Bridge \u673a\u5236 Metrics \u673a\u5236 \u4e2d\u95f4\u4ef6\u3001\u7f51\u5173\u3001\u5de5\u5177\u94fe \u62c9\u53d6\u3001\u63a8\u9001 \u589e\u91cf\u3001\u5168\u91cf \u5b9e\u65f6\u3001\u79bb\u7ebf","title":"\u5143\u6570\u636e\u96c6\u6210"},{"location":"share/2019/metadata-integration/#hdfs","text":"\u57fa\u4e8e HDFS Checkpoint \u673a\u5236 \u57fa\u4e8e QJM \u67b6\u6784\uff0c\u4ece JournalNode \u62c9\u53d6\u6570\u636e","title":"HDFS"},{"location":"share/2019/metadata-integration/#hive","text":"\u589e\u91cf\uff1aHive \u63d0\u4f9b\u7684 Hook \u673a\u5236","title":"Hive"},{"location":"share/2019/metadata-integration/#hbase","text":"\u589e\u91cf\uff1aHBase \u63d0\u4f9b\u7684 Coprocessor \u673a\u5236","title":"HBase"},{"location":"share/2019/metadata-integration/#kafka","text":"Kafka \u63d0\u4f9b\u7684 ZkUtils \u5de5\u5177","title":"Kafka"},{"location":"share/2019/metadata-integration/#kylin","text":"Kylin \u63d0\u4f9b\u7684 ResourceTool \u5de5\u5177","title":"Kylin"},{"location":"share/2019/metadata-integration/#druid","text":"\u901a\u8fc7 MySQL \u96c6\u6210\u65b9\u5f0f\uff0c\u53c2\u8003 SQLMetadataConnector","title":"Druid"},{"location":"share/2019/metadata-integration/#elasticsearch","text":"\u901a\u8fc7 REST APIs \u65b9\u5f0f","title":"ElasticSearch"},{"location":"share/2019/metadata-integration/#mysql","text":"\u901a\u8fc7 Canal \u8fdb\u884c binlog \u589e\u91cf\u8ba2\u9605&\u6d88\u8d39","title":"MySQL"},{"location":"share/2019/metadata-integration/#other","text":"Impala Redis TiDB Tair YARN Spark Flink Oozie ZooKeeper","title":"Other"},{"location":"share/2019/metadata-integration/#reference","text":"Apache Atlas Navigator Metadata Server Management How to write a Hive Hook","title":"Reference"},{"location":"share/2019/metadata-warehouse/","text":"\u5143\u6570\u636e\u6570\u4ed3 \u00b6 \u57fa\u7840\u6570\u636e \u00b6 \u6570\u636e\u8d44\u4ea7\uff1a\u547d\u540d\u7a7a\u95f4\u3001\u5e93\u3001\u8868\u3001\u76ee\u5f55\u3001\u6587\u4ef6\u7b49 \u6570\u4ed3\u96c6\u5e02\uff1a\u5206\u5c42\u3001\u4e3b\u9898\u3001\u4e1a\u52a1\u7ebf\u3001\u8840\u7f18\u3001\u5f71\u54cd \u6743\u9650\u5ba1\u8ba1\uff1a\u79df\u6237\u3001\u9879\u76ee\u7ec4\u3001\u7528\u6237\u3001\u89d2\u8272\u3001\u6743\u9650\uff0c\u5ba1\u8ba1 \u8c03\u5ea6\u8ba1\u7b97\uff1a\u4f5c\u4e1a\u3001\u6d4b\u8bd5\u3001\u5ba1\u6838\u3001\u8fd0\u884c\u3001\u91cd\u5bfc \u6570\u636e\u8d28\u91cf\uff1aSLA\u3001DQC\u3001\u751f\u547d\u5468\u671f \u670d\u52a1\u6570\u636e\uff1a\u961f\u5217\u3001\u5b58\u50a8\u3001\u8ba1\u7b97\u3001\u8c03\u5ea6 \u5e94\u7528\u6570\u636e\uff1a\u5e94\u7528\u3001\u62a5\u8868\u3001\u90ae\u4ef6\u3001\u67e5\u8be2 \u6570\u4ed3\u96c6\u5e02 \u00b6 \u6574\u5408\u4e8b\u5b9e\u5c42\uff08\u660e\u7ec6\uff09 \u00b6 \u6307\u6807\u4e3b\u9898\u5c42\uff08\u805a\u5408\uff09 \u00b6 \u5e94\u7528\u670d\u52a1 \u00b6 \u8d44\u6e90\u76ee\u5f55\u3001\u6570\u636e\u5730\u56fe \u6307\u6807\u4f53\u7cfb\u3001\u4ef7\u503c\u4f53\u7cfb \u4f18\u5316\u5206\u6790 \u5197\u4f59\u5206\u6790 \u70ed\u5ea6\u5206\u6790 \u5f71\u54cd\u5206\u6790 \u8d21\u732e\u5206\u6790 \u4f5c\u4e1a\u4f18\u5316 \u5b58\u50a8\u4f18\u5316 \u94fe\u8def\u4f18\u5316 \u6a21\u578b\u4f18\u5316 Reference \u00b6","title":"\u5143\u6570\u636e\u6570\u4ed3"},{"location":"share/2019/metadata-warehouse/#_1","text":"","title":"\u5143\u6570\u636e\u6570\u4ed3"},{"location":"share/2019/metadata-warehouse/#_2","text":"\u6570\u636e\u8d44\u4ea7\uff1a\u547d\u540d\u7a7a\u95f4\u3001\u5e93\u3001\u8868\u3001\u76ee\u5f55\u3001\u6587\u4ef6\u7b49 \u6570\u4ed3\u96c6\u5e02\uff1a\u5206\u5c42\u3001\u4e3b\u9898\u3001\u4e1a\u52a1\u7ebf\u3001\u8840\u7f18\u3001\u5f71\u54cd \u6743\u9650\u5ba1\u8ba1\uff1a\u79df\u6237\u3001\u9879\u76ee\u7ec4\u3001\u7528\u6237\u3001\u89d2\u8272\u3001\u6743\u9650\uff0c\u5ba1\u8ba1 \u8c03\u5ea6\u8ba1\u7b97\uff1a\u4f5c\u4e1a\u3001\u6d4b\u8bd5\u3001\u5ba1\u6838\u3001\u8fd0\u884c\u3001\u91cd\u5bfc \u6570\u636e\u8d28\u91cf\uff1aSLA\u3001DQC\u3001\u751f\u547d\u5468\u671f \u670d\u52a1\u6570\u636e\uff1a\u961f\u5217\u3001\u5b58\u50a8\u3001\u8ba1\u7b97\u3001\u8c03\u5ea6 \u5e94\u7528\u6570\u636e\uff1a\u5e94\u7528\u3001\u62a5\u8868\u3001\u90ae\u4ef6\u3001\u67e5\u8be2","title":"\u57fa\u7840\u6570\u636e"},{"location":"share/2019/metadata-warehouse/#_3","text":"","title":"\u6570\u4ed3\u96c6\u5e02"},{"location":"share/2019/metadata-warehouse/#_4","text":"","title":"\u6574\u5408\u4e8b\u5b9e\u5c42\uff08\u660e\u7ec6\uff09"},{"location":"share/2019/metadata-warehouse/#_5","text":"","title":"\u6307\u6807\u4e3b\u9898\u5c42\uff08\u805a\u5408\uff09"},{"location":"share/2019/metadata-warehouse/#_6","text":"\u8d44\u6e90\u76ee\u5f55\u3001\u6570\u636e\u5730\u56fe \u6307\u6807\u4f53\u7cfb\u3001\u4ef7\u503c\u4f53\u7cfb \u4f18\u5316\u5206\u6790 \u5197\u4f59\u5206\u6790 \u70ed\u5ea6\u5206\u6790 \u5f71\u54cd\u5206\u6790 \u8d21\u732e\u5206\u6790 \u4f5c\u4e1a\u4f18\u5316 \u5b58\u50a8\u4f18\u5316 \u94fe\u8def\u4f18\u5316 \u6a21\u578b\u4f18\u5316","title":"\u5e94\u7528\u670d\u52a1"},{"location":"share/2019/metadata-warehouse/#reference","text":"","title":"Reference"},{"location":"share/2019/spark-debug/","text":"Spark \u6e90\u7801\u8c03\u8bd5 \u00b6 \u73af\u5883 \u00b6 \u53ea\u6d89\u53ca Java \u53ca Scala \u4ee3\u7801\u7684\u7f16\u8bd1\u3001\u6d4b\u8bd5\u53ca\u8c03\u8bd5 macOS 10.14.5 Java 8u152 Scala 2.12.8 Maven 3.6.0 SBT 0.13.18 IDEA 2018.3.4 Spark 2.4.3 \u547d\u4ee4 \u00b6 \u7f16\u8bd1 \u00b6 maven ./build/mvn -DskipTests clean package ./build/mvn -pl :spark-core_2.12 -DskipTests clean package -am -pl \uff0c\u7f16\u8bd1\u6307\u5b9a\u6a21\u5757\uff0c{groupId}:{artifactId} \u6216\u662f dir_path -am \uff0c\u540c\u65f6\u7f16\u8bd1\u4f9d\u8d56\u6a21\u5757 ./dev/make-distribution.sh --tgz -Phadoop-2.7 -Phive -Phive-thriftserver -Pyarn -DskipTests sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false project core package \u6d4b\u8bd5 \u00b6 maven ./build/mvn -pl :core ./build/mvn test -DwildcardSuites = none -Dtest = org.apache.spark.streaming.JavaAPISuite -DwildcardSuites \uff0c\u6307\u5b9a Scala \u6d4b\u8bd5 -Dtest \uff0c\u6307\u5b9a Java \u6d4b\u8bd5 ./build/mvn test -pl core -Dtest = none -Dsuites = '*DAGSchedulerSuite SPARK-3353' Scala Test \u4f7f\u7528\u901a\u914d\u7b26\u5339\u914d\uff1a\u7c7b\u3001\u65b9\u6cd5\u3001\u6d4b\u8bd5\u540d\u79f0 sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false project core test testOnly *DAGSchedulerSuite -- -z \"SPARK-3353\" \u8c03\u8bd5 \u00b6 IDEA\uff1aRun > Edit Configurations > + > Remote > Host localhost \u3001Port 5005 \u3001Command -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 ./bin/spark-submit --driver-java-options \"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005\" --class org.apache.spark.examples.SparkPi examples/target/spark-examples_2.11-2.4.3-SNAPSHOT.jar Standalone \u6a21\u5f0f\uff0c\u53ef\u53ea\u542f\u52a8\u4e00\u4e2a Executor \u8fdb\u884c\u8c03\u8bd5 maven ./build/mvn test -pl core -Dtest = none -Dsuites = '*DAGSchedulerSuite' -DdebugForkedProcess = true -DdebuggerPort = 5005 -DdebugForkedProcess=true \uff0c\u5f00\u542f UT \u8c03\u8bd5\uff0c\u9ed8\u8ba4\u7aef\u53e3 5005 sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false -jvm-debug 5005 project core set fork in Test : = false testOnly org.apache.spark.scheduler.DAGSchedulerSuite -DdebugForkedProcess=true \uff0c\u5f00\u542f UT \u8c03\u8bd5\uff0c\u9ed8\u8ba4\u7aef\u53e3 5005 \u95ee\u9898 \u00b6 Reference \u00b6 Spark Github Building Spark Useful Developer Tools Using the ScalaTest Maven plugin SBT Testing Java \u751f\u4ea7\u73af\u5883 debug","title":"Spark \u6e90\u7801\u8c03\u8bd5"},{"location":"share/2019/spark-debug/#spark","text":"","title":"Spark \u6e90\u7801\u8c03\u8bd5"},{"location":"share/2019/spark-debug/#_1","text":"\u53ea\u6d89\u53ca Java \u53ca Scala \u4ee3\u7801\u7684\u7f16\u8bd1\u3001\u6d4b\u8bd5\u53ca\u8c03\u8bd5 macOS 10.14.5 Java 8u152 Scala 2.12.8 Maven 3.6.0 SBT 0.13.18 IDEA 2018.3.4 Spark 2.4.3","title":"\u73af\u5883"},{"location":"share/2019/spark-debug/#_2","text":"","title":"\u547d\u4ee4"},{"location":"share/2019/spark-debug/#_3","text":"maven ./build/mvn -DskipTests clean package ./build/mvn -pl :spark-core_2.12 -DskipTests clean package -am -pl \uff0c\u7f16\u8bd1\u6307\u5b9a\u6a21\u5757\uff0c{groupId}:{artifactId} \u6216\u662f dir_path -am \uff0c\u540c\u65f6\u7f16\u8bd1\u4f9d\u8d56\u6a21\u5757 ./dev/make-distribution.sh --tgz -Phadoop-2.7 -Phive -Phive-thriftserver -Pyarn -DskipTests sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false project core package","title":"\u7f16\u8bd1"},{"location":"share/2019/spark-debug/#_4","text":"maven ./build/mvn -pl :core ./build/mvn test -DwildcardSuites = none -Dtest = org.apache.spark.streaming.JavaAPISuite -DwildcardSuites \uff0c\u6307\u5b9a Scala \u6d4b\u8bd5 -Dtest \uff0c\u6307\u5b9a Java \u6d4b\u8bd5 ./build/mvn test -pl core -Dtest = none -Dsuites = '*DAGSchedulerSuite SPARK-3353' Scala Test \u4f7f\u7528\u901a\u914d\u7b26\u5339\u914d\uff1a\u7c7b\u3001\u65b9\u6cd5\u3001\u6d4b\u8bd5\u540d\u79f0 sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false project core test testOnly *DAGSchedulerSuite -- -z \"SPARK-3353\"","title":"\u6d4b\u8bd5"},{"location":"share/2019/spark-debug/#_5","text":"IDEA\uff1aRun > Edit Configurations > + > Remote > Host localhost \u3001Port 5005 \u3001Command -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 ./bin/spark-submit --driver-java-options \"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005\" --class org.apache.spark.examples.SparkPi examples/target/spark-examples_2.11-2.4.3-SNAPSHOT.jar Standalone \u6a21\u5f0f\uff0c\u53ef\u53ea\u542f\u52a8\u4e00\u4e2a Executor \u8fdb\u884c\u8c03\u8bd5 maven ./build/mvn test -pl core -Dtest = none -Dsuites = '*DAGSchedulerSuite' -DdebugForkedProcess = true -DdebuggerPort = 5005 -DdebugForkedProcess=true \uff0c\u5f00\u542f UT \u8c03\u8bd5\uff0c\u9ed8\u8ba4\u7aef\u53e3 5005 sbt ./build/sbt -Pscala-2.12 -Phive -Phive-thriftserver -Pyarn -Dhadoop-2.7 -DskipTests -Dsbt.override.build.repos = false -jvm-debug 5005 project core set fork in Test : = false testOnly org.apache.spark.scheduler.DAGSchedulerSuite -DdebugForkedProcess=true \uff0c\u5f00\u542f UT \u8c03\u8bd5\uff0c\u9ed8\u8ba4\u7aef\u53e3 5005","title":"\u8c03\u8bd5"},{"location":"share/2019/spark-debug/#_6","text":"","title":"\u95ee\u9898"},{"location":"share/2019/spark-debug/#reference","text":"Spark Github Building Spark Useful Developer Tools Using the ScalaTest Maven plugin SBT Testing Java \u751f\u4ea7\u73af\u5883 debug","title":"Reference"},{"location":"share/2019/spark-job-execution-process/","text":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u00b6 spark-submit \u68c0\u67e5 SPARK_HOME\uff0c\u63d0\u4ea4\u7ed9 spark-class\uff0c\u6307\u5b9a\u6267\u884c\u7c7b spark-class \u68c0\u67e5 SPARK_HOME\uff0c\u52a0\u8f7d Spark \u73af\u5883\u53d8\u91cf\uff0c\u68c0\u67e5 Java \u6267\u884c\u8def\u5f84\uff0c\u68c0\u67e5 Spark \u4f9d\u8d56\u8def\u5f84\uff0c\u62fc\u63a5\u547d\u4ee4\uff0c\u6267\u884c\u547d\u4ee4 launcher.Main \u62fc\u63a5\u547d\u4ee4\uff0c\u8f93\u51fa\u547d\u4ee4 deploy.SparkSubmit \u89e3\u6790\u53c2\u6570\uff0c\u51c6\u5907\u73af\u5883\uff0c\u8c03\u7528 child class main\uff08YARN Cluster \u6a21\u5f0f\u901a\u8fc7 yarn.Client\uff09 - createApplication - verifyClusterResources - createContainerLaunchContext/createApplicationSubmissionContext\uff08__app__.jar\u3001__spark_libs__\u3001__spark_conf__\u3001launch_container.sh ...\uff09 - submitApplication User Class Main SparkSession\u3001SparkContext Driver: runJob -> DAGScheduler#runJob, submitJob -> DAGSchedulerEventProcessLoop#doOnReceive(JobSubmitted) -> DAGScheduler#handleJobSubmitted, submitStage(Submits stage, but first recursively submits any missing parents, BFS.), submitMissingTasks -> TaskScheduler#submitTasks(TaskSet) -> CoarseGrainedSchedulerBackend#reviveOffers Executor: CoarseGrainedExecutorBackend#revive -> Executor#launchTask -> TaskRunner#run -> Task#run -> ShuffleMapTask(MapStatus), ResultTask(func():U)#runTask -> CoarseGrainedExecutorBackend#statusUpdate \u8d44\u6e90\u6ce8\u9500\u3001\u6e05\u7406 Reference \u00b6","title":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"share/2019/spark-job-execution-process/#spark-cluster-mode-on-yarn","text":"spark-submit \u68c0\u67e5 SPARK_HOME\uff0c\u63d0\u4ea4\u7ed9 spark-class\uff0c\u6307\u5b9a\u6267\u884c\u7c7b spark-class \u68c0\u67e5 SPARK_HOME\uff0c\u52a0\u8f7d Spark \u73af\u5883\u53d8\u91cf\uff0c\u68c0\u67e5 Java \u6267\u884c\u8def\u5f84\uff0c\u68c0\u67e5 Spark \u4f9d\u8d56\u8def\u5f84\uff0c\u62fc\u63a5\u547d\u4ee4\uff0c\u6267\u884c\u547d\u4ee4 launcher.Main \u62fc\u63a5\u547d\u4ee4\uff0c\u8f93\u51fa\u547d\u4ee4 deploy.SparkSubmit \u89e3\u6790\u53c2\u6570\uff0c\u51c6\u5907\u73af\u5883\uff0c\u8c03\u7528 child class main\uff08YARN Cluster \u6a21\u5f0f\u901a\u8fc7 yarn.Client\uff09 - createApplication - verifyClusterResources - createContainerLaunchContext/createApplicationSubmissionContext\uff08__app__.jar\u3001__spark_libs__\u3001__spark_conf__\u3001launch_container.sh ...\uff09 - submitApplication User Class Main SparkSession\u3001SparkContext Driver: runJob -> DAGScheduler#runJob, submitJob -> DAGSchedulerEventProcessLoop#doOnReceive(JobSubmitted) -> DAGScheduler#handleJobSubmitted, submitStage(Submits stage, but first recursively submits any missing parents, BFS.), submitMissingTasks -> TaskScheduler#submitTasks(TaskSet) -> CoarseGrainedSchedulerBackend#reviveOffers Executor: CoarseGrainedExecutorBackend#revive -> Executor#launchTask -> TaskRunner#run -> Task#run -> ShuffleMapTask(MapStatus), ResultTask(func():U)#runTask -> CoarseGrainedExecutorBackend#statusUpdate \u8d44\u6e90\u6ce8\u9500\u3001\u6e05\u7406","title":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"share/2019/spark-job-execution-process/#reference","text":"","title":"Reference"},{"location":"share/2019/spark-job-time-cost-analysis/","text":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 \u00b6 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u00b6 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u5916\u90e8\u5f71\u54cd \u00b6 \u5728\u7ebf\u8c03\u5ea6\u7cfb\u7edf\uff08e.g. Oozie\u3001Airflow\uff09 \u00b6 \u7528\u6237\u63d0\u4ea4\u4f5c\u4e1a\u5230\u5728\u7ebf\u5e94\u7528\u8c03\u5ea6\u7cfb\u7edf\uff0c\u7cfb\u7edf\u6839\u636e\u5e94\u7528\u6216\u7cfb\u7edf\u81ea\u8eab\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u5c06\u4f5c\u4e1a\u5206\u914d\u5230\u5bf9\u5e94\u5e94\u7528\u8c03\u5ea6\u961f\u5217\u6392\u961f\uff0c\u6267\u884c\u673a\u5c06\u4f5c\u4e1a\u63d0\u4ea4\u5230\u5bf9\u5e94\u7684\u96c6\u7fa4\u6216\u670d\u52a1\uff08\u8d44\u6e90\u8c03\u5ea6\u7cfb\u7edf\uff09 \u8d44\u6e90\u8c03\u5ea6\u7cfb\u7edf\uff08e.g. YARN\u3001Mesos\uff09 \u00b6 \u6839\u636e\u7ea6\u675f\u6761\u4ef6\uff0c\u8fdb\u5165\u5bf9\u5e94\u8d44\u6e90\u8c03\u5ea6\u961f\u5217\u6392\u961f\uff0c\u7533\u8bf7\u8d44\u6e90\uff0c\u542f\u52a8ApplicationMaster\uff0cApplicationMaster\u542f\u52a8Driver\uff0c\u7533\u8bf7\u8d44\u6e90\uff0c\u542f\u52a8Executor \u8d44\u6e90\u4e0d\u8db3\u65f6\uff0c\u6ee1\u8db3\u6700\u5c0f\u6ce8\u518c\u8d44\u6e90\u6bd4\u4f8b\u6216\u8fbe\u5230\u7b49\u5f85\u65f6\u95f4\uff0c\u5f00\u59cb\u6267\u884c \u5143\u6570\u636e\u7cfb\u7edf\uff08e.g. Hive Metastore\uff09 \u00b6 \u6a21\u578b\u5143\u6570\u636e\u4fe1\u606f\uff0cCatalog\uff08e.g. databases\u3001tables\u3001columns,\u3001partitions\u3001functions) \u5b58\u50a8\u7cfb\u7edf\uff08e.g. HDFS\u3001Alluxio\uff09 \u00b6 input\uff08get splits\uff09\uff1a\u5927\u6587\u4ef6\u5206\u5272\u95ee\u9898\uff1boutput\uff08commit job\uff09\uff1a\u5c0f\u6587\u4ef6\u5b58\u50a8\u95ee\u9898 \u6587\u4ef6\u683c\u5f0f\uff1aORC\u3001Parquet \u6743\u9650/\u5ba1\u8ba1\uff08e.g. Ranger\u3001Sentry\uff09 \u00b6 \u9274\u6743\uff1a\u8d44\u6e90\u63a7\u5236\u7c92\u5ea6\u3001\u9274\u6743\u65f6\u673a \u5ba1\u8ba1 \u5185\u90e8\u673a\u5236 \u00b6 \u8c03\u5ea6 \u00b6 Job Stage Task Shuffle Service \u00b6 read\uff08remote\u3001local\uff09 write DataSource V2 \u00b6 input\uff08get splits\uff09\uff1a\u5927\u6587\u4ef6\u5206\u5272\u95ee\u9898 output\uff08commit job\uff09\uff1a\u5c0f\u6587\u4ef6\u5b58\u50a8\u95ee\u9898 \u7279\u6027 Filter Push Partitioning Transactional \u4efb\u52a1 \u00b6 \u8d44\u6e90\u4e0d\u5145\u8db3\uff1a\u8c03\u5ea6\u5ef6\u8fdf\u3001\u8d44\u6e90\u4f7f\u7528\u7387\u9ad8 \u5e8f\u5217\u5316\u4e0e\u53cd\u5e8f\u5217\u5316\uff1a\u8c03\u6574\u5e8f\u5217\u5316 \u590d\u6742\u8ba1\u7b97\uff1a\u5206\u6bb5\u8ba1\u7b97 \u6570\u636e\u8bb0\u5f55\u6570\u91cf\u5927\uff1a\u63d0\u9ad8\u5e76\u884c\u5ea6 \u6570\u636e\u8bb0\u5f55\u5b58\u50a8\u5927\uff1a\u51cf\u5c11\u5197\u4f59\u4fe1\u606f \u6570\u636e\u503e\u659c\uff08TODO\uff09\uff1a\u52a0\u76d0\u3001\u5206\u7ec4 \u5176\u4ed6 \u00b6 GC \u672c\u5730\u5316 \u8d44\u6e90\u4f7f\u7528\u7387 \u8d85\u65f6\u4e0e\u91cd\u8bd5 \u5ea6\u91cf \u00b6 \u503e\u659c \u65f6\u95f4\u503e\u659c\uff08\u6570\u636e\u503e\u659c\u3001\u6162\u8282\u70b9\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38\uff09 \u6570\u636e\u503e\u659c\uff08\u5927\u5c0f\u3001\u6570\u91cf\uff09 Reference \u00b6","title":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790"},{"location":"share/2019/spark-job-time-cost-analysis/#spark","text":"","title":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790"},{"location":"share/2019/spark-job-time-cost-analysis/#spark-cluster-mode-on-yarn","text":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09","title":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#_1","text":"","title":"\u5916\u90e8\u5f71\u54cd"},{"location":"share/2019/spark-job-time-cost-analysis/#eg-oozieairflow","text":"\u7528\u6237\u63d0\u4ea4\u4f5c\u4e1a\u5230\u5728\u7ebf\u5e94\u7528\u8c03\u5ea6\u7cfb\u7edf\uff0c\u7cfb\u7edf\u6839\u636e\u5e94\u7528\u6216\u7cfb\u7edf\u81ea\u8eab\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u5c06\u4f5c\u4e1a\u5206\u914d\u5230\u5bf9\u5e94\u5e94\u7528\u8c03\u5ea6\u961f\u5217\u6392\u961f\uff0c\u6267\u884c\u673a\u5c06\u4f5c\u4e1a\u63d0\u4ea4\u5230\u5bf9\u5e94\u7684\u96c6\u7fa4\u6216\u670d\u52a1\uff08\u8d44\u6e90\u8c03\u5ea6\u7cfb\u7edf\uff09","title":"\u5728\u7ebf\u8c03\u5ea6\u7cfb\u7edf\uff08e.g. Oozie\u3001Airflow\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#eg-yarnmesos","text":"\u6839\u636e\u7ea6\u675f\u6761\u4ef6\uff0c\u8fdb\u5165\u5bf9\u5e94\u8d44\u6e90\u8c03\u5ea6\u961f\u5217\u6392\u961f\uff0c\u7533\u8bf7\u8d44\u6e90\uff0c\u542f\u52a8ApplicationMaster\uff0cApplicationMaster\u542f\u52a8Driver\uff0c\u7533\u8bf7\u8d44\u6e90\uff0c\u542f\u52a8Executor \u8d44\u6e90\u4e0d\u8db3\u65f6\uff0c\u6ee1\u8db3\u6700\u5c0f\u6ce8\u518c\u8d44\u6e90\u6bd4\u4f8b\u6216\u8fbe\u5230\u7b49\u5f85\u65f6\u95f4\uff0c\u5f00\u59cb\u6267\u884c","title":"\u8d44\u6e90\u8c03\u5ea6\u7cfb\u7edf\uff08e.g. YARN\u3001Mesos\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#eg-hive-metastore","text":"\u6a21\u578b\u5143\u6570\u636e\u4fe1\u606f\uff0cCatalog\uff08e.g. databases\u3001tables\u3001columns,\u3001partitions\u3001functions)","title":"\u5143\u6570\u636e\u7cfb\u7edf\uff08e.g. Hive Metastore\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#eg-hdfsalluxio","text":"input\uff08get splits\uff09\uff1a\u5927\u6587\u4ef6\u5206\u5272\u95ee\u9898\uff1boutput\uff08commit job\uff09\uff1a\u5c0f\u6587\u4ef6\u5b58\u50a8\u95ee\u9898 \u6587\u4ef6\u683c\u5f0f\uff1aORC\u3001Parquet","title":"\u5b58\u50a8\u7cfb\u7edf\uff08e.g. HDFS\u3001Alluxio\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#eg-rangersentry","text":"\u9274\u6743\uff1a\u8d44\u6e90\u63a7\u5236\u7c92\u5ea6\u3001\u9274\u6743\u65f6\u673a \u5ba1\u8ba1","title":"\u6743\u9650/\u5ba1\u8ba1\uff08e.g. Ranger\u3001Sentry\uff09"},{"location":"share/2019/spark-job-time-cost-analysis/#_2","text":"","title":"\u5185\u90e8\u673a\u5236"},{"location":"share/2019/spark-job-time-cost-analysis/#_3","text":"Job Stage Task","title":"\u8c03\u5ea6"},{"location":"share/2019/spark-job-time-cost-analysis/#shuffle-service","text":"read\uff08remote\u3001local\uff09 write","title":"Shuffle Service"},{"location":"share/2019/spark-job-time-cost-analysis/#datasource-v2","text":"input\uff08get splits\uff09\uff1a\u5927\u6587\u4ef6\u5206\u5272\u95ee\u9898 output\uff08commit job\uff09\uff1a\u5c0f\u6587\u4ef6\u5b58\u50a8\u95ee\u9898 \u7279\u6027 Filter Push Partitioning Transactional","title":"DataSource V2"},{"location":"share/2019/spark-job-time-cost-analysis/#_4","text":"\u8d44\u6e90\u4e0d\u5145\u8db3\uff1a\u8c03\u5ea6\u5ef6\u8fdf\u3001\u8d44\u6e90\u4f7f\u7528\u7387\u9ad8 \u5e8f\u5217\u5316\u4e0e\u53cd\u5e8f\u5217\u5316\uff1a\u8c03\u6574\u5e8f\u5217\u5316 \u590d\u6742\u8ba1\u7b97\uff1a\u5206\u6bb5\u8ba1\u7b97 \u6570\u636e\u8bb0\u5f55\u6570\u91cf\u5927\uff1a\u63d0\u9ad8\u5e76\u884c\u5ea6 \u6570\u636e\u8bb0\u5f55\u5b58\u50a8\u5927\uff1a\u51cf\u5c11\u5197\u4f59\u4fe1\u606f \u6570\u636e\u503e\u659c\uff08TODO\uff09\uff1a\u52a0\u76d0\u3001\u5206\u7ec4","title":"\u4efb\u52a1"},{"location":"share/2019/spark-job-time-cost-analysis/#_5","text":"GC \u672c\u5730\u5316 \u8d44\u6e90\u4f7f\u7528\u7387 \u8d85\u65f6\u4e0e\u91cd\u8bd5","title":"\u5176\u4ed6"},{"location":"share/2019/spark-job-time-cost-analysis/#_6","text":"\u503e\u659c \u65f6\u95f4\u503e\u659c\uff08\u6570\u636e\u503e\u659c\u3001\u6162\u8282\u70b9\u3001\u4f9d\u8d56\u670d\u52a1\u5f02\u5e38\uff09 \u6570\u636e\u503e\u659c\uff08\u5927\u5c0f\u3001\u6570\u91cf\uff09","title":"\u5ea6\u91cf"},{"location":"share/2019/spark-job-time-cost-analysis/#reference","text":"","title":"Reference"},{"location":"share/2019/spark-shuffle-service/","text":"Spark Shuffle Service \u00b6 \u5728\u8fdb\u884c Shuffle \u8fc7\u7a0b\uff0c\u4e0a\u6e38 Executor Mapper \u9636\u6bb5\uff0c\u5c06\u6570\u636e\u5199\u5230\u672c\u5730\u78c1\u76d8\uff0c\u4e0b\u6e38 Executor Reducer \u9636\u6bb5\uff0c\u901a\u8fc7\u4e0a\u6e38 Executor \u62c9\u53d6\u6570\u636e\uff1b\u5c24\u5176\u5728\u52a8\u6001\u8d44\u6e90\u5206\u914d\u60c5\u5f62\u4e0b\uff0cExecutor \u53ef\u80fd\u88ab\u79fb\u9664\u6216\u62a2\u5360\uff0c\u5c31\u9700\u8981\u91cd\u7b97\u8fd9\u90e8\u5206\u6570\u636e \u5728 YARN \u8c03\u5ea6\u6a21\u5f0f\u4e0b\uff0c\u901a\u8fc7\u5728 NodeManager \u4e0a\u542f\u52a8 YarnShuffleService\uff08ExternalShuffleService\uff09 \u957f\u65f6\u8f85\u52a9\u670d\u52a1\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684 Shuffle \u670d\u52a1\uff0c\u4f18\u96c5\u5730\u5173\u95ed Executor\uff0c\u5e76\u4fdd\u7559\u5176\u72b6\u6001 Shuffle \u8fc7\u7a0b\u53d8\u4e3a\uff1a\u4e0a\u6e38 Executor Mapper \u9636\u6bb5\uff0c\u5411\u672c\u5730 Shuffle Service \u6ce8\u518c\uff0c\u5c06\u6570\u636e\u5199\u5230\u672c\u5730\u78c1\u76d8\uff0c\u5c31\u53ef\u4ee5\u9000\u51fa\uff1b\u4e0b\u6e38 Executor Reducer \u901a\u8fc7\u4e0a\u6e38 Executor \u7684 Shuffle Service \u62c9\u53d6\u6570\u636e \u76ee\u524d\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u4e09\u79cd\u5b9e\u73b0\uff1a ExternalShuffleService\uff08Standalone\uff09 YarnShuffleService\uff08YARN\uff09 MesosExternalShuffleService\uff08Mesos\uff09 \u91cd\u8981\u7ec4\u4ef6\uff08YARN \u6a21\u5f0f\uff09 \u00b6 YarnShuffleService\uff1aNodeManager \u542f\u52a8\u7684 Spark Shuffle Service \u957f\u65f6\u8f85\u52a9\u670d\u52a1\uff0c\u7ba1\u7406\u4f5c\u4e1a\u3001\u670d\u52a1\u3001\u6062\u590d TransportServer\uff1a\u5b9e\u9645\u63d0\u4f9b Shuffle \u7684\u670d\u52a1 ExternalShuffleBlockHandler\uff1aTransportServer \u7684 blockHandler\uff0c\u5904\u7406 RPC \u8bf7\u6c42 \u7279\u70b9\u4e0e\u95ee\u9898\uff08YARN \u6a21\u5f0f\uff09 \u00b6 \u6570\u636e\u5b58\u50a8\u5728\u672c\u5730\u78c1\u76d8\uff0c\u6ca1\u6709\u5907\u4efd IO \u5e76\u53d1\uff1a\u5927\u91cf RPC \u8bf7\u6c42\uff08M*R\uff09 IO \u541e\u5410\uff1a\u70ed\u70b9\u6570\u636e\u3001\u968f\u673a\u8bfb\u3001\u5199\u653e\u5927\uff083X\uff09 GC \u9891\u7e41\uff0c\u5f71\u54cd NodeManager \u4f18\u5316\u601d\u8def \u00b6 \u6570\u636e\u5bb9\u9519\uff1aS3\u3001\u526f\u672c\u3001WAL \u670d\u52a1\u5bb9\u9519\uff1a\u8d1f\u8f7d\u5747\u8861\u3001Failover IO\u4f18\u5316\uff1a\u589e\u5927block\u3001\u51cf\u5c11\u968f\u673a\u8bfb GC\u8c03\u4f18 \u6d41\u63a7\uff1a\u670d\u52a1\u7aef\u3001\u5ba2\u6237\u7aef\uff08\u907f\u514d\u5931\u8d25\uff09 \u76d1\u63a7\u544a\u8b66 \u4e0eNodeManager\u9694\u79bb Reference \u00b6 Cosco: An Efficient Facebook-Scale Shuffle Service","title":"Spark Shuffle Service"},{"location":"share/2019/spark-shuffle-service/#spark-shuffle-service","text":"\u5728\u8fdb\u884c Shuffle \u8fc7\u7a0b\uff0c\u4e0a\u6e38 Executor Mapper \u9636\u6bb5\uff0c\u5c06\u6570\u636e\u5199\u5230\u672c\u5730\u78c1\u76d8\uff0c\u4e0b\u6e38 Executor Reducer \u9636\u6bb5\uff0c\u901a\u8fc7\u4e0a\u6e38 Executor \u62c9\u53d6\u6570\u636e\uff1b\u5c24\u5176\u5728\u52a8\u6001\u8d44\u6e90\u5206\u914d\u60c5\u5f62\u4e0b\uff0cExecutor \u53ef\u80fd\u88ab\u79fb\u9664\u6216\u62a2\u5360\uff0c\u5c31\u9700\u8981\u91cd\u7b97\u8fd9\u90e8\u5206\u6570\u636e \u5728 YARN \u8c03\u5ea6\u6a21\u5f0f\u4e0b\uff0c\u901a\u8fc7\u5728 NodeManager \u4e0a\u542f\u52a8 YarnShuffleService\uff08ExternalShuffleService\uff09 \u957f\u65f6\u8f85\u52a9\u670d\u52a1\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684 Shuffle \u670d\u52a1\uff0c\u4f18\u96c5\u5730\u5173\u95ed Executor\uff0c\u5e76\u4fdd\u7559\u5176\u72b6\u6001 Shuffle \u8fc7\u7a0b\u53d8\u4e3a\uff1a\u4e0a\u6e38 Executor Mapper \u9636\u6bb5\uff0c\u5411\u672c\u5730 Shuffle Service \u6ce8\u518c\uff0c\u5c06\u6570\u636e\u5199\u5230\u672c\u5730\u78c1\u76d8\uff0c\u5c31\u53ef\u4ee5\u9000\u51fa\uff1b\u4e0b\u6e38 Executor Reducer \u901a\u8fc7\u4e0a\u6e38 Executor \u7684 Shuffle Service \u62c9\u53d6\u6570\u636e \u76ee\u524d\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u4e09\u79cd\u5b9e\u73b0\uff1a ExternalShuffleService\uff08Standalone\uff09 YarnShuffleService\uff08YARN\uff09 MesosExternalShuffleService\uff08Mesos\uff09","title":"Spark Shuffle Service"},{"location":"share/2019/spark-shuffle-service/#yarn","text":"YarnShuffleService\uff1aNodeManager \u542f\u52a8\u7684 Spark Shuffle Service \u957f\u65f6\u8f85\u52a9\u670d\u52a1\uff0c\u7ba1\u7406\u4f5c\u4e1a\u3001\u670d\u52a1\u3001\u6062\u590d TransportServer\uff1a\u5b9e\u9645\u63d0\u4f9b Shuffle \u7684\u670d\u52a1 ExternalShuffleBlockHandler\uff1aTransportServer \u7684 blockHandler\uff0c\u5904\u7406 RPC \u8bf7\u6c42","title":"\u91cd\u8981\u7ec4\u4ef6\uff08YARN \u6a21\u5f0f\uff09"},{"location":"share/2019/spark-shuffle-service/#yarn_1","text":"\u6570\u636e\u5b58\u50a8\u5728\u672c\u5730\u78c1\u76d8\uff0c\u6ca1\u6709\u5907\u4efd IO \u5e76\u53d1\uff1a\u5927\u91cf RPC \u8bf7\u6c42\uff08M*R\uff09 IO \u541e\u5410\uff1a\u70ed\u70b9\u6570\u636e\u3001\u968f\u673a\u8bfb\u3001\u5199\u653e\u5927\uff083X\uff09 GC \u9891\u7e41\uff0c\u5f71\u54cd NodeManager","title":"\u7279\u70b9\u4e0e\u95ee\u9898\uff08YARN \u6a21\u5f0f\uff09"},{"location":"share/2019/spark-shuffle-service/#_1","text":"\u6570\u636e\u5bb9\u9519\uff1aS3\u3001\u526f\u672c\u3001WAL \u670d\u52a1\u5bb9\u9519\uff1a\u8d1f\u8f7d\u5747\u8861\u3001Failover IO\u4f18\u5316\uff1a\u589e\u5927block\u3001\u51cf\u5c11\u968f\u673a\u8bfb GC\u8c03\u4f18 \u6d41\u63a7\uff1a\u670d\u52a1\u7aef\u3001\u5ba2\u6237\u7aef\uff08\u907f\u514d\u5931\u8d25\uff09 \u76d1\u63a7\u544a\u8b66 \u4e0eNodeManager\u9694\u79bb","title":"\u4f18\u5316\u601d\u8def"},{"location":"share/2019/spark-shuffle-service/#reference","text":"Cosco: An Efficient Facebook-Scale Shuffle Service","title":"Reference"},{"location":"share/2019/spark-sql-rules/","text":"Spark SQL \u89c4\u5219 \u00b6 Analyzer \u00b6 lazy val batches : Seq [ Batch ] = Seq ( Batch ( \"Hints\" , fixedPoint , new ResolveHints . ResolveJoinStrategyHints ( conf ), // BROADCAST\u3001SHUFFLE_MERGE\u3001SHUFFLE_HASH\u3001SHUFFLE_REPLICATE_NL ResolveHints . ResolveCoalesceHints , // COALESCE\u3001REPARTITION new ResolveHints . RemoveAllHints ( conf )), // \u79fb\u9664\u65e0\u6548 Hint Batch ( \"Simple Sanity Check\" , Once , LookupFunctions ), // \u68c0\u67e5 Function \u662f\u5426\u5b58\u5728 Batch ( \"Substitution\" , fixedPoint , CTESubstitution , // CTE \u66ff\u6362 WindowsSubstitution , // Window \u66ff\u6362 EliminateUnions , // \u6d88\u9664 Union\uff08\u53ea\u6709\u4e00\u4e2a\u65f6\uff09 new SubstituteUnresolvedOrdinals ( conf )), // \u66ff\u6362 order by\u3001group by \u5e8f\u53f7 Batch ( \"Resolution\" , fixedPoint , ResolveTableValuedFunctions :: // \u6570\u636e\u8868\u51fd\u6570\uff0crange ResolveAlterTable :: // ALTER TABLE v2 ResolveTables :: // Table v2\uff0c\u8868 ResolveRelations :: // Table v1 ResolveReferences :: // Reference \u5217 ResolveCreateNamedStruct :: // named_struct ResolveDeserializer :: // Deserializer \u53cd\u5e8f\u5217\u5316 ResolveNewInstance :: // \u6784\u9020\u5b9e\u4f8b ResolveUpCast :: // \u7c7b\u578b\u8f6c\u6362 ResolveGroupingAnalytics :: // \u591a\u7ef4\u5206\u6790\uff0cGroupingSets/Cube/Rollup ResolvePivot :: // \u900f\u89c6\uff0c\u884c\u5217\u8f6c\u6362 ResolveOrdinalInOrderByAndGroupBy :: // \u5e8f\u53f7\uff0corder/sort by\u3001group by ResolveAggAliasInGroupBy :: // \u805a\u5408\u4e2d\u7684\u522b\u540d\uff0cgroup by\u3001grouping sets ResolveMissingReferences :: // \u8865\u5145\u7f3a\u5931\u7684 Reference\uff0csort by\u3001having ExtractGenerator :: // \u63d0\u53d6\u751f\u6210\u5668\uff0cexplode ResolveGenerate :: // \u751f\u6210\u5668 ResolveFunctions :: // Function\uff0c\u51fd\u6570 ResolveAliases :: // Alias\uff0c\u522b\u540d ResolveSubquery :: // \u5b50\u67e5\u8be2 ResolveSubqueryColumnAliases :: // \u5b50\u67e5\u8be2\u522b\u540d ResolveWindowOrder :: // Window Order ResolveWindowFrame :: // Window Frame ResolveNaturalAndUsingJoin :: // \u4f7f\u7528 Join \u66ff\u6362 Natural \u5f62\u5f0f ResolveOutputRelation :: // \u5904\u7406 \u8f93\u51fa\u6570\u636e\u548c\u8868\u7684\u5dee\u5f02 ExtractWindowExpressions :: // \u63d0\u53d6 Window GlobalAggregates :: // \u5168\u5c40\u805a\u5408 ResolveAggregateFunctions :: // \u805a\u5408\u51fd\u6570 TimeWindowing :: // \u6ed1\u52a8\u65f6\u95f4\u7a97\u53e3 ResolveInlineTables ( conf ) :: // \u5185\u8054\u8868 VALUES() ResolveHigherOrderFunctions ( catalog ) :: // higher order function\uff0clambda function ResolveLambdaVariables ( conf ) :: // lambda function \u53c2\u6570 ResolveTimeZone ( conf ) :: // TimeZone ResolveRandomSeed :: // \u968f\u673a\u6570\u751f\u6210 TypeCoercion . typeCoercionRules ( conf ) ++ // \u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 extendedResolutionRules : _ * ), // \u6269\u5c55\u89c4\u5219 Batch ( \"Post-Hoc Resolution\" , Once , postHocResolutionRules : _ * ), // \u6269\u5c55\u89c4\u5219 Batch ( \"Nondeterministic\" , Once , PullOutNondeterministic ), // \u975e\u786e\u5b9a\u6027\u8868\u8fbe\u5f0f Batch ( \"UDF\" , Once , HandleNullInputsForUDF ), // \u5904\u7406\u4e3a null \u7684\u8f93\u5165 Batch ( \"UpdateNullability\" , Once , UpdateAttributeNullability ), // \u66f4\u65b0\u53ef\u4ee5\u4e3a\u7a7a\u5c5e\u6027 Batch ( \"Subquery\" , Once , UpdateOuterReferences ), // \u5904\u7406\u5b50\u67e5\u8be2\u7684\u5916\u90e8\u5f15\u7528 Batch ( \"Cleanup\" , fixedPoint , CleanupAliases ) // \u6e05\u7406\u6ca1\u5fc5\u8981\u7684\u522b\u540d ) Optimizer \u00b6 /** * Defines the default rule batches in the Optimizer. * * Implementations of this class should override this method, and [[nonExcludableRules]] if * necessary, instead of [[batches]]. The rule batches that eventually run in the Optimizer, * i.e., returned by [[batches]], will be (defaultBatches - (excludedRules - nonExcludableRules)). */ def defaultBatches : Seq [ Batch ] = { val operatorOptimizationRuleSet = Seq ( // Operator push down PushProjectionThroughUnion , // \u5bf9\u4e8e\u5168\u90e8\u662f\u786e\u5b9a\u6027 Project \u8fdb\u884c\u4e0b\u63a8 ReorderJoin , // \u6839\u636e Join \u5173\u8054\u6761\u4ef6\uff0c\u8fdb\u884c\u987a\u5e8f\u91cd\u6392 EliminateOuterJoin , // \u6d88\u9664\u975e\u7a7a\u7ea6\u675f\u7684 Outer Join PushDownPredicates , // \u8c13\u8bcd\u4e0b\u63a8 PushDownLeftSemiAntiJoin , // Project\u3001Window\u3001Union\u3001Aggregate\u3001PushPredicateThroughNonJoin \u573a\u666f\u4e0b\uff0c\u4e0b\u63a8 LeftSemi/LeftAnti PushLeftSemiLeftAntiThroughJoin , // Join \u573a\u666f\u4e0b\uff0c\u4e0b\u63a8 LeftSemi/LeftAnti LimitPushDown , // Limit \u4e0b\u63a8 ColumnPruning , // \u5217\u88c1\u526a InferFiltersFromConstraints , // \u6839\u636e\u7ea6\u675f\u63a8\u65ad Filter \u4fe1\u606f // Operator combine CollapseRepartition , // \u5408\u5e76 Repartition CollapseProject , // \u5408\u5e76 Project CollapseWindow , // \u5408\u5e76 Window\uff08\u76f8\u540c\u7684\u5206\u533a\u53ca\u6392\u5e8f\uff09 CombineFilters , // \u5408\u5e76 Filter CombineLimits , // \u5408\u5e76 Limit CombineUnions , // \u5408\u5e76 Union // Constant folding and strength reduction TransposeWindow , // \u8f6c\u7f6e Window\uff0c\u4f18\u5316\u8ba1\u7b97 NullPropagation , // Null \u4f20\u9012 ConstantPropagation , // \u5e38\u91cf\u4f20\u9012 FoldablePropagation , // \u53ef\u6298\u53e0\u5b57\u6bb5\u3001\u5c5e\u6027\u4f20\u64ad OptimizeIn , // \u4f18\u5316 In\uff0c\u7a7a\u5904\u7406\u3001\u91cd\u590d\u5904\u7406 ConstantFolding , // \u5e38\u91cf\u6298\u53e0 ReorderAssociativeOperator , // \u6392\u5e8f\u4e0e\u6298\u53e0\u53d8\u91cf LikeSimplification , // \u4f18\u5316 Like \u5bf9\u5e94\u7684\u6b63\u5219 BooleanSimplification , // \u7b80\u5316 Boolean \u8868\u8fbe\u5f0f SimplifyConditionals , // \u7b80\u5316\u6761\u4ef6\u8868\u8fbe\u5f0f\uff0cif/case RemoveDispensableExpressions , // \u79fb\u9664\u4e0d\u5fc5\u8981\u7684\u8282\u70b9\uff0cpositive SimplifyBinaryComparison , // \u4f18\u5316\u6bd4\u8f83\u8868\u8fbe\u5f0f\u4e3a Boolean Literal ReplaceNullWithFalseInPredicate , // \u4f18\u5316 Null \u573a\u666f Literal PruneFilters , // \u88c1\u526a\u660e\u786e\u7684\u8fc7\u6ee4\u6761\u4ef6 EliminateSorts , // \u6d88\u9664 Sort\uff0c\u65e0\u5173\u6216\u91cd\u590d SimplifyCasts , // \u7b80\u5316 Cast\uff0c\u7c7b\u578b\u5339\u914d SimplifyCaseConversionExpressions , // \u7b80\u5316 \u53e0\u52a0\u7684\u5927\u5c0f\u5199\u8f6c\u6362 RewriteCorrelatedScalarSubquery , // \u5b50\u67e5\u8be2\u6539\u5199\u4e3a Join EliminateSerialization , // \u6d88\u9664 \u5e8f\u5217\u5316 RemoveRedundantAliases , // \u5220\u9664\u5197\u4f59\u7684\u522b\u540d RemoveNoopOperators , // \u5220\u9664\u6ca1\u6709\u64cd\u4f5c\u7684\u64cd\u4f5c\u7b26 SimplifyExtractValueOps , // \u7b80\u5316\u7b26\u5408\u7c7b\u578b\u64cd\u4f5c\u7b26 CombineConcats ) ++ // \u5408\u5e76 Concat \u8868\u8fbe\u5f0f extendedOperatorOptimizationRules // \u6269\u5c55\u89c4\u5219 val operatorOptimizationBatch : Seq [ Batch ] = { val rulesWithoutInferFiltersFromConstraints = operatorOptimizationRuleSet . filterNot ( _ == InferFiltersFromConstraints ) Batch ( \"Operator Optimization before Inferring Filters\" , fixedPoint , rulesWithoutInferFiltersFromConstraints : _ * ) :: Batch ( \"Infer Filters\" , Once , InferFiltersFromConstraints ) :: Batch ( \"Operator Optimization after Inferring Filters\" , fixedPoint , rulesWithoutInferFiltersFromConstraints : _ * ) :: Nil } ( Batch ( \"Eliminate Distinct\" , Once , EliminateDistinct ) :: // \u6d88\u9664\u805a\u5408\u4e2d\u5197\u4f59\u7684 Distinct // Technically some of the rules in Finish Analysis are not optimizer rules and belong more // in the analyzer, because they are needed for correctness (e.g. ComputeCurrentTime). // However, because we also use the analyzer to canonicalized queries (for view definition), // we do not eliminate subqueries or compute current time in the analyzer. Batch ( \"Finish Analysis\" , Once , EliminateResolvedHint , // \u901a\u8fc7 Join \u6539\u5199 Hint EliminateSubqueryAliases , // \u6d88\u9664 \u5b50\u67e5\u8be2\u522b\u540d EliminateView , // \u6d88\u9664 \u89c6\u56fe ReplaceExpressions , // \u66ff\u6362\u3001\u6539\u5199 \u8868\u8fbe\u5f0f ComputeCurrentTime , // \u8ba1\u7b97\u5f53\u524d\u65e5\u671f\u6216\u65f6\u95f4 GetCurrentDatabase ( sessionCatalog ), // \u66ff\u6362\u5f53\u524d\u7684\u6570\u636e\u5e93 RewriteDistinctAggregates , // Distinct \u4f18\u5316\u6539\u5199 ReplaceDeduplicateWithAggregate ) :: // \u901a\u8fc7\u805a\u5408\u4f18\u5316\u5220\u9664\u91cd\u590d\u6570\u636e\u7b97\u5b50 ////////////////////////////////////////////////////////////////////////////////////////// // Optimizer rules start here ////////////////////////////////////////////////////////////////////////////////////////// // - Do the first call of CombineUnions before starting the major Optimizer rules, // since it can reduce the number of iteration and the other rules could add/move // extra operators between two adjacent Union operators. // - Call CombineUnions again in Batch(\"Operator Optimizations\"), // since the other rules might make two separate Unions operators adjacent. Batch ( \"Union\" , Once , CombineUnions ) :: // \u5408\u5e76\u76f8\u90bb\u7684 Union Batch ( \"OptimizeLimitZero\" , Once , OptimizeLimitZero ) :: // \u4f18\u5316 limit 0 // Run this once earlier. This might simplify the plan and reduce cost of optimizer. // For example, a query such as Filter(LocalRelation) would go through all the heavy // optimizer rules that are triggered when there is a filter // (e.g. InferFiltersFromConstraints). If we run this batch earlier, the query becomes just // LocalRelation and does not trigger many rules. Batch ( \"LocalRelation early\" , fixedPoint , ConvertToLocalRelation , // \u4f18\u5316 LocalRelation PropagateEmptyRelation ) :: // \u4f18\u5316 EmptyRelation Batch ( \"Pullup Correlated Expressions\" , Once , PullupCorrelatedPredicates ) :: // \u5904\u7406\u5f15\u7528\u5916\u90e8\u8c13\u8bcd Batch ( \"Subquery\" , Once , OptimizeSubqueries ) :: // \u4f18\u5316 \u5b50\u67e5\u8be2\uff0c\u53bb\u9664\u4e0d\u5fc5\u8981\u6392\u5e8f Batch ( \"Replace Operators\" , fixedPoint , RewriteExceptAll , // \u91cd\u5199 Except All RewriteIntersectAll , // \u91cd\u5199 Intersect All ReplaceIntersectWithSemiJoin , // \u4f7f\u7528 Semi Join\uff0c\u91cd\u5199 Intersect ReplaceExceptWithFilter , // \u4f7f\u7528 Filter\uff0c\u91cd\u5199 Except ReplaceExceptWithAntiJoin , // \u4f7f\u7528 Anti Join\uff0c\u91cd\u5199 Except ReplaceDistinctWithAggregate ) :: // \u4f7f\u7528 Aggregate\uff0c\u91cd\u5199 Distinct Batch ( \"Aggregate\" , fixedPoint , RemoveLiteralFromGroupExpressions , // \u5220\u9664\u805a\u5408\u8868\u8fbe\u5f0f\u7684\u5b57\u9762\u91cf RemoveRepetitionFromGroupExpressions ) :: Nil ++ // \u5220\u9664\u805a\u5408\u8868\u8fbe\u5f0f\u7684\u91cd\u590d\u4fe1\u606f operatorOptimizationBatch ) :+ Batch ( \"Join Reorder\" , Once , CostBasedJoinReorder ) :+ // \u57fa\u4e8e\u635f\u5931\u7684 Join \u91cd\u6392 Batch ( \"Remove Redundant Sorts\" , Once , RemoveRedundantSorts ) :+ // \u5220\u9664\u5197\u4f59\u7684\u6392\u5e8f Batch ( \"Decimal Optimizations\" , fixedPoint , DecimalAggregates ) :+ // Decimal \u7c7b\u578b\u805a\u5408\u4f18\u5316 Batch ( \"Object Expressions Optimization\" , fixedPoint , EliminateMapObjects , // \u6d88\u9664 MapObject CombineTypedFilters , // \u5408\u5e76\u76f8\u90bb\u7684\u7c7b\u578b\u8fc7\u6ee4 ObjectSerializerPruning , // \u88c1\u526a\u4e0d\u5fc5\u8981\u7684\u5e8f\u5217\u5316 ReassignLambdaVariableID ) :+ // \u91cd\u65b0\u5206\u7c7b LambdaVariable ID\uff0c\u5229\u4e8e codegen \u4f18\u5316 Batch ( \"LocalRelation\" , fixedPoint , ConvertToLocalRelation , // \u4f18\u5316 LocalRelation PropagateEmptyRelation ) :+ // \u4f18\u5316 EmptyRelation Batch ( \"Extract PythonUDF From JoinCondition\" , Once , PullOutPythonUDFInJoinCondition ) :+ // \u6807\u8bc6 Join \u4e2d\u7684 PythonUDF // The following batch should be executed after batch \"Join Reorder\" \"LocalRelation\" and // \"Extract PythonUDF From JoinCondition\". Batch ( \"Check Cartesian Products\" , Once , CheckCartesianProducts ) :+ // \u68c0\u6d4b \u7b1b\u5361\u5c14\u79ef \u7ea6\u675f\u6761\u4ef6 Batch ( \"RewriteSubquery\" , Once , RewritePredicateSubquery , // \u91cd\u5199 \u5b50\u67e5\u8be2\uff0cEXISTS/NOT EXISTS\u3001IN/NOT IN ColumnPruning , // \u88c1\u526a\u5217 CollapseProject , // \u5408\u5e76\u6295\u5f71 RemoveNoopOperators ) :+ // \u5220\u9664\u65e0\u7528\u7684\u64cd\u4f5c\u7b26 // This batch must be executed after the `RewriteSubquery` batch, which creates joins. Batch ( \"NormalizeFloatingNumbers\" , Once , NormalizeFloatingNumbers ) // \u89c4\u8303 Float \u7c7b\u578b\u6570\u503c } SparkPlan \u00b6 SparkStrategy \u00b6 Reference \u00b6 \u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e0a\uff09 \u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e2d\uff09 \u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e0b\uff09","title":"Spark SQL \u89c4\u5219"},{"location":"share/2019/spark-sql-rules/#spark-sql","text":"","title":"Spark SQL \u89c4\u5219"},{"location":"share/2019/spark-sql-rules/#analyzer","text":"lazy val batches : Seq [ Batch ] = Seq ( Batch ( \"Hints\" , fixedPoint , new ResolveHints . ResolveJoinStrategyHints ( conf ), // BROADCAST\u3001SHUFFLE_MERGE\u3001SHUFFLE_HASH\u3001SHUFFLE_REPLICATE_NL ResolveHints . ResolveCoalesceHints , // COALESCE\u3001REPARTITION new ResolveHints . RemoveAllHints ( conf )), // \u79fb\u9664\u65e0\u6548 Hint Batch ( \"Simple Sanity Check\" , Once , LookupFunctions ), // \u68c0\u67e5 Function \u662f\u5426\u5b58\u5728 Batch ( \"Substitution\" , fixedPoint , CTESubstitution , // CTE \u66ff\u6362 WindowsSubstitution , // Window \u66ff\u6362 EliminateUnions , // \u6d88\u9664 Union\uff08\u53ea\u6709\u4e00\u4e2a\u65f6\uff09 new SubstituteUnresolvedOrdinals ( conf )), // \u66ff\u6362 order by\u3001group by \u5e8f\u53f7 Batch ( \"Resolution\" , fixedPoint , ResolveTableValuedFunctions :: // \u6570\u636e\u8868\u51fd\u6570\uff0crange ResolveAlterTable :: // ALTER TABLE v2 ResolveTables :: // Table v2\uff0c\u8868 ResolveRelations :: // Table v1 ResolveReferences :: // Reference \u5217 ResolveCreateNamedStruct :: // named_struct ResolveDeserializer :: // Deserializer \u53cd\u5e8f\u5217\u5316 ResolveNewInstance :: // \u6784\u9020\u5b9e\u4f8b ResolveUpCast :: // \u7c7b\u578b\u8f6c\u6362 ResolveGroupingAnalytics :: // \u591a\u7ef4\u5206\u6790\uff0cGroupingSets/Cube/Rollup ResolvePivot :: // \u900f\u89c6\uff0c\u884c\u5217\u8f6c\u6362 ResolveOrdinalInOrderByAndGroupBy :: // \u5e8f\u53f7\uff0corder/sort by\u3001group by ResolveAggAliasInGroupBy :: // \u805a\u5408\u4e2d\u7684\u522b\u540d\uff0cgroup by\u3001grouping sets ResolveMissingReferences :: // \u8865\u5145\u7f3a\u5931\u7684 Reference\uff0csort by\u3001having ExtractGenerator :: // \u63d0\u53d6\u751f\u6210\u5668\uff0cexplode ResolveGenerate :: // \u751f\u6210\u5668 ResolveFunctions :: // Function\uff0c\u51fd\u6570 ResolveAliases :: // Alias\uff0c\u522b\u540d ResolveSubquery :: // \u5b50\u67e5\u8be2 ResolveSubqueryColumnAliases :: // \u5b50\u67e5\u8be2\u522b\u540d ResolveWindowOrder :: // Window Order ResolveWindowFrame :: // Window Frame ResolveNaturalAndUsingJoin :: // \u4f7f\u7528 Join \u66ff\u6362 Natural \u5f62\u5f0f ResolveOutputRelation :: // \u5904\u7406 \u8f93\u51fa\u6570\u636e\u548c\u8868\u7684\u5dee\u5f02 ExtractWindowExpressions :: // \u63d0\u53d6 Window GlobalAggregates :: // \u5168\u5c40\u805a\u5408 ResolveAggregateFunctions :: // \u805a\u5408\u51fd\u6570 TimeWindowing :: // \u6ed1\u52a8\u65f6\u95f4\u7a97\u53e3 ResolveInlineTables ( conf ) :: // \u5185\u8054\u8868 VALUES() ResolveHigherOrderFunctions ( catalog ) :: // higher order function\uff0clambda function ResolveLambdaVariables ( conf ) :: // lambda function \u53c2\u6570 ResolveTimeZone ( conf ) :: // TimeZone ResolveRandomSeed :: // \u968f\u673a\u6570\u751f\u6210 TypeCoercion . typeCoercionRules ( conf ) ++ // \u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 extendedResolutionRules : _ * ), // \u6269\u5c55\u89c4\u5219 Batch ( \"Post-Hoc Resolution\" , Once , postHocResolutionRules : _ * ), // \u6269\u5c55\u89c4\u5219 Batch ( \"Nondeterministic\" , Once , PullOutNondeterministic ), // \u975e\u786e\u5b9a\u6027\u8868\u8fbe\u5f0f Batch ( \"UDF\" , Once , HandleNullInputsForUDF ), // \u5904\u7406\u4e3a null \u7684\u8f93\u5165 Batch ( \"UpdateNullability\" , Once , UpdateAttributeNullability ), // \u66f4\u65b0\u53ef\u4ee5\u4e3a\u7a7a\u5c5e\u6027 Batch ( \"Subquery\" , Once , UpdateOuterReferences ), // \u5904\u7406\u5b50\u67e5\u8be2\u7684\u5916\u90e8\u5f15\u7528 Batch ( \"Cleanup\" , fixedPoint , CleanupAliases ) // \u6e05\u7406\u6ca1\u5fc5\u8981\u7684\u522b\u540d )","title":"Analyzer"},{"location":"share/2019/spark-sql-rules/#optimizer","text":"/** * Defines the default rule batches in the Optimizer. * * Implementations of this class should override this method, and [[nonExcludableRules]] if * necessary, instead of [[batches]]. The rule batches that eventually run in the Optimizer, * i.e., returned by [[batches]], will be (defaultBatches - (excludedRules - nonExcludableRules)). */ def defaultBatches : Seq [ Batch ] = { val operatorOptimizationRuleSet = Seq ( // Operator push down PushProjectionThroughUnion , // \u5bf9\u4e8e\u5168\u90e8\u662f\u786e\u5b9a\u6027 Project \u8fdb\u884c\u4e0b\u63a8 ReorderJoin , // \u6839\u636e Join \u5173\u8054\u6761\u4ef6\uff0c\u8fdb\u884c\u987a\u5e8f\u91cd\u6392 EliminateOuterJoin , // \u6d88\u9664\u975e\u7a7a\u7ea6\u675f\u7684 Outer Join PushDownPredicates , // \u8c13\u8bcd\u4e0b\u63a8 PushDownLeftSemiAntiJoin , // Project\u3001Window\u3001Union\u3001Aggregate\u3001PushPredicateThroughNonJoin \u573a\u666f\u4e0b\uff0c\u4e0b\u63a8 LeftSemi/LeftAnti PushLeftSemiLeftAntiThroughJoin , // Join \u573a\u666f\u4e0b\uff0c\u4e0b\u63a8 LeftSemi/LeftAnti LimitPushDown , // Limit \u4e0b\u63a8 ColumnPruning , // \u5217\u88c1\u526a InferFiltersFromConstraints , // \u6839\u636e\u7ea6\u675f\u63a8\u65ad Filter \u4fe1\u606f // Operator combine CollapseRepartition , // \u5408\u5e76 Repartition CollapseProject , // \u5408\u5e76 Project CollapseWindow , // \u5408\u5e76 Window\uff08\u76f8\u540c\u7684\u5206\u533a\u53ca\u6392\u5e8f\uff09 CombineFilters , // \u5408\u5e76 Filter CombineLimits , // \u5408\u5e76 Limit CombineUnions , // \u5408\u5e76 Union // Constant folding and strength reduction TransposeWindow , // \u8f6c\u7f6e Window\uff0c\u4f18\u5316\u8ba1\u7b97 NullPropagation , // Null \u4f20\u9012 ConstantPropagation , // \u5e38\u91cf\u4f20\u9012 FoldablePropagation , // \u53ef\u6298\u53e0\u5b57\u6bb5\u3001\u5c5e\u6027\u4f20\u64ad OptimizeIn , // \u4f18\u5316 In\uff0c\u7a7a\u5904\u7406\u3001\u91cd\u590d\u5904\u7406 ConstantFolding , // \u5e38\u91cf\u6298\u53e0 ReorderAssociativeOperator , // \u6392\u5e8f\u4e0e\u6298\u53e0\u53d8\u91cf LikeSimplification , // \u4f18\u5316 Like \u5bf9\u5e94\u7684\u6b63\u5219 BooleanSimplification , // \u7b80\u5316 Boolean \u8868\u8fbe\u5f0f SimplifyConditionals , // \u7b80\u5316\u6761\u4ef6\u8868\u8fbe\u5f0f\uff0cif/case RemoveDispensableExpressions , // \u79fb\u9664\u4e0d\u5fc5\u8981\u7684\u8282\u70b9\uff0cpositive SimplifyBinaryComparison , // \u4f18\u5316\u6bd4\u8f83\u8868\u8fbe\u5f0f\u4e3a Boolean Literal ReplaceNullWithFalseInPredicate , // \u4f18\u5316 Null \u573a\u666f Literal PruneFilters , // \u88c1\u526a\u660e\u786e\u7684\u8fc7\u6ee4\u6761\u4ef6 EliminateSorts , // \u6d88\u9664 Sort\uff0c\u65e0\u5173\u6216\u91cd\u590d SimplifyCasts , // \u7b80\u5316 Cast\uff0c\u7c7b\u578b\u5339\u914d SimplifyCaseConversionExpressions , // \u7b80\u5316 \u53e0\u52a0\u7684\u5927\u5c0f\u5199\u8f6c\u6362 RewriteCorrelatedScalarSubquery , // \u5b50\u67e5\u8be2\u6539\u5199\u4e3a Join EliminateSerialization , // \u6d88\u9664 \u5e8f\u5217\u5316 RemoveRedundantAliases , // \u5220\u9664\u5197\u4f59\u7684\u522b\u540d RemoveNoopOperators , // \u5220\u9664\u6ca1\u6709\u64cd\u4f5c\u7684\u64cd\u4f5c\u7b26 SimplifyExtractValueOps , // \u7b80\u5316\u7b26\u5408\u7c7b\u578b\u64cd\u4f5c\u7b26 CombineConcats ) ++ // \u5408\u5e76 Concat \u8868\u8fbe\u5f0f extendedOperatorOptimizationRules // \u6269\u5c55\u89c4\u5219 val operatorOptimizationBatch : Seq [ Batch ] = { val rulesWithoutInferFiltersFromConstraints = operatorOptimizationRuleSet . filterNot ( _ == InferFiltersFromConstraints ) Batch ( \"Operator Optimization before Inferring Filters\" , fixedPoint , rulesWithoutInferFiltersFromConstraints : _ * ) :: Batch ( \"Infer Filters\" , Once , InferFiltersFromConstraints ) :: Batch ( \"Operator Optimization after Inferring Filters\" , fixedPoint , rulesWithoutInferFiltersFromConstraints : _ * ) :: Nil } ( Batch ( \"Eliminate Distinct\" , Once , EliminateDistinct ) :: // \u6d88\u9664\u805a\u5408\u4e2d\u5197\u4f59\u7684 Distinct // Technically some of the rules in Finish Analysis are not optimizer rules and belong more // in the analyzer, because they are needed for correctness (e.g. ComputeCurrentTime). // However, because we also use the analyzer to canonicalized queries (for view definition), // we do not eliminate subqueries or compute current time in the analyzer. Batch ( \"Finish Analysis\" , Once , EliminateResolvedHint , // \u901a\u8fc7 Join \u6539\u5199 Hint EliminateSubqueryAliases , // \u6d88\u9664 \u5b50\u67e5\u8be2\u522b\u540d EliminateView , // \u6d88\u9664 \u89c6\u56fe ReplaceExpressions , // \u66ff\u6362\u3001\u6539\u5199 \u8868\u8fbe\u5f0f ComputeCurrentTime , // \u8ba1\u7b97\u5f53\u524d\u65e5\u671f\u6216\u65f6\u95f4 GetCurrentDatabase ( sessionCatalog ), // \u66ff\u6362\u5f53\u524d\u7684\u6570\u636e\u5e93 RewriteDistinctAggregates , // Distinct \u4f18\u5316\u6539\u5199 ReplaceDeduplicateWithAggregate ) :: // \u901a\u8fc7\u805a\u5408\u4f18\u5316\u5220\u9664\u91cd\u590d\u6570\u636e\u7b97\u5b50 ////////////////////////////////////////////////////////////////////////////////////////// // Optimizer rules start here ////////////////////////////////////////////////////////////////////////////////////////// // - Do the first call of CombineUnions before starting the major Optimizer rules, // since it can reduce the number of iteration and the other rules could add/move // extra operators between two adjacent Union operators. // - Call CombineUnions again in Batch(\"Operator Optimizations\"), // since the other rules might make two separate Unions operators adjacent. Batch ( \"Union\" , Once , CombineUnions ) :: // \u5408\u5e76\u76f8\u90bb\u7684 Union Batch ( \"OptimizeLimitZero\" , Once , OptimizeLimitZero ) :: // \u4f18\u5316 limit 0 // Run this once earlier. This might simplify the plan and reduce cost of optimizer. // For example, a query such as Filter(LocalRelation) would go through all the heavy // optimizer rules that are triggered when there is a filter // (e.g. InferFiltersFromConstraints). If we run this batch earlier, the query becomes just // LocalRelation and does not trigger many rules. Batch ( \"LocalRelation early\" , fixedPoint , ConvertToLocalRelation , // \u4f18\u5316 LocalRelation PropagateEmptyRelation ) :: // \u4f18\u5316 EmptyRelation Batch ( \"Pullup Correlated Expressions\" , Once , PullupCorrelatedPredicates ) :: // \u5904\u7406\u5f15\u7528\u5916\u90e8\u8c13\u8bcd Batch ( \"Subquery\" , Once , OptimizeSubqueries ) :: // \u4f18\u5316 \u5b50\u67e5\u8be2\uff0c\u53bb\u9664\u4e0d\u5fc5\u8981\u6392\u5e8f Batch ( \"Replace Operators\" , fixedPoint , RewriteExceptAll , // \u91cd\u5199 Except All RewriteIntersectAll , // \u91cd\u5199 Intersect All ReplaceIntersectWithSemiJoin , // \u4f7f\u7528 Semi Join\uff0c\u91cd\u5199 Intersect ReplaceExceptWithFilter , // \u4f7f\u7528 Filter\uff0c\u91cd\u5199 Except ReplaceExceptWithAntiJoin , // \u4f7f\u7528 Anti Join\uff0c\u91cd\u5199 Except ReplaceDistinctWithAggregate ) :: // \u4f7f\u7528 Aggregate\uff0c\u91cd\u5199 Distinct Batch ( \"Aggregate\" , fixedPoint , RemoveLiteralFromGroupExpressions , // \u5220\u9664\u805a\u5408\u8868\u8fbe\u5f0f\u7684\u5b57\u9762\u91cf RemoveRepetitionFromGroupExpressions ) :: Nil ++ // \u5220\u9664\u805a\u5408\u8868\u8fbe\u5f0f\u7684\u91cd\u590d\u4fe1\u606f operatorOptimizationBatch ) :+ Batch ( \"Join Reorder\" , Once , CostBasedJoinReorder ) :+ // \u57fa\u4e8e\u635f\u5931\u7684 Join \u91cd\u6392 Batch ( \"Remove Redundant Sorts\" , Once , RemoveRedundantSorts ) :+ // \u5220\u9664\u5197\u4f59\u7684\u6392\u5e8f Batch ( \"Decimal Optimizations\" , fixedPoint , DecimalAggregates ) :+ // Decimal \u7c7b\u578b\u805a\u5408\u4f18\u5316 Batch ( \"Object Expressions Optimization\" , fixedPoint , EliminateMapObjects , // \u6d88\u9664 MapObject CombineTypedFilters , // \u5408\u5e76\u76f8\u90bb\u7684\u7c7b\u578b\u8fc7\u6ee4 ObjectSerializerPruning , // \u88c1\u526a\u4e0d\u5fc5\u8981\u7684\u5e8f\u5217\u5316 ReassignLambdaVariableID ) :+ // \u91cd\u65b0\u5206\u7c7b LambdaVariable ID\uff0c\u5229\u4e8e codegen \u4f18\u5316 Batch ( \"LocalRelation\" , fixedPoint , ConvertToLocalRelation , // \u4f18\u5316 LocalRelation PropagateEmptyRelation ) :+ // \u4f18\u5316 EmptyRelation Batch ( \"Extract PythonUDF From JoinCondition\" , Once , PullOutPythonUDFInJoinCondition ) :+ // \u6807\u8bc6 Join \u4e2d\u7684 PythonUDF // The following batch should be executed after batch \"Join Reorder\" \"LocalRelation\" and // \"Extract PythonUDF From JoinCondition\". Batch ( \"Check Cartesian Products\" , Once , CheckCartesianProducts ) :+ // \u68c0\u6d4b \u7b1b\u5361\u5c14\u79ef \u7ea6\u675f\u6761\u4ef6 Batch ( \"RewriteSubquery\" , Once , RewritePredicateSubquery , // \u91cd\u5199 \u5b50\u67e5\u8be2\uff0cEXISTS/NOT EXISTS\u3001IN/NOT IN ColumnPruning , // \u88c1\u526a\u5217 CollapseProject , // \u5408\u5e76\u6295\u5f71 RemoveNoopOperators ) :+ // \u5220\u9664\u65e0\u7528\u7684\u64cd\u4f5c\u7b26 // This batch must be executed after the `RewriteSubquery` batch, which creates joins. Batch ( \"NormalizeFloatingNumbers\" , Once , NormalizeFloatingNumbers ) // \u89c4\u8303 Float \u7c7b\u578b\u6570\u503c }","title":"Optimizer"},{"location":"share/2019/spark-sql-rules/#sparkplan","text":"","title":"SparkPlan"},{"location":"share/2019/spark-sql-rules/#sparkstrategy","text":"","title":"SparkStrategy"},{"location":"share/2019/spark-sql-rules/#reference","text":"\u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e0a\uff09 \u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e2d\uff09 \u4e00\u6761 SQL \u5728 Apache Spark \u4e4b\u65c5\uff08\u4e0b\uff09","title":"Reference"},{"location":"share/2019/talking-data-quality/","text":"\u6f2b\u8c08\u6570\u636e\u8d28\u91cf \u00b6 \u4fdd\u969c\u7cfb\u7edf \u00b6 DQC SLA \u5f00\u6e90\u9879\u76ee \u00b6 Apache Griffin Profiling\uff08\u7edf\u8ba1\u4fe1\u606f\uff09 Accuracy\uff08\u51c6\u786e\u6027\uff09 Completeness\uff08\u5b8c\u6574\u6027\uff09 Timeliness\uff08\u65f6\u6548\u6027\uff09 Anomaly detection\uff08\u5f02\u5e38\u68c0\u6d4b\uff09 Validity\uff08\u6709\u6548\u6027\uff09 \u5e38\u89c1\u6307\u6807 \u00b6 \u6570\u636e\uff1a\u8868\u3001\u5b57\u6bb5 \u5b57\u6bb5\uff1a\u7ef4\u5ea6\u3001\u6307\u6807 \u7c7b\u578b\uff1a\u6570\u503c\u3001\u5b57\u7b26 \u65f6\u6548\u6027 \u8868\uff0cSLA\uff08\u8c03\u5ea6\u3001\u8d44\u6e90\uff09 \u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\uff0c\u4f5c\u4e1a\u6267\u884c\u65f6\u95f4 \u552f\u4e00\u6027 \u5b57\u6bb5\uff0c\u4e3b\u952e \u5197\u4f59\u7387\uff0c\u91cd\u590d\u7387 \u4e00\u81f4\u6027 \u5b57\u6bb5\uff0c\u6307\u6807 \u5bf9\u7167\u3001\u94a9\u7a3d \u5b8c\u6574\u6027 \u5b57\u6bb5\uff0c\u7f3a\u5931\u503c 0\uff0cnull\uff0c\u7a7a\u5b57\u7b26 \u5408\u7406\u6027 \u5b57\u6bb5\uff0c\u6ce2\u52a8\u7387\uff0c\u8868\uff0c\u6570\u636e\u91cf \u65f6\u95f4\u5e8f\u5217\uff1a\u79fb\u52a8\u5e73\u5747\u3001\u6307\u6570\u5e73\u6ed1\uff0cARIMA\uff0cLSTM \u89c4\u8303\u6027 \u5b57\u6bb5\uff0c\u5f02\u5e38\u503c \u7279\u6b8a\u5b57\u7b26\uff1a\u7c7b\u578b\u4e0d\u5339\u914d \u503c\u57df\uff1a\u679a\u4e3e\u503c\uff0c\u5747\u503c\u3001\u6700\u5927\u503c\u3001\u6700\u5c0f\u503c\uff0c\u6700\u5c0f\u957f\u5ea6\u3001\u6700\u5927\u957f\u5ea6 \u8d28\u91cf\u4fdd\u969c \u00b6 \u53ef\u7ba1\u7406\u3001\u53ef\u5b9a\u4e49\u3001\u53ef\u5b9a\u91cf\u3001\u53ef\u4f18\u5316 \u4e8b\u524d\u3001\u4e8b\u4e2d\u3001\u4e8b\u540e \u8d44\u4ea7\u7c7b\u76ee\u3001\u5206\u7ea7\u3001\u6210\u672c\u3001\u4ef7\u503c \u7ec4\u7ec7\u3001\u5236\u5ea6\u3001\u7ba1\u7406\u3001\u6d41\u7a0b\u3001\u89c4\u8303 \u9700\u6c42\u3001\u5f00\u53d1\u3001\u6d4b\u8bd5\u3001\u6545\u969c\u3001\u4ea4\u63a5 \u5176\u4ed6 \u00b6 \u8d28\u91cf\u96c6\u5e02 \u81ea\u52a8\u5316\u76d1\u63a7 \u6210\u672c\u5206\u6790 \u6839\u6e90\u5206\u6790 \u5f71\u54cd\u5206\u6790 \u4ef7\u503c\u4f53\u7cfb \u6545\u969c\u9884\u6d4b \u8d44\u6e90\u89c4\u5212 Reference \u00b6","title":"\u6f2b\u8c08\u6570\u636e\u8d28\u91cf"},{"location":"share/2019/talking-data-quality/#_1","text":"","title":"\u6f2b\u8c08\u6570\u636e\u8d28\u91cf"},{"location":"share/2019/talking-data-quality/#_2","text":"DQC SLA","title":"\u4fdd\u969c\u7cfb\u7edf"},{"location":"share/2019/talking-data-quality/#_3","text":"Apache Griffin Profiling\uff08\u7edf\u8ba1\u4fe1\u606f\uff09 Accuracy\uff08\u51c6\u786e\u6027\uff09 Completeness\uff08\u5b8c\u6574\u6027\uff09 Timeliness\uff08\u65f6\u6548\u6027\uff09 Anomaly detection\uff08\u5f02\u5e38\u68c0\u6d4b\uff09 Validity\uff08\u6709\u6548\u6027\uff09","title":"\u5f00\u6e90\u9879\u76ee"},{"location":"share/2019/talking-data-quality/#_4","text":"\u6570\u636e\uff1a\u8868\u3001\u5b57\u6bb5 \u5b57\u6bb5\uff1a\u7ef4\u5ea6\u3001\u6307\u6807 \u7c7b\u578b\uff1a\u6570\u503c\u3001\u5b57\u7b26 \u65f6\u6548\u6027 \u8868\uff0cSLA\uff08\u8c03\u5ea6\u3001\u8d44\u6e90\uff09 \u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\uff0c\u4f5c\u4e1a\u6267\u884c\u65f6\u95f4 \u552f\u4e00\u6027 \u5b57\u6bb5\uff0c\u4e3b\u952e \u5197\u4f59\u7387\uff0c\u91cd\u590d\u7387 \u4e00\u81f4\u6027 \u5b57\u6bb5\uff0c\u6307\u6807 \u5bf9\u7167\u3001\u94a9\u7a3d \u5b8c\u6574\u6027 \u5b57\u6bb5\uff0c\u7f3a\u5931\u503c 0\uff0cnull\uff0c\u7a7a\u5b57\u7b26 \u5408\u7406\u6027 \u5b57\u6bb5\uff0c\u6ce2\u52a8\u7387\uff0c\u8868\uff0c\u6570\u636e\u91cf \u65f6\u95f4\u5e8f\u5217\uff1a\u79fb\u52a8\u5e73\u5747\u3001\u6307\u6570\u5e73\u6ed1\uff0cARIMA\uff0cLSTM \u89c4\u8303\u6027 \u5b57\u6bb5\uff0c\u5f02\u5e38\u503c \u7279\u6b8a\u5b57\u7b26\uff1a\u7c7b\u578b\u4e0d\u5339\u914d \u503c\u57df\uff1a\u679a\u4e3e\u503c\uff0c\u5747\u503c\u3001\u6700\u5927\u503c\u3001\u6700\u5c0f\u503c\uff0c\u6700\u5c0f\u957f\u5ea6\u3001\u6700\u5927\u957f\u5ea6","title":"\u5e38\u89c1\u6307\u6807"},{"location":"share/2019/talking-data-quality/#_5","text":"\u53ef\u7ba1\u7406\u3001\u53ef\u5b9a\u4e49\u3001\u53ef\u5b9a\u91cf\u3001\u53ef\u4f18\u5316 \u4e8b\u524d\u3001\u4e8b\u4e2d\u3001\u4e8b\u540e \u8d44\u4ea7\u7c7b\u76ee\u3001\u5206\u7ea7\u3001\u6210\u672c\u3001\u4ef7\u503c \u7ec4\u7ec7\u3001\u5236\u5ea6\u3001\u7ba1\u7406\u3001\u6d41\u7a0b\u3001\u89c4\u8303 \u9700\u6c42\u3001\u5f00\u53d1\u3001\u6d4b\u8bd5\u3001\u6545\u969c\u3001\u4ea4\u63a5","title":"\u8d28\u91cf\u4fdd\u969c"},{"location":"share/2019/talking-data-quality/#_6","text":"\u8d28\u91cf\u96c6\u5e02 \u81ea\u52a8\u5316\u76d1\u63a7 \u6210\u672c\u5206\u6790 \u6839\u6e90\u5206\u6790 \u5f71\u54cd\u5206\u6790 \u4ef7\u503c\u4f53\u7cfb \u6545\u969c\u9884\u6d4b \u8d44\u6e90\u89c4\u5212","title":"\u5176\u4ed6"},{"location":"share/2019/talking-data-quality/#reference","text":"","title":"Reference"},{"location":"week/2019/","text":"2019 \u00b6 Month 01 02 03 04 05 October -- -- -- -- -- September Week 9-1 Week 9-2 Week 9-3 Week 9-4 Week 9-5 August Week 8-1 Week 8-2 Week 8-3 Week 8-4 -- July Week 7-1 Week 7-2 Week 7-3 Week 7-4 -- June -- Week 6-2 Week 6-3 Week 6-4 Week 6-5","title":2019},{"location":"week/2019/#2019","text":"Month 01 02 03 04 05 October -- -- -- -- -- September Week 9-1 Week 9-2 Week 9-3 Week 9-4 Week 9-5 August Week 8-1 Week 8-2 Week 8-3 Week 8-4 -- July Week 7-1 Week 7-2 Week 7-3 Week 7-4 -- June -- Week 6-2 Week 6-3 Week 6-4 Week 6-5","title":"2019"},{"location":"week/2019/0609/","text":"ARTS - 2019 Week 6-2 \u00b6 20190609~20190615 Algorithm \u00b6 7. Reverse Integer 9. Palindrome Number Review \u00b6 Apache Spark Core - Deep Dive \u2014 Proper Optimization \u00b6 Optimizing spark jobs through a true understanding of spark core. Learn What is a partition? What is the difference between read/shuffle/write partitions? How to increase parallelism and decrease output files? Where does shuffle data go between stages? What is the \"right\" size for your spark partitions and files? Why does a job slow down with only a few tasks left and never finish? Why doesn't adding nodes decrease my compute time? \u3010PDF\u3011Apache Spark Core - Deep Dive \u2014 Proper Optimization Review \u00b6 \u5c42\u6b21\u67b6\u6784 \u00b6 Cluster\u3001Driver\u3001Executor\uff08Core \u3001Storage \uff09 Application -(Action)-> Job -(Shuffle)-> Stage -(Partition)-> Task \u603b\u7ed3 \u00b6 \u5145\u5206\u5229\u7528\u8d44\u6e90 Core Memory Disk Network Data Cost \u57fa\u7ebf\u4e0e\u95ee\u9898 \u8d44\u6e90\uff1aCore\u3001Memory\u3001Disk\u3001Network \u4f5c\u4e1a\uff1aJob\u3001Stage\u3001Task\u3001Spill \u51cf\u5c11\u6570\u636e\u626b\u63cf \u5206\u533a - Partition Filter \u5206\u6876 Z-Ordering - Colocate \u6b63\u786e\u8bbe\u7f6e\u5206\u533a \u7c7b\u578b Input - \u63a7\u5236\u5206\u533a\u5927\u5c0f spark.sql.files.maxPartitionBytes (mutable) Shuffle - \u63a7\u5236\u5206\u533a\u6570\u91cf spark.sql.shuffle.partitions Output - \u63a7\u5236\u5206\u533a\u5927\u5c0f maxRecordsPerFile\u3001Coalesce\u3001Repartition\u3001localCheckpoint \u539f\u5219 \u6570\u636e\u63a2\u7d22\uff0c\u8d44\u6e90\u9884\u4f30 \u5747\u8861\u6570\u636e\uff0c\u4fdd\u8bc1\u5e76\u884c\u5ea6 - 128MB/100W\u3001\u4fdd\u6301\u500d\u6570 Input\u3001Shuffle\u3001Output \u907f\u514d Spill \u5e73\u8861\u4e0e\u53d6\u820d Input Partitions Shuffle Partitions Output Files Spills GC Times Join \u4f18\u5316 SortMerge Join \u2013 \u4e24\u4fa7\u6570\u636e\u91cf\u90fd\u5f88\u5927 Broadcast Join \u2013 \u4e00\u4fa7\u6570\u636e\u91cf\u5c0f BroadcastNestedLoop Join - \u6ca1\u6709\u76f8\u7b49\u8c13\u8bcd Skew Join - Salting\uff0cGrouping Range Join - Point\u3001Overlap \u51cf\u5c11\u6570\u636e\u79fb\u52a8\u4e0e\u91cd\u65b0\u5206\u533a df#cache\u3001df#persist CACHE TABLE \u4f7f\u7528\u5411\u91cf\u5316 UDF Tip \u00b6 Maven \u4f9d\u8d56 \u00b6 \u4f9d\u8d56 \u00b6 \u4f9d\u8d56\u5143\u7d20 \u5750\u6807\uff1agroupId, artifactId, version\uff08\u8303\u56f4\uff09 \u4f5c\u7528\u57df\uff08scope\uff09\uff1acompile\u3001test\u3001provided \u3001runtime \u7c7b\u522b\uff08classifier\uff09\uff1a\u4e0d\u540c\u6784\u5efa\u65b9\u5f0f\u7684\u6807\u8bc6 \u4f9d\u8d56\u539f\u5219 \u6700\u77ed\u8def\u52b2\u539f\u5219 \u6700\u5148\u5b9a\u4e49\u539f\u5219 \u89e3\u51b3\u51b2\u7a81 \u660e\u786e\u5b9a\u4e49\u4f9d\u8d56 \u6392\u9664\u51b2\u7a81\u4f9d\u8d56 \u8c03\u6574\u4f9d\u8d56\u4f5c\u7528\u57df \u901a\u8fc7Shade\u63d2\u4ef6\u8c03\u6574 Share \u00b6 Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790 \u00b6 \u5916\u90e8\u5f71\u54cd\u3001\u4f9d\u8d56 \u5185\u90e8\u6d41\u7a0b\u3001\u673a\u5236 Reference \u00b6 Maven","title":"ARTS - 2019 Week 6-2"},{"location":"week/2019/0609/#arts-2019-week-6-2","text":"20190609~20190615","title":"ARTS - 2019 Week 6-2"},{"location":"week/2019/0609/#algorithm","text":"7. Reverse Integer 9. Palindrome Number","title":"Algorithm"},{"location":"week/2019/0609/#review","text":"","title":"Review"},{"location":"week/2019/0609/#apache-spark-core-deep-dive-proper-optimization","text":"Optimizing spark jobs through a true understanding of spark core. Learn What is a partition? What is the difference between read/shuffle/write partitions? How to increase parallelism and decrease output files? Where does shuffle data go between stages? What is the \"right\" size for your spark partitions and files? Why does a job slow down with only a few tasks left and never finish? Why doesn't adding nodes decrease my compute time? \u3010PDF\u3011Apache Spark Core - Deep Dive \u2014 Proper Optimization","title":"Apache Spark Core - Deep Dive \u2014 Proper Optimization"},{"location":"week/2019/0609/#review_1","text":"","title":"Review"},{"location":"week/2019/0609/#_1","text":"Cluster\u3001Driver\u3001Executor\uff08Core \u3001Storage \uff09 Application -(Action)-> Job -(Shuffle)-> Stage -(Partition)-> Task","title":"\u5c42\u6b21\u67b6\u6784"},{"location":"week/2019/0609/#_2","text":"\u5145\u5206\u5229\u7528\u8d44\u6e90 Core Memory Disk Network Data Cost \u57fa\u7ebf\u4e0e\u95ee\u9898 \u8d44\u6e90\uff1aCore\u3001Memory\u3001Disk\u3001Network \u4f5c\u4e1a\uff1aJob\u3001Stage\u3001Task\u3001Spill \u51cf\u5c11\u6570\u636e\u626b\u63cf \u5206\u533a - Partition Filter \u5206\u6876 Z-Ordering - Colocate \u6b63\u786e\u8bbe\u7f6e\u5206\u533a \u7c7b\u578b Input - \u63a7\u5236\u5206\u533a\u5927\u5c0f spark.sql.files.maxPartitionBytes (mutable) Shuffle - \u63a7\u5236\u5206\u533a\u6570\u91cf spark.sql.shuffle.partitions Output - \u63a7\u5236\u5206\u533a\u5927\u5c0f maxRecordsPerFile\u3001Coalesce\u3001Repartition\u3001localCheckpoint \u539f\u5219 \u6570\u636e\u63a2\u7d22\uff0c\u8d44\u6e90\u9884\u4f30 \u5747\u8861\u6570\u636e\uff0c\u4fdd\u8bc1\u5e76\u884c\u5ea6 - 128MB/100W\u3001\u4fdd\u6301\u500d\u6570 Input\u3001Shuffle\u3001Output \u907f\u514d Spill \u5e73\u8861\u4e0e\u53d6\u820d Input Partitions Shuffle Partitions Output Files Spills GC Times Join \u4f18\u5316 SortMerge Join \u2013 \u4e24\u4fa7\u6570\u636e\u91cf\u90fd\u5f88\u5927 Broadcast Join \u2013 \u4e00\u4fa7\u6570\u636e\u91cf\u5c0f BroadcastNestedLoop Join - \u6ca1\u6709\u76f8\u7b49\u8c13\u8bcd Skew Join - Salting\uff0cGrouping Range Join - Point\u3001Overlap \u51cf\u5c11\u6570\u636e\u79fb\u52a8\u4e0e\u91cd\u65b0\u5206\u533a df#cache\u3001df#persist CACHE TABLE \u4f7f\u7528\u5411\u91cf\u5316 UDF","title":"\u603b\u7ed3"},{"location":"week/2019/0609/#tip","text":"","title":"Tip"},{"location":"week/2019/0609/#maven","text":"","title":"Maven \u4f9d\u8d56"},{"location":"week/2019/0609/#_3","text":"\u4f9d\u8d56\u5143\u7d20 \u5750\u6807\uff1agroupId, artifactId, version\uff08\u8303\u56f4\uff09 \u4f5c\u7528\u57df\uff08scope\uff09\uff1acompile\u3001test\u3001provided \u3001runtime \u7c7b\u522b\uff08classifier\uff09\uff1a\u4e0d\u540c\u6784\u5efa\u65b9\u5f0f\u7684\u6807\u8bc6 \u4f9d\u8d56\u539f\u5219 \u6700\u77ed\u8def\u52b2\u539f\u5219 \u6700\u5148\u5b9a\u4e49\u539f\u5219 \u89e3\u51b3\u51b2\u7a81 \u660e\u786e\u5b9a\u4e49\u4f9d\u8d56 \u6392\u9664\u51b2\u7a81\u4f9d\u8d56 \u8c03\u6574\u4f9d\u8d56\u4f5c\u7528\u57df \u901a\u8fc7Shade\u63d2\u4ef6\u8c03\u6574","title":"\u4f9d\u8d56"},{"location":"week/2019/0609/#share","text":"","title":"Share"},{"location":"week/2019/0609/#spark","text":"\u5916\u90e8\u5f71\u54cd\u3001\u4f9d\u8d56 \u5185\u90e8\u6d41\u7a0b\u3001\u673a\u5236","title":"Spark \u4f5c\u4e1a\u8017\u65f6\u5206\u6790"},{"location":"week/2019/0609/#reference","text":"Maven","title":"Reference"},{"location":"week/2019/0616/","text":"ARTS - 2019 Week 6-3 \u00b6 20190616~20190622 Algorithm \u00b6 13. Roman to Integer 14. Longest Common Prefix Review \u00b6 A Deep Dive into Query Execution Engine of Spark SQL \u00b6 Spark SQL enables Spark to perform efficient and fault-tolerant relational query processing with analytics database technologies. The relational queries are compiled to the executable physical plans consisting of transformations and actions on RDDs with the generated Java code. The code is compiled to Java bytecode, executed at runtime by JVM and optimized by JIT to native machine code at runtime. This talk will take a deep dive into Spark SQL execution engine. The talk includes pipelined execution, whole-stage code generation, UDF execution, memory management, vectorized readers, lineage based RDD transformation and action. \u3010PDF\u3011A Deep Dive into Query Execution Engine of Spark SQL Review \u00b6 \u57fa\u7840\u4ecb\u7ecd Spark \u7ec4\u4ef6 Spark Core\u3001Data Source Connectors Catalyst Optimization & Tungsten Execution SparkSession / DataFrame / Dataset APIs SQL\u3001Spark ML\u3001Spark Streaming\u3001Spark Graph\u30013 rd -party Libraries SQL \u6d41\u7a0b Parser -> Analysis -> Logical Optimization -> Physical Planning -> Code Generation -> Execution Agenda \u7269\u7406\u6267\u884c\u8ba1\u5212 Transform logical operators into physical operators Choose between different physical alternatives Includes physical traits of the execution engine Some ops may be mapped into multiple physical nodes \u4ee3\u7801\u751f\u6210 No virtual function calls Data in CPU registers Loop unrolling & SIMD \u5bb9\u9519\u4e0e\u5931\u8d25\u5904\u7406 Mid-query recovery model\uff1a\u6839\u636e\u8840\u7f18\u91cd\u65b0\u8ba1\u7b97\u4e22\u5931\u7684\u5206\u533a Task\u3001Fetch\uff1a\u91cd\u8bd5\u7b56\u7565 \u5185\u5b58\u7ba1\u7406 \u4fdd\u7559\u5185\u5b58\u3001\u7528\u6237\u5185\u5b58\u3001\u6267\u884c\u5185\u5b58\u3001\u5b58\u50a8\u5185\u5b58 - Execution Memory - Buffer intermediate results - Normally short lived - Storage Memory - Reuse data for future computation - Cached data can be long-lived - LRU eviction for spill data Delta Lake\uff08Vectorized\uff09 Full ACID transactions Schema management Scalable metadata handling Data versioning and time travel Unified batch/streaming support Record update and deletion Data expectation UDF \u8f6c\u6362\u4e3a\u5bf9\u5e94\u6570\u636e\u683c\u5f0f -> \u8c03\u7528UDF -> \u8f6c\u6362\u56de\u5185\u90e8\u6570\u636e\u683c\u5f0f - Java/Scala UDFs - Hive UDFs - Python/Pandas UDFs PySpark\uff08Koalas\uff09 \u901a\u8fc7 Py4J \u6267\u884c Python \u4ee3\u7801 Physical Operator\uff08JVM\uff09 -> PythonRunner\uff08JVM\uff09 -> \u5e8f\u5217\u5316/\u53cd\u5e8f\u5217\u5316\u6570\u636e -> \u6267\u884c\u4ee3\u7801\uff08Python Worker\uff09 Tip \u00b6 JVM \u5e38\u7528\u53c2\u6570 \u00b6 -Dproperty=value \u8bbe\u7f6e\u7cfb\u7edf\u5c5e\u6027\uff0c\u901a\u8fc7System.getProperty\u83b7\u53d6 -verbose:gc \u5c55\u793a\u6bcf\u4e2aGC\u4e8b\u4ef6\u7684\u4fe1\u606f -Xms6g \u521d\u59cb\u5806\u5185\u5b58\u5927\u5c0f -Xmx6g \u6700\u5927\u5806\u5185\u5b58\u5927\u5c0f -XX:MetaspaceSize=96m \u521d\u59cb Metaspace \u5927\u5c0f -XX:MaxMetaspaceSize=96m \u6700\u5927 Metaspace \u5927\u5c0f -XX:+UseG1GC \u4f7f\u7528 G1 GC -XX:MaxGCPauseMillis=20 \u6700\u5927 GC \u76ee\u6807\u505c\u987f\u65f6\u95f4 -XX:InitiatingHeapOccupancyPercent=35 \u89e6\u53d1\u6807\u8bb0\u5468\u671f\u5806\u5360\u7528\u7387\u9608\u503c -XX:G1HeapRegionSize=16M G1 region \u7684\u5927\u5c0f -XX:MinMetaspaceFreeRatio=50 Metaspace GC \u540e\uff0cMetaspace \u7a7a\u95f2\u7a7a\u95f4\u6700\u5c0f\u6bd4\u4f8b -XX:MaxMetaspaceFreeRatio=80 Metaspace GC \u540e\uff0cMetaspace \u7a7a\u95f2\u7a7a\u95f4\u6700\u5927\u6bd4\u4f8b -XX:+PrintGCDetails \u6253\u5370 GC \u8be6\u60c5 -XX:+PrintGCTimeStamps \u6253\u5370 GC \u65f6 JVM \u542f\u52a8\u81f3\u4eca\u7684\u65f6\u95f4\u6233 -XX:+PrintGCDateStamps \u6253\u5370 GC \u65f6\u7684\u65e5\u671f\u548c\u65f6\u95f4 Share \u00b6 Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u00b6 Reference \u00b6 \u5783\u573e\u4f18\u5148\u578b\u5783\u573e\u56de\u6536\u5668\u8c03\u4f18 Java8 JVM\u53c2\u6570\u89e3\u8bfb \u4e00\u53ea\u61c2JVM\u53c2\u6570\u7684\u72d0\u72f8","title":"ARTS - 2019 Week 6-3"},{"location":"week/2019/0616/#arts-2019-week-6-3","text":"20190616~20190622","title":"ARTS - 2019 Week 6-3"},{"location":"week/2019/0616/#algorithm","text":"13. Roman to Integer 14. Longest Common Prefix","title":"Algorithm"},{"location":"week/2019/0616/#review","text":"","title":"Review"},{"location":"week/2019/0616/#a-deep-dive-into-query-execution-engine-of-spark-sql","text":"Spark SQL enables Spark to perform efficient and fault-tolerant relational query processing with analytics database technologies. The relational queries are compiled to the executable physical plans consisting of transformations and actions on RDDs with the generated Java code. The code is compiled to Java bytecode, executed at runtime by JVM and optimized by JIT to native machine code at runtime. This talk will take a deep dive into Spark SQL execution engine. The talk includes pipelined execution, whole-stage code generation, UDF execution, memory management, vectorized readers, lineage based RDD transformation and action. \u3010PDF\u3011A Deep Dive into Query Execution Engine of Spark SQL","title":"A Deep Dive into Query Execution Engine of Spark SQL"},{"location":"week/2019/0616/#review_1","text":"\u57fa\u7840\u4ecb\u7ecd Spark \u7ec4\u4ef6 Spark Core\u3001Data Source Connectors Catalyst Optimization & Tungsten Execution SparkSession / DataFrame / Dataset APIs SQL\u3001Spark ML\u3001Spark Streaming\u3001Spark Graph\u30013 rd -party Libraries SQL \u6d41\u7a0b Parser -> Analysis -> Logical Optimization -> Physical Planning -> Code Generation -> Execution Agenda \u7269\u7406\u6267\u884c\u8ba1\u5212 Transform logical operators into physical operators Choose between different physical alternatives Includes physical traits of the execution engine Some ops may be mapped into multiple physical nodes \u4ee3\u7801\u751f\u6210 No virtual function calls Data in CPU registers Loop unrolling & SIMD \u5bb9\u9519\u4e0e\u5931\u8d25\u5904\u7406 Mid-query recovery model\uff1a\u6839\u636e\u8840\u7f18\u91cd\u65b0\u8ba1\u7b97\u4e22\u5931\u7684\u5206\u533a Task\u3001Fetch\uff1a\u91cd\u8bd5\u7b56\u7565 \u5185\u5b58\u7ba1\u7406 \u4fdd\u7559\u5185\u5b58\u3001\u7528\u6237\u5185\u5b58\u3001\u6267\u884c\u5185\u5b58\u3001\u5b58\u50a8\u5185\u5b58 - Execution Memory - Buffer intermediate results - Normally short lived - Storage Memory - Reuse data for future computation - Cached data can be long-lived - LRU eviction for spill data Delta Lake\uff08Vectorized\uff09 Full ACID transactions Schema management Scalable metadata handling Data versioning and time travel Unified batch/streaming support Record update and deletion Data expectation UDF \u8f6c\u6362\u4e3a\u5bf9\u5e94\u6570\u636e\u683c\u5f0f -> \u8c03\u7528UDF -> \u8f6c\u6362\u56de\u5185\u90e8\u6570\u636e\u683c\u5f0f - Java/Scala UDFs - Hive UDFs - Python/Pandas UDFs PySpark\uff08Koalas\uff09 \u901a\u8fc7 Py4J \u6267\u884c Python \u4ee3\u7801 Physical Operator\uff08JVM\uff09 -> PythonRunner\uff08JVM\uff09 -> \u5e8f\u5217\u5316/\u53cd\u5e8f\u5217\u5316\u6570\u636e -> \u6267\u884c\u4ee3\u7801\uff08Python Worker\uff09","title":"Review"},{"location":"week/2019/0616/#tip","text":"","title":"Tip"},{"location":"week/2019/0616/#jvm","text":"-Dproperty=value \u8bbe\u7f6e\u7cfb\u7edf\u5c5e\u6027\uff0c\u901a\u8fc7System.getProperty\u83b7\u53d6 -verbose:gc \u5c55\u793a\u6bcf\u4e2aGC\u4e8b\u4ef6\u7684\u4fe1\u606f -Xms6g \u521d\u59cb\u5806\u5185\u5b58\u5927\u5c0f -Xmx6g \u6700\u5927\u5806\u5185\u5b58\u5927\u5c0f -XX:MetaspaceSize=96m \u521d\u59cb Metaspace \u5927\u5c0f -XX:MaxMetaspaceSize=96m \u6700\u5927 Metaspace \u5927\u5c0f -XX:+UseG1GC \u4f7f\u7528 G1 GC -XX:MaxGCPauseMillis=20 \u6700\u5927 GC \u76ee\u6807\u505c\u987f\u65f6\u95f4 -XX:InitiatingHeapOccupancyPercent=35 \u89e6\u53d1\u6807\u8bb0\u5468\u671f\u5806\u5360\u7528\u7387\u9608\u503c -XX:G1HeapRegionSize=16M G1 region \u7684\u5927\u5c0f -XX:MinMetaspaceFreeRatio=50 Metaspace GC \u540e\uff0cMetaspace \u7a7a\u95f2\u7a7a\u95f4\u6700\u5c0f\u6bd4\u4f8b -XX:MaxMetaspaceFreeRatio=80 Metaspace GC \u540e\uff0cMetaspace \u7a7a\u95f2\u7a7a\u95f4\u6700\u5927\u6bd4\u4f8b -XX:+PrintGCDetails \u6253\u5370 GC \u8be6\u60c5 -XX:+PrintGCTimeStamps \u6253\u5370 GC \u65f6 JVM \u542f\u52a8\u81f3\u4eca\u7684\u65f6\u95f4\u6233 -XX:+PrintGCDateStamps \u6253\u5370 GC \u65f6\u7684\u65e5\u671f\u548c\u65f6\u95f4","title":"JVM \u5e38\u7528\u53c2\u6570"},{"location":"week/2019/0616/#share","text":"","title":"Share"},{"location":"week/2019/0616/#spark-cluster-mode-on-yarn","text":"","title":"Spark \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"week/2019/0616/#reference","text":"\u5783\u573e\u4f18\u5148\u578b\u5783\u573e\u56de\u6536\u5668\u8c03\u4f18 Java8 JVM\u53c2\u6570\u89e3\u8bfb \u4e00\u53ea\u61c2JVM\u53c2\u6570\u7684\u72d0\u72f8","title":"Reference"},{"location":"week/2019/0623/","text":"ARTS - 2019 Week 6-4 \u00b6 20190623~20190629 Algorithm \u00b6 20. Valid Parentheses 21. Merge Two Sorted Lists Review \u00b6 Cosco: An Efficient Facebook-Scale Shuffle Service \u00b6 Cosco is an efficient shuffle-as-a-service that powers Spark (and Hive) jobs at Facebook warehouse scale. It is implemented as a scalable, reliable and maintainable distributed system. Cosco is based on the idea of partial in-memory aggregation across a shared pool of distributed memory. This provides vastly improved efficiency in disk usage compared to Spark\u2019s built-in shuffle. Long term, we believe the Cosco architecture will be key to efficiently supporting jobs at ever larger scale. In this talk we\u2019ll take a deep dive into the Cosco architecture and describe how it\u2019s deployed at Facebook. We will then describe how it\u2019s integrated to run shuffle for Spark, and contrast it with Spark\u2019s built-in sort-based shuffle mechanism and SOS (presented at Spark+AI Summit 2018). \u3010PDF\u3011Cosco: An Efficient Facebook-Scale Shuffle Service Review \u00b6 \u80cc\u666f \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\uff0c\u597d\u5904\uff1a\u786c\u4ef6\u3001\u4f18\u5316\u3001\u7ba1\u7406\u3001\u914d\u7f6e \u8ba1\u7b97\uff1aCPU\u3001GPU\u3001RAM \u5b58\u50a8\uff1aDisk\u3001\u6301\u4e45\u5b58\u50a8\u3001\u4e34\u65f6\u5b58\u50a8 \u95ee\u9898\uff1a\u78c1\u76d8\u670d\u52a1\u65f6\u95f4\u3001\u541e\u5410\uff1b\u5199\u653e\u5927 Cosco\u4ecb\u7ecd \u5bf9\u4e8e\u6bcf\u4e2a Reducer \u7684\u5206\u533a\uff0cMapper \u5171\u4eab\u4e00\u4e2a\u9884\u5199\u7f13\u51b2\u533a Reducer \u53ef\u4ee5\u987a\u5e8f\u8bfb\u53d6\u5199\u5165\u7684\u6570\u636e IO\u541e\u5410\uff1a\u987a\u5e8f\u8bfb\uff0c\u589e\u5927IO\u5927\u5c0f \u5199\u653e\u5927\uff1a\u907f\u514d Spill \u95ee\u9898 Shuffle Exchange \u5728\u78c1\u76d8\u4e0a\u5904\u7406 \u5355\u4e2a Shuffle Exchange \u5904\u7406\u80fd\u529b\uff1aPB\u7ea7\uff0c10W Mapper\uff0c1W Reducer \u5199\u653e\u5927\uff1a3\u500d IO\u541e\u5410\uff1a200k IO\u5e76\u53d1\uff1aReader \u5e76\u53d1\uff0cM*R \u65b9\u6848 \u9884\u5199\u7f13\u51b2\u533a\uff08Write-ahead buffers\uff09\uff1a\u5bf9\u4e8e\u6bcf\u4e2a Reducer \u7684\u5206\u533a\uff0cMapper \u5171\u4eab\u4e00\u4e2a\u9884\u5199\u7f13\u51b2\u533a\uff0c\u6392\u5e8f\uff08\u53ef\u9009\uff09 \u4f20\u8f93\uff08Delivery\uff09\uff1a\u6570\u636e Ack\u4e0eFailover\uff08Exactly once\u3001At least once\uff09 \u526f\u672c\uff08Replication\uff09\uff1a\u6587\u4ef6 Failover \u5143\u6570\u636e\uff08Metadata\uff09\uff1aMapper \u63d0\u4ea4\u6587\u4ef6\uff0cReducer \u8bf7\u6c42\u6587\u4ef6 \u8c03\u5ea6\u5668\uff08Scheduler\uff09\uff1aShuffle \u8ba1\u7b97\u8c03\u5ea6\u3001\u5bb9\u9519 \u9650\u5236 \u6570\u636e\u5bb9\u91cf \u5185\u5b58\u5bb9\u91cf Tip \u00b6 Spark \u5e38\u7528\u53c2\u6570 \u00b6 spark.executor.extraJavaOptions=\"-XX:+PrintGCDetails -XX:+PrintGCTimeStamps\" Executor JVM \u53c2\u6570 spark.executor.cores=2 Executor \u6838\u6570 spark.executor.memory=4g Executor \u5185\u5b58\u5927\u5c0f spark.yarn.executor.memoryOverhead=1g Executor \u5806\u5916\u5185\u5b58\u5927\u5c0f spark.driver.extraJavaOptions=\"-XX:+PrintGCDetails -XX:+PrintGCTimeStamps\" Driver JVM \u53c2\u6570 spark.driver.cores=2 Driver \u6838\u6570 spark.driver.memory=4g Driver \u5185\u5b58\u5927\u5c0f spark.yarn.driver.memoryOverhead=1g Driver \u5806\u5916\u5185\u5b58\u5927\u5c0f spark.speculation=true \u5f00\u542f\u63a8\u6d4b\u6267\u884c spark.speculation.quantile=0.75 \u8fdb\u884c\u63a8\u6d4b\u6267\u884c\u7684\u4efb\u52a1\u5b8c\u6210\u6700\u5c0f\u6bd4\u4f8b spark.speculation.multiplier=1.5 \u6ee1\u8db3\u6700\u5c0f\u5b8c\u6210\u6bd4\u4f8b\u6761\u4ef6\u4e0b\uff0c\u8fdb\u884c\u63a8\u6d4b\u6267\u884c\u7684\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u5927\u4e8e\u5b8c\u6210\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u4e2d\u4f4d\u6570\u7684\u6700\u5c0f\u500d\u6570 spark.memory.fraction=0.6 \u6267\u884c\u548c\u5b58\u50a8\u5185\u5b58\u5360\u5806\u5185\u5b58\u7684\u6bd4\u4f8b\uff0c\u589e\u52a0\u53ef\u80fd\u5bfc\u81f4OOM\uff1b300MB\u4fdd\u7559\u5185\u5b58\uff0c\u5269\u4e0b\u4e3a\u7528\u6237\u5185\u5b58(1.0 - spark.memory.fraction) * (SYSTEM_MEMORY - RESERVED_MEMORY) spark.memory.storageFraction=0.5 \u5b58\u50a8\u5185\u5b58\u514d\u4e8e\u88ab\u8ba1\u7b97\u9a71\u9010\u7684\u5185\u5b58\u6bd4\u4f8b\uff0c\u9a71\u9010\u901a\u8fc7LRU\u673a\u5236\uff0c\u8ba1\u7b97\u5185\u5b58\u4e0d\u8db3\u53ef\u80fd\u5bfc\u81f4spill\u5230\u78c1\u76d8 spark.memory.offHeap.enabled=true \u4f7f\u7528\u5806\u5916\u5185\u5b58\uff0c\u51cf\u5c11GC\u538b\u529b spark.memory.offHeap.size=2147483648 \u8bbe\u7f6e\u5806\u5916\u5185\u5b58\u5927\u5c0f spark.shuffle.file.buffer=32k shuffle\u8f93\u51fa\u5185\u5b58\u7f13\u51b2\u5927\u5c0f\uff0c\u51cf\u5c11\u78c1\u76d8IO\u538b\u529b spark.unsafe.sorter.spill.reader.buffer.size=2097152 \u8bfb\u53d6spill\u6587\u4ef6\u7f13\u51b2\u5927\u5c0f spark.sql.autoBroadcastJoinThreshold=10m \u8868\u88ab\u5e7f\u64ad\u7684\u6700\u5927\u503c spark.sql.broadcastTimeout=300 \u8868\u88ab\u5e7f\u64ad\u7684\u8d85\u65f6\u65f6\u95f4 spark.dynamicAllocation.enabled=true \u5f00\u542f\u52a8\u6001\u8d44\u6e90\u5206\u914d spark.dynamicAllocation.minExecutors=20 \u6700\u5c11 Executor \u6570\u91cf spark.dynamicAllocation.maxExecutors=200 \u6700\u591a Executor \u6570\u91cf spark.shuffle.service.enabled=true \u5f00\u542f\u5916\u90e8 Shuffle Service spark.shuffle.service.port=7337 Shuffle Service \u7aef\u53e3 spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2 FileOutputCommitter \u4f7f\u7528 V2 \u7b97\u6cd5\uff0c\u51cf\u5c11commitJob\u8017\u65f6\uff0cV1 \u589e\u52a0\u4e86\u4e00\u81f4\u6027\u4fdd\u8bc1 Share \u00b6 Spark Shuffle Service \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 6-4"},{"location":"week/2019/0623/#arts-2019-week-6-4","text":"20190623~20190629","title":"ARTS - 2019 Week 6-4"},{"location":"week/2019/0623/#algorithm","text":"20. Valid Parentheses 21. Merge Two Sorted Lists","title":"Algorithm"},{"location":"week/2019/0623/#review","text":"","title":"Review"},{"location":"week/2019/0623/#cosco-an-efficient-facebook-scale-shuffle-service","text":"Cosco is an efficient shuffle-as-a-service that powers Spark (and Hive) jobs at Facebook warehouse scale. It is implemented as a scalable, reliable and maintainable distributed system. Cosco is based on the idea of partial in-memory aggregation across a shared pool of distributed memory. This provides vastly improved efficiency in disk usage compared to Spark\u2019s built-in shuffle. Long term, we believe the Cosco architecture will be key to efficiently supporting jobs at ever larger scale. In this talk we\u2019ll take a deep dive into the Cosco architecture and describe how it\u2019s deployed at Facebook. We will then describe how it\u2019s integrated to run shuffle for Spark, and contrast it with Spark\u2019s built-in sort-based shuffle mechanism and SOS (presented at Spark+AI Summit 2018). \u3010PDF\u3011Cosco: An Efficient Facebook-Scale Shuffle Service","title":"Cosco: An Efficient Facebook-Scale Shuffle Service"},{"location":"week/2019/0623/#review_1","text":"\u80cc\u666f \u5b58\u50a8\u8ba1\u7b97\u5206\u79bb\uff0c\u597d\u5904\uff1a\u786c\u4ef6\u3001\u4f18\u5316\u3001\u7ba1\u7406\u3001\u914d\u7f6e \u8ba1\u7b97\uff1aCPU\u3001GPU\u3001RAM \u5b58\u50a8\uff1aDisk\u3001\u6301\u4e45\u5b58\u50a8\u3001\u4e34\u65f6\u5b58\u50a8 \u95ee\u9898\uff1a\u78c1\u76d8\u670d\u52a1\u65f6\u95f4\u3001\u541e\u5410\uff1b\u5199\u653e\u5927 Cosco\u4ecb\u7ecd \u5bf9\u4e8e\u6bcf\u4e2a Reducer \u7684\u5206\u533a\uff0cMapper \u5171\u4eab\u4e00\u4e2a\u9884\u5199\u7f13\u51b2\u533a Reducer \u53ef\u4ee5\u987a\u5e8f\u8bfb\u53d6\u5199\u5165\u7684\u6570\u636e IO\u541e\u5410\uff1a\u987a\u5e8f\u8bfb\uff0c\u589e\u5927IO\u5927\u5c0f \u5199\u653e\u5927\uff1a\u907f\u514d Spill \u95ee\u9898 Shuffle Exchange \u5728\u78c1\u76d8\u4e0a\u5904\u7406 \u5355\u4e2a Shuffle Exchange \u5904\u7406\u80fd\u529b\uff1aPB\u7ea7\uff0c10W Mapper\uff0c1W Reducer \u5199\u653e\u5927\uff1a3\u500d IO\u541e\u5410\uff1a200k IO\u5e76\u53d1\uff1aReader \u5e76\u53d1\uff0cM*R \u65b9\u6848 \u9884\u5199\u7f13\u51b2\u533a\uff08Write-ahead buffers\uff09\uff1a\u5bf9\u4e8e\u6bcf\u4e2a Reducer \u7684\u5206\u533a\uff0cMapper \u5171\u4eab\u4e00\u4e2a\u9884\u5199\u7f13\u51b2\u533a\uff0c\u6392\u5e8f\uff08\u53ef\u9009\uff09 \u4f20\u8f93\uff08Delivery\uff09\uff1a\u6570\u636e Ack\u4e0eFailover\uff08Exactly once\u3001At least once\uff09 \u526f\u672c\uff08Replication\uff09\uff1a\u6587\u4ef6 Failover \u5143\u6570\u636e\uff08Metadata\uff09\uff1aMapper \u63d0\u4ea4\u6587\u4ef6\uff0cReducer \u8bf7\u6c42\u6587\u4ef6 \u8c03\u5ea6\u5668\uff08Scheduler\uff09\uff1aShuffle \u8ba1\u7b97\u8c03\u5ea6\u3001\u5bb9\u9519 \u9650\u5236 \u6570\u636e\u5bb9\u91cf \u5185\u5b58\u5bb9\u91cf","title":"Review"},{"location":"week/2019/0623/#tip","text":"","title":"Tip"},{"location":"week/2019/0623/#spark","text":"spark.executor.extraJavaOptions=\"-XX:+PrintGCDetails -XX:+PrintGCTimeStamps\" Executor JVM \u53c2\u6570 spark.executor.cores=2 Executor \u6838\u6570 spark.executor.memory=4g Executor \u5185\u5b58\u5927\u5c0f spark.yarn.executor.memoryOverhead=1g Executor \u5806\u5916\u5185\u5b58\u5927\u5c0f spark.driver.extraJavaOptions=\"-XX:+PrintGCDetails -XX:+PrintGCTimeStamps\" Driver JVM \u53c2\u6570 spark.driver.cores=2 Driver \u6838\u6570 spark.driver.memory=4g Driver \u5185\u5b58\u5927\u5c0f spark.yarn.driver.memoryOverhead=1g Driver \u5806\u5916\u5185\u5b58\u5927\u5c0f spark.speculation=true \u5f00\u542f\u63a8\u6d4b\u6267\u884c spark.speculation.quantile=0.75 \u8fdb\u884c\u63a8\u6d4b\u6267\u884c\u7684\u4efb\u52a1\u5b8c\u6210\u6700\u5c0f\u6bd4\u4f8b spark.speculation.multiplier=1.5 \u6ee1\u8db3\u6700\u5c0f\u5b8c\u6210\u6bd4\u4f8b\u6761\u4ef6\u4e0b\uff0c\u8fdb\u884c\u63a8\u6d4b\u6267\u884c\u7684\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u5927\u4e8e\u5b8c\u6210\u4efb\u52a1\u6267\u884c\u65f6\u95f4\u4e2d\u4f4d\u6570\u7684\u6700\u5c0f\u500d\u6570 spark.memory.fraction=0.6 \u6267\u884c\u548c\u5b58\u50a8\u5185\u5b58\u5360\u5806\u5185\u5b58\u7684\u6bd4\u4f8b\uff0c\u589e\u52a0\u53ef\u80fd\u5bfc\u81f4OOM\uff1b300MB\u4fdd\u7559\u5185\u5b58\uff0c\u5269\u4e0b\u4e3a\u7528\u6237\u5185\u5b58(1.0 - spark.memory.fraction) * (SYSTEM_MEMORY - RESERVED_MEMORY) spark.memory.storageFraction=0.5 \u5b58\u50a8\u5185\u5b58\u514d\u4e8e\u88ab\u8ba1\u7b97\u9a71\u9010\u7684\u5185\u5b58\u6bd4\u4f8b\uff0c\u9a71\u9010\u901a\u8fc7LRU\u673a\u5236\uff0c\u8ba1\u7b97\u5185\u5b58\u4e0d\u8db3\u53ef\u80fd\u5bfc\u81f4spill\u5230\u78c1\u76d8 spark.memory.offHeap.enabled=true \u4f7f\u7528\u5806\u5916\u5185\u5b58\uff0c\u51cf\u5c11GC\u538b\u529b spark.memory.offHeap.size=2147483648 \u8bbe\u7f6e\u5806\u5916\u5185\u5b58\u5927\u5c0f spark.shuffle.file.buffer=32k shuffle\u8f93\u51fa\u5185\u5b58\u7f13\u51b2\u5927\u5c0f\uff0c\u51cf\u5c11\u78c1\u76d8IO\u538b\u529b spark.unsafe.sorter.spill.reader.buffer.size=2097152 \u8bfb\u53d6spill\u6587\u4ef6\u7f13\u51b2\u5927\u5c0f spark.sql.autoBroadcastJoinThreshold=10m \u8868\u88ab\u5e7f\u64ad\u7684\u6700\u5927\u503c spark.sql.broadcastTimeout=300 \u8868\u88ab\u5e7f\u64ad\u7684\u8d85\u65f6\u65f6\u95f4 spark.dynamicAllocation.enabled=true \u5f00\u542f\u52a8\u6001\u8d44\u6e90\u5206\u914d spark.dynamicAllocation.minExecutors=20 \u6700\u5c11 Executor \u6570\u91cf spark.dynamicAllocation.maxExecutors=200 \u6700\u591a Executor \u6570\u91cf spark.shuffle.service.enabled=true \u5f00\u542f\u5916\u90e8 Shuffle Service spark.shuffle.service.port=7337 Shuffle Service \u7aef\u53e3 spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2 FileOutputCommitter \u4f7f\u7528 V2 \u7b97\u6cd5\uff0c\u51cf\u5c11commitJob\u8017\u65f6\uff0cV1 \u589e\u52a0\u4e86\u4e00\u81f4\u6027\u4fdd\u8bc1","title":"Spark \u5e38\u7528\u53c2\u6570"},{"location":"week/2019/0623/#share","text":"","title":"Share"},{"location":"week/2019/0623/#spark-shuffle-service","text":"","title":"Spark Shuffle Service"},{"location":"week/2019/0623/#reference","text":"","title":"Reference"},{"location":"week/2019/0630/","text":"ARTS - 2019 Week 6-5 \u00b6 20190630~20190706 Algorithm \u00b6 26. Remove Duplicates from Sorted Array 27. Remove Element 28. Implement strStr() 35. Search Insert Position Review \u00b6 TuneIn: How to Get Your Hadoop/Spark Jobs Tuned While You\u2019re Sleeping \u00b6 Have you ever tuned a Spark, Hive or Pig job? If yes, then you must know that it is a never ending cycle of executing the job, observing the running job, making sense out of hundreds of metrics and then re-running it with the better parameters. Imagine doing this for tens of thousands of jobs. Performance optimization at this scale manually is tedious, requires significant expertise and results into wasting a lot of resources to do the same task again and again. As Hadoop/Spark is the natural choice for any data processing with many naive users, it becomes important to develop a tool to automatically tune Hadoop/Spark jobs. At LinkedIn we tried to solve the problem using Dr. Elephant, an open-sourced self-serve performance monitoring and tuning tool for Hadoop and Spark, used at LinkedIn and various other companies. While it has proven to be very successful, it relies on the developers\u2019 initiative to check and apply the recommendation manually. It also expects some expertise from developers to arrive at the optimal configuration from the recommendations. In this talk we will discuss TuneIn, an auto tuning framework developed on top of Dr. Elephant. We will describe how we are using an iterative approach of optimization to find optimal parameters. We will discuss the various optimization algorithms we tried and why we found Particle Swarm Optimization algorithm to give best results. We will talk about how we avoided using any extra execution and tuned the jobs during their regular scheduled execution. We go into detail on techniques employed to ensure faster convergence and zero failed executions while tuning. We will showcase how we achieved more than 50% gain in resource usage by tuning a small set of parameters. We will also talk about the lessons learned and the future roadmap. \u3010PDF\u3011TuneIn: How to Get Your Hadoop/Spark Jobs Tuned While You\u2019re Sleeping \u80cc\u666f \u00b6 \u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387 \u51cf\u5c11\u4f5c\u4e1a\u6267\u884c\u65f6\u95f4 Dr. Elephant \u00b6 Particle Swarm Optimization (PSO) \u641c\u7d22\u7a7a\u95f4\uff1a\u5f85\u8c03\u4f18\u7684\u53c2\u6570 \u4f18\u5316\uff1a\u907f\u514d\u5931\u8d25\u3001\u52a0\u5feb\u6536\u655b\u3001\u7ea6\u675f\u4f18\u5316\u3001\u53c2\u6570\u4f9d\u8d56 \u635f\u5931\u51fd\u6570\uff1a\u9884\u4f30\u8d44\u6e90\u7684\u4f7f\u7528 \u60e9\u7f5a\u51fd\u6570\uff1a\u907f\u514d\u8fc7\u62df\u5408\uff0c\u5bfc\u81f4\u8d44\u6e90\u5206\u914d\u8fc7\u4e8e\u82db\u523b \u6d41\u7a0b \u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u83b7\u53d6\u4f5c\u4e1a\u6267\u884c\u53c2\u6570 \u8fd4\u56de\u4f18\u5316\u540e\u7684\u53c2\u6570 \u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u63d0\u4ea4\u4f5c\u4e1a \u83b7\u53d6\u4f5c\u4e1a\u5ea6\u91cf\u4fe1\u606f\uff0c\u5206\u6790\u4f5c\u4e1a \u7279\u5f81 \u5bf9\u5468\u671f\u8fd0\u884c\u4efb\u52a1\u8c03\u4f18\uff0c\u53ef\u4ee5\u81ea\u52a8\u5173\u95ed\u8c03\u4f18 \u63a7\u5236\u8d44\u6e90\u4f7f\u7528\u548c\u6267\u884c\u65f6\u95f4\uff0c\u652f\u6301hive\u3001spark\uff0c\u6613\u4e8e\u96c6\u6210 \u5bb9\u9519\u5904\u7406\uff0c\u53c2\u6570\u8c03\u6574\u7ea6\u675f\uff0c\u5931\u8d25\u5904\u7406 \u89c4\u5212 \u4f18\u5316\u6267\u884c\u65f6\u957f \u901a\u8fc7IPSO\u63d0\u5347\u6536\u655b\u901f\u5ea6 \u66f4\u667a\u80fd\u7684\u4f18\u5316\u5f00\u5173 Tip \u00b6 Kafka \u96c6\u7fa4\u53c2\u6570 \u00b6 Broker \u65e5\u5fd7\u5b58\u653e\u8def\u5f84\uff1a log.dirs=/data/kafka1,/data/kafka2 ZooKeeper \u96c6\u7fa4\u5730\u5740\uff0c\u534f\u8c03\u3001\u7ba1\u7406\uff0c\u4fdd\u5b58 Kafka \u96c6\u7fa4\u5143\u6570\u636e\u4fe1\u606f\uff1a zookeeper.connect=zk1:2181,zk2:2181,zk3:2181/kafka1 \u76d1\u542c\u5668\uff0c\u8bbf\u95ee Kafka \u670d\u52a1\u7684\u534f\u8bae\u3001\u4e3b\u673a\u540d\u548c\u7aef\u53e3\uff1a listeners=PLAINTEXT://localhost:9092 \u4e0d\u5141\u8bb8\u81ea\u52a8\u521b\u5efa Topic\uff1a auto.create.topics.enable=false \u4e0d\u5141\u8bb8 Unclean Leader \u9009\u4e3e\uff1a unclean.leader.election.enable=false \u4e0d\u5141\u8bb8\u5b9a\u671f\u8fdb\u884c Leader \u9009\u4e3e\uff1a auto.leader.rebalance.enable=false \u6d88\u606f\u4fdd\u5b58\u7684\u6700\u957f\u65f6\u95f4\uff1a log.retention.hour{minutes|ms}=168 \u603b\u4f53\u6d88\u606f\u4fdd\u5b58\u7684\u6700\u5927\u5bb9\u91cf\uff1a log.retention.bytes=100 000 000 000 \u63a5\u6536\u6bcf\u6761\u6d88\u606f\u7684\u6700\u5927\u5927\u5c0f\uff1a message.max.bytes=1 000 000 Topic \u6d88\u606f\u4fdd\u5b58\u7684\u6700\u957f\u65f6\u95f4\uff1a retention.ms=604 800 000 \u63a5\u6536\u6bcf\u6761\u6d88\u606f\u7684\u6700\u5927\u5927\u5c0f\uff1a max.message.bytes=1 000 000 JVM \u5806\u5185\u5b58\u8bbe\u7f6e\uff1a export KAFKA_HEAP_OPTS=--Xms6g --Xmx6g GC\u53c2\u6570\u8bbe\u7f6e\uff1a export KAFKA_JVM_PERFORMANCE_OPTS=-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 OS \u6587\u4ef6\u63cf\u8ff0\u7b26\u9650\u5236\uff1a ulimit -n 1000000 \u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\uff1a XFS\u3001ZFS \u8c03\u6574 Swap \u7a7a\u95f4\u6bd4\u4f8b\uff1a vm.swappiness=1 \u5173\u95ed\u8bbf\u95ee\u65f6\u95f4 Share \u00b6 Spark \u6e90\u7801\u8c03\u8bd5 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 6-5"},{"location":"week/2019/0630/#arts-2019-week-6-5","text":"20190630~20190706","title":"ARTS - 2019 Week 6-5"},{"location":"week/2019/0630/#algorithm","text":"26. Remove Duplicates from Sorted Array 27. Remove Element 28. Implement strStr() 35. Search Insert Position","title":"Algorithm"},{"location":"week/2019/0630/#review","text":"","title":"Review"},{"location":"week/2019/0630/#tunein-how-to-get-your-hadoopspark-jobs-tuned-while-youre-sleeping","text":"Have you ever tuned a Spark, Hive or Pig job? If yes, then you must know that it is a never ending cycle of executing the job, observing the running job, making sense out of hundreds of metrics and then re-running it with the better parameters. Imagine doing this for tens of thousands of jobs. Performance optimization at this scale manually is tedious, requires significant expertise and results into wasting a lot of resources to do the same task again and again. As Hadoop/Spark is the natural choice for any data processing with many naive users, it becomes important to develop a tool to automatically tune Hadoop/Spark jobs. At LinkedIn we tried to solve the problem using Dr. Elephant, an open-sourced self-serve performance monitoring and tuning tool for Hadoop and Spark, used at LinkedIn and various other companies. While it has proven to be very successful, it relies on the developers\u2019 initiative to check and apply the recommendation manually. It also expects some expertise from developers to arrive at the optimal configuration from the recommendations. In this talk we will discuss TuneIn, an auto tuning framework developed on top of Dr. Elephant. We will describe how we are using an iterative approach of optimization to find optimal parameters. We will discuss the various optimization algorithms we tried and why we found Particle Swarm Optimization algorithm to give best results. We will talk about how we avoided using any extra execution and tuned the jobs during their regular scheduled execution. We go into detail on techniques employed to ensure faster convergence and zero failed executions while tuning. We will showcase how we achieved more than 50% gain in resource usage by tuning a small set of parameters. We will also talk about the lessons learned and the future roadmap. \u3010PDF\u3011TuneIn: How to Get Your Hadoop/Spark Jobs Tuned While You\u2019re Sleeping","title":"TuneIn: How to Get Your Hadoop/Spark Jobs Tuned While You\u2019re Sleeping"},{"location":"week/2019/0630/#_1","text":"\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387 \u51cf\u5c11\u4f5c\u4e1a\u6267\u884c\u65f6\u95f4","title":"\u80cc\u666f"},{"location":"week/2019/0630/#dr-elephant","text":"Particle Swarm Optimization (PSO) \u641c\u7d22\u7a7a\u95f4\uff1a\u5f85\u8c03\u4f18\u7684\u53c2\u6570 \u4f18\u5316\uff1a\u907f\u514d\u5931\u8d25\u3001\u52a0\u5feb\u6536\u655b\u3001\u7ea6\u675f\u4f18\u5316\u3001\u53c2\u6570\u4f9d\u8d56 \u635f\u5931\u51fd\u6570\uff1a\u9884\u4f30\u8d44\u6e90\u7684\u4f7f\u7528 \u60e9\u7f5a\u51fd\u6570\uff1a\u907f\u514d\u8fc7\u62df\u5408\uff0c\u5bfc\u81f4\u8d44\u6e90\u5206\u914d\u8fc7\u4e8e\u82db\u523b \u6d41\u7a0b \u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u83b7\u53d6\u4f5c\u4e1a\u6267\u884c\u53c2\u6570 \u8fd4\u56de\u4f18\u5316\u540e\u7684\u53c2\u6570 \u4f5c\u4e1a\u8c03\u5ea6\u7cfb\u7edf\u63d0\u4ea4\u4f5c\u4e1a \u83b7\u53d6\u4f5c\u4e1a\u5ea6\u91cf\u4fe1\u606f\uff0c\u5206\u6790\u4f5c\u4e1a \u7279\u5f81 \u5bf9\u5468\u671f\u8fd0\u884c\u4efb\u52a1\u8c03\u4f18\uff0c\u53ef\u4ee5\u81ea\u52a8\u5173\u95ed\u8c03\u4f18 \u63a7\u5236\u8d44\u6e90\u4f7f\u7528\u548c\u6267\u884c\u65f6\u95f4\uff0c\u652f\u6301hive\u3001spark\uff0c\u6613\u4e8e\u96c6\u6210 \u5bb9\u9519\u5904\u7406\uff0c\u53c2\u6570\u8c03\u6574\u7ea6\u675f\uff0c\u5931\u8d25\u5904\u7406 \u89c4\u5212 \u4f18\u5316\u6267\u884c\u65f6\u957f \u901a\u8fc7IPSO\u63d0\u5347\u6536\u655b\u901f\u5ea6 \u66f4\u667a\u80fd\u7684\u4f18\u5316\u5f00\u5173","title":"Dr. Elephant"},{"location":"week/2019/0630/#tip","text":"","title":"Tip"},{"location":"week/2019/0630/#kafka","text":"Broker \u65e5\u5fd7\u5b58\u653e\u8def\u5f84\uff1a log.dirs=/data/kafka1,/data/kafka2 ZooKeeper \u96c6\u7fa4\u5730\u5740\uff0c\u534f\u8c03\u3001\u7ba1\u7406\uff0c\u4fdd\u5b58 Kafka \u96c6\u7fa4\u5143\u6570\u636e\u4fe1\u606f\uff1a zookeeper.connect=zk1:2181,zk2:2181,zk3:2181/kafka1 \u76d1\u542c\u5668\uff0c\u8bbf\u95ee Kafka \u670d\u52a1\u7684\u534f\u8bae\u3001\u4e3b\u673a\u540d\u548c\u7aef\u53e3\uff1a listeners=PLAINTEXT://localhost:9092 \u4e0d\u5141\u8bb8\u81ea\u52a8\u521b\u5efa Topic\uff1a auto.create.topics.enable=false \u4e0d\u5141\u8bb8 Unclean Leader \u9009\u4e3e\uff1a unclean.leader.election.enable=false \u4e0d\u5141\u8bb8\u5b9a\u671f\u8fdb\u884c Leader \u9009\u4e3e\uff1a auto.leader.rebalance.enable=false \u6d88\u606f\u4fdd\u5b58\u7684\u6700\u957f\u65f6\u95f4\uff1a log.retention.hour{minutes|ms}=168 \u603b\u4f53\u6d88\u606f\u4fdd\u5b58\u7684\u6700\u5927\u5bb9\u91cf\uff1a log.retention.bytes=100 000 000 000 \u63a5\u6536\u6bcf\u6761\u6d88\u606f\u7684\u6700\u5927\u5927\u5c0f\uff1a message.max.bytes=1 000 000 Topic \u6d88\u606f\u4fdd\u5b58\u7684\u6700\u957f\u65f6\u95f4\uff1a retention.ms=604 800 000 \u63a5\u6536\u6bcf\u6761\u6d88\u606f\u7684\u6700\u5927\u5927\u5c0f\uff1a max.message.bytes=1 000 000 JVM \u5806\u5185\u5b58\u8bbe\u7f6e\uff1a export KAFKA_HEAP_OPTS=--Xms6g --Xmx6g GC\u53c2\u6570\u8bbe\u7f6e\uff1a export KAFKA_JVM_PERFORMANCE_OPTS=-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 OS \u6587\u4ef6\u63cf\u8ff0\u7b26\u9650\u5236\uff1a ulimit -n 1000000 \u6587\u4ef6\u7cfb\u7edf\u7c7b\u578b\uff1a XFS\u3001ZFS \u8c03\u6574 Swap \u7a7a\u95f4\u6bd4\u4f8b\uff1a vm.swappiness=1 \u5173\u95ed\u8bbf\u95ee\u65f6\u95f4","title":"Kafka \u96c6\u7fa4\u53c2\u6570"},{"location":"week/2019/0630/#share","text":"","title":"Share"},{"location":"week/2019/0630/#spark","text":"","title":"Spark \u6e90\u7801\u8c03\u8bd5"},{"location":"week/2019/0630/#reference","text":"","title":"Reference"},{"location":"week/2019/0707/","text":"ARTS - 2019 Week 7-1 \u00b6 20190707~20190713 Algorithm \u00b6 38. Count and Say Review \u00b6 Understanding Query Plans and Spark UIs \u00b6 The common use cases of Spark SQL include ad hoc analysis, logical warehouse, query federation, and ETL processing. Spark SQL also powers the other Spark libraries, including structured streaming for stream processing, MLlib for machine learning, and GraphFrame for graph-parallel computation. For boosting the speed of your Spark applications, you can perform the optimization efforts on the queries prior employing to the production systems. Spark query plans and Spark UIs provide you insight on the performance of your queries. This talk discloses how to read and tune the query plans for enhanced performance. It will also cover the major related features in the recent and upcoming releases of Apache Spark. \u3010PDF\u3011Understanding Query Plans and Spark UIs Read Plan \u00b6 Spark UI \u6216\u8005 Spark History Server \u7684 SQL \u6807\u7b7e\u9875 - Details \u6309\u94ae Parsed Plan Analyzed Plan Optimized Plan Physical Plan Understand and Tune Plans \u00b6 \u660e\u786e\u67e5\u8be2\u6570\u636e\u7684\u7c7b\u578b\uff0c\u907f\u514d\u7c7b\u578b\u9690\u5f0f\u8f6c\u6362\u95ee\u9898 \u521b\u5efa Spark ORC \u6a21\u5f0f\u8868\uff08using orc\uff09\uff0c\u81ea\u52a8\u8c13\u8bcd\u4e0b\u63a8 \u5f00\u542f\u5d4c\u5957\u7ed3\u6784\u88c1\u526a\uff08spark.sql.optimizer.nestedSchemaPruning.enabled=true\uff09 \u4f7f\u7528\u975e\u786e\u5b9a UDF\uff08asNondeterministic\uff09\uff0c\u907f\u514d\u4e0d\u6b63\u786e\u7684\u91cd\u590d\u8c03\u7528 \u4f7f\u7528\u8de8 Session \u7684\u7f13\u5b58 Spark 3.0 Join Hints(BROADCAST/MERGE/SHUFFLE_HASH/SHUFFLE_REPLICATE_NL) Track Execution \u00b6 \u4e00\u6b21\u67e5\u8be2\u5bf9\u5e94\u591a\u4e2a\u4f5c\u4e1a\uff0c\u4e00\u4e2a\u4f5c\u4e1a\u5bf9\u5e94\u4e00\u4e2aDAG \u6807\u7b7e\u9875\uff1aJob\u3001Stage\u3001Executor Job\uff1a\u6267\u884c\u65f6\u95f4\u3001\u4efb\u52a1\u6570\u91cf\u4e0e\u72b6\u6001 Stage\uff1a\u6267\u884c\u65f6\u95f4\u3001\u5f02\u5e38\u4efb\u52a1\u3001\u8017\u65f6\u4efb\u52a1\u3001\u4efb\u52a1\u5747\u8861\u3001\u6570\u636e\u503e\u659c\u3001\u4efb\u52a1\u6570\u91cf\u4e0e\u72b6\u6001\u3001\u5206\u533a\u6570\u91cf\u3001\u672c\u5730\u6027 Executor\uff1a\u5b58\u50a8\u3001\u4efb\u52a1\u3001GC\u3001Shuffle\u3001\u7ebf\u7a0b\u4fe1\u606f Delta Lake \u901a\u8fc7\u5728 transaction log \u4e2d\u5b58\u50a8\u5143\u6570\u636e\u4fe1\u606f\uff0c\u66ff\u4ee3\u539f\u7528\u57fa\u4e8e metastore \u5bf9\u5e94\u7684\u5206\u533a\u53ef\u80fd\u975e\u5e38\u591a - \u4e0d\u53d7 Hive Metastore \u5f71\u54cd \u751f\u6210\u7684\u6587\u4ef6\u53ef\u80fd\u975e\u5e38\u591a - \u5143\u6570\u636e\u4e0e\u6570\u636e\u5206\u79bb\uff0c\u6570\u636e\u5408\u5e76\u5199 \u65b0\u7684\u6570\u636e\u4e0d\u76f4\u63a5\u53ef\u89c1\uff0c\u9700\u5237\u65b0\u8868\uff08Refresh Table\uff09 - \u8bfb\u53d6\u6b63\u5728\u8ba1\u7b97\u7684\u6570\u636e \u7279\u6027 \u5b8c\u5168 ACID \u4e8b\u52a1\u652f\u6301 Schema \u7ba1\u7406 \u6570\u636e\u65f6\u95f4\u53ca\u7248\u672c\u4fe1\u606f \u7edf\u4e00\u6279\u5904\u7406\u4e0e\u6d41\u8ba1\u7b97\u652f\u6301 \u5143\u6570\u636e\u7ba1\u7406\u80fd\u529b \u652f\u6301\u66f4\u65b0\u4e0e\u5220\u9664 \u6570\u636e\u53ef\u9884\u671f Tip \u00b6 Hive \u5e38\u7528\u53c2\u6570 \u00b6 set hive.mapred.mode=strict; -- \u4f7f\u7528\u4e25\u683c\u6a21\u5f0f\uff0c\u68c0\u67e5\u53ef\u80fd\u4e0d\u5408\u7406\u8ba1\u7b97 set hive.exec.parallel=true\uff1b-- \u5f00\u542f\u5e76\u53d1\u6267\u884c set hive.exec.parallel.thread.number=16; -- \u6700\u5927\u5e76\u884c\u5ea6 set hive.exec.dynamic.partition=true; -- \u5f00\u542f\u52a8\u6001\u5206\u533a set hive.exec.dynamic.partition.mode=nonstrict; -- \u4f7f\u7528\u975e\u4e25\u683c\u6a21\u5f0f\uff0c\u5141\u8bb8\u5168\u90e8\u5206\u533a\u5b57\u6bb5\u4e3a\u52a8\u6001\u5206\u533a set hive.exec.max.dynamic.partitions=1000; -- \u5141\u8bb8\u6700\u5927\u521b\u5efa\u5206\u533a\u603b\u6570 set hive.exec.max.dynamic.partitions.pernode=100; -- \u6bcf\u4e2aMapper\u6216Reducer\u8282\u70b9\u5141\u8bb8\u6700\u5927\u521b\u5efa\u5206\u533a\u603b\u6570 set hive.merge.mapfiles=true; -- \u5408\u5e76mapper\u4f5c\u4e1a\u5c0f\u6587\u4ef6 set hive.merge.mapredfiles=true; -- \u5408\u5e76reducer\u4f5c\u4e1a\u5c0f\u6587\u4ef6 set hive.merge.size.per.task=256000000; -- \u5408\u5e76\u6587\u4ef6\u5927\u5c0f set hive.merge.smallfiles.avgsize=64000000; -- \u5f53\u6587\u4ef6\u5e73\u5747\u5927\u5c0f\u5c0f\u4e8e\u8be5\u503c\uff0c\u542f\u52a8Job\u5408\u5e76\u5c0f\u6587\u4ef6 Share \u00b6 \u6f2b\u8c08\u6570\u636e\u8d28\u91cf \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 7-1"},{"location":"week/2019/0707/#arts-2019-week-7-1","text":"20190707~20190713","title":"ARTS - 2019 Week 7-1"},{"location":"week/2019/0707/#algorithm","text":"38. Count and Say","title":"Algorithm"},{"location":"week/2019/0707/#review","text":"","title":"Review"},{"location":"week/2019/0707/#understanding-query-plans-and-spark-uis","text":"The common use cases of Spark SQL include ad hoc analysis, logical warehouse, query federation, and ETL processing. Spark SQL also powers the other Spark libraries, including structured streaming for stream processing, MLlib for machine learning, and GraphFrame for graph-parallel computation. For boosting the speed of your Spark applications, you can perform the optimization efforts on the queries prior employing to the production systems. Spark query plans and Spark UIs provide you insight on the performance of your queries. This talk discloses how to read and tune the query plans for enhanced performance. It will also cover the major related features in the recent and upcoming releases of Apache Spark. \u3010PDF\u3011Understanding Query Plans and Spark UIs","title":"Understanding Query Plans and Spark UIs"},{"location":"week/2019/0707/#read-plan","text":"Spark UI \u6216\u8005 Spark History Server \u7684 SQL \u6807\u7b7e\u9875 - Details \u6309\u94ae Parsed Plan Analyzed Plan Optimized Plan Physical Plan","title":"Read Plan"},{"location":"week/2019/0707/#understand-and-tune-plans","text":"\u660e\u786e\u67e5\u8be2\u6570\u636e\u7684\u7c7b\u578b\uff0c\u907f\u514d\u7c7b\u578b\u9690\u5f0f\u8f6c\u6362\u95ee\u9898 \u521b\u5efa Spark ORC \u6a21\u5f0f\u8868\uff08using orc\uff09\uff0c\u81ea\u52a8\u8c13\u8bcd\u4e0b\u63a8 \u5f00\u542f\u5d4c\u5957\u7ed3\u6784\u88c1\u526a\uff08spark.sql.optimizer.nestedSchemaPruning.enabled=true\uff09 \u4f7f\u7528\u975e\u786e\u5b9a UDF\uff08asNondeterministic\uff09\uff0c\u907f\u514d\u4e0d\u6b63\u786e\u7684\u91cd\u590d\u8c03\u7528 \u4f7f\u7528\u8de8 Session \u7684\u7f13\u5b58 Spark 3.0 Join Hints(BROADCAST/MERGE/SHUFFLE_HASH/SHUFFLE_REPLICATE_NL)","title":"Understand and Tune Plans"},{"location":"week/2019/0707/#track-execution","text":"\u4e00\u6b21\u67e5\u8be2\u5bf9\u5e94\u591a\u4e2a\u4f5c\u4e1a\uff0c\u4e00\u4e2a\u4f5c\u4e1a\u5bf9\u5e94\u4e00\u4e2aDAG \u6807\u7b7e\u9875\uff1aJob\u3001Stage\u3001Executor Job\uff1a\u6267\u884c\u65f6\u95f4\u3001\u4efb\u52a1\u6570\u91cf\u4e0e\u72b6\u6001 Stage\uff1a\u6267\u884c\u65f6\u95f4\u3001\u5f02\u5e38\u4efb\u52a1\u3001\u8017\u65f6\u4efb\u52a1\u3001\u4efb\u52a1\u5747\u8861\u3001\u6570\u636e\u503e\u659c\u3001\u4efb\u52a1\u6570\u91cf\u4e0e\u72b6\u6001\u3001\u5206\u533a\u6570\u91cf\u3001\u672c\u5730\u6027 Executor\uff1a\u5b58\u50a8\u3001\u4efb\u52a1\u3001GC\u3001Shuffle\u3001\u7ebf\u7a0b\u4fe1\u606f Delta Lake \u901a\u8fc7\u5728 transaction log \u4e2d\u5b58\u50a8\u5143\u6570\u636e\u4fe1\u606f\uff0c\u66ff\u4ee3\u539f\u7528\u57fa\u4e8e metastore \u5bf9\u5e94\u7684\u5206\u533a\u53ef\u80fd\u975e\u5e38\u591a - \u4e0d\u53d7 Hive Metastore \u5f71\u54cd \u751f\u6210\u7684\u6587\u4ef6\u53ef\u80fd\u975e\u5e38\u591a - \u5143\u6570\u636e\u4e0e\u6570\u636e\u5206\u79bb\uff0c\u6570\u636e\u5408\u5e76\u5199 \u65b0\u7684\u6570\u636e\u4e0d\u76f4\u63a5\u53ef\u89c1\uff0c\u9700\u5237\u65b0\u8868\uff08Refresh Table\uff09 - \u8bfb\u53d6\u6b63\u5728\u8ba1\u7b97\u7684\u6570\u636e \u7279\u6027 \u5b8c\u5168 ACID \u4e8b\u52a1\u652f\u6301 Schema \u7ba1\u7406 \u6570\u636e\u65f6\u95f4\u53ca\u7248\u672c\u4fe1\u606f \u7edf\u4e00\u6279\u5904\u7406\u4e0e\u6d41\u8ba1\u7b97\u652f\u6301 \u5143\u6570\u636e\u7ba1\u7406\u80fd\u529b \u652f\u6301\u66f4\u65b0\u4e0e\u5220\u9664 \u6570\u636e\u53ef\u9884\u671f","title":"Track Execution"},{"location":"week/2019/0707/#tip","text":"","title":"Tip"},{"location":"week/2019/0707/#hive","text":"set hive.mapred.mode=strict; -- \u4f7f\u7528\u4e25\u683c\u6a21\u5f0f\uff0c\u68c0\u67e5\u53ef\u80fd\u4e0d\u5408\u7406\u8ba1\u7b97 set hive.exec.parallel=true\uff1b-- \u5f00\u542f\u5e76\u53d1\u6267\u884c set hive.exec.parallel.thread.number=16; -- \u6700\u5927\u5e76\u884c\u5ea6 set hive.exec.dynamic.partition=true; -- \u5f00\u542f\u52a8\u6001\u5206\u533a set hive.exec.dynamic.partition.mode=nonstrict; -- \u4f7f\u7528\u975e\u4e25\u683c\u6a21\u5f0f\uff0c\u5141\u8bb8\u5168\u90e8\u5206\u533a\u5b57\u6bb5\u4e3a\u52a8\u6001\u5206\u533a set hive.exec.max.dynamic.partitions=1000; -- \u5141\u8bb8\u6700\u5927\u521b\u5efa\u5206\u533a\u603b\u6570 set hive.exec.max.dynamic.partitions.pernode=100; -- \u6bcf\u4e2aMapper\u6216Reducer\u8282\u70b9\u5141\u8bb8\u6700\u5927\u521b\u5efa\u5206\u533a\u603b\u6570 set hive.merge.mapfiles=true; -- \u5408\u5e76mapper\u4f5c\u4e1a\u5c0f\u6587\u4ef6 set hive.merge.mapredfiles=true; -- \u5408\u5e76reducer\u4f5c\u4e1a\u5c0f\u6587\u4ef6 set hive.merge.size.per.task=256000000; -- \u5408\u5e76\u6587\u4ef6\u5927\u5c0f set hive.merge.smallfiles.avgsize=64000000; -- \u5f53\u6587\u4ef6\u5e73\u5747\u5927\u5c0f\u5c0f\u4e8e\u8be5\u503c\uff0c\u542f\u52a8Job\u5408\u5e76\u5c0f\u6587\u4ef6","title":"Hive \u5e38\u7528\u53c2\u6570"},{"location":"week/2019/0707/#share","text":"","title":"Share"},{"location":"week/2019/0707/#_1","text":"","title":"\u6f2b\u8c08\u6570\u636e\u8d28\u91cf"},{"location":"week/2019/0707/#reference","text":"","title":"Reference"},{"location":"week/2019/0714/","text":"ARTS - 2019 Week 7-2 \u00b6 20190714~20190720 Algorithm \u00b6 53. Maximum Subarray 58. Length of Last Word Review \u00b6 Oversubscribing Apache Spark Resource Usage for Fun and $$$ \u00b6 Apache Spark is quickly being adopted at Facebook and now powers an important portion of Facebook\u2019s batch ETL workload. While Spark is typically more efficient than Hive, we continue to search for opportunities to further reduce hardware costs. Recently, we have started an effort to apply custom resource oversubscription for every unique Spark job. We often observe that system resources (e.g. CPU / memory) tend to be underutilized in Spark jobs. For example, when the data can not fit in memory, disk spill may dominate overall performance. Since the default configuration allocates one CPU core per Spark task, this can lead to situations where Spark jobs are not using all the CPU resources allocated to them and as a result, the overall cluster CPU utilization can remain low even under peak scheduling conditions. Similarly, for memory, depending on the input data and shuffle sizes, the job might not fully utilize its reserved memory and a significant amount of cluster memory can be wasted. In this session, we will describe the CPU and memory oversubscription technique we use to increase overall resource utilization of our Spark clusters. We leverage a historical stats based resource oversubscription algorithm that considers the historical resource usage of each unique Spark job and predicts the ideal resource allocation to minimize unused resources and increase the cluster utilization. We\u2019ll also explain the changes necessary to Spark and the resource manager in order to support oversubscription. Finally, we will conclude by sharing our results and the future direction for this project. \u3010PDF\u3011Tuning Apache Spark Resource Usage For Fun And Efficiency Spark \u8fd0\u884c\u6a21\u578b\u3001\u5185\u5b58\u6a21\u578b\uff1a \u00b6 CPU/IO\uff1aMetrics\u3001Efficiency Memory\uff1aMetrics\u3001Efficiency History-based Resource Auto-tuning \u00b6 \u9700\u8981 CPU \u6838\u652f\u6301\u5206\u914d\u5c0f\u6570 \u5468\u671f\u8fd0\u884c\u4f5c\u4e1a\u8d44\u6e90\u4f7f\u7528\u7684\u65e5\u5fd7 \u67b6\u6784 \u9884\u6d4b\u4f5c\u4e1a\u6240\u9700\u8981 CPU \u548c\u5185\u5b58 \u4f5c\u4e1a\u83b7\u53d6\u9884\u6d4b\u7684\u8d44\u6e90\u8fdb\u884c\u7533\u8bf7 \u6570\u636e \u4f5c\u4e1a\u8fc7\u53bb10\u5929\u8fd0\u884c\u7684\u5386\u53f2\u4fe1\u606f CPU \u4f7f\u7528\u65f6\u95f4\u3001CPU \u7533\u8bf7\u65f6\u95f4 Executor \u6700\u5927\u4f7f\u7528\u5185\u5b58 \u4f5c\u4e1a\u6807\u8bc6 \u7b97\u6cd5 \u5185\u5b58\u4f7f\u7528\u91cf CPU\u4f7f\u7528\u91cf \u95ee\u9898 CPU \u4e0a\u4e0b\u6587\u5207\u6362 \u5185\u5b58\u4f7f\u7528\u8d85\u9650\u989d\u88ab Kill Kill Job Result CPU\uff1a\u7533\u8bf7\u3001\u4f7f\u7528\u3001\u5269\u4f59 Memory\uff1a\u7533\u8bf7\u3001\u4f7f\u7528\u3001\u5269\u4f59 Backlog\uff1a\u5ef6\u8fdf\u3001\u79ef\u538b Resource Waiting\uff1a\u8d44\u6e90\u7b49\u5f85\u65f6\u95f4 Tip \u00b6 Spark \u5e38\u7528\u53c2\u6570 \u00b6 spark.executor.cores=4; spark.executor.memory=8G; spark.executor.memory.overhead=4G; spark.task.cpus=1; spark.sql.shuffle.partitions=800; Share \u00b6 Spark SQL \u89c4\u5219 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 7-2"},{"location":"week/2019/0714/#arts-2019-week-7-2","text":"20190714~20190720","title":"ARTS - 2019 Week 7-2"},{"location":"week/2019/0714/#algorithm","text":"53. Maximum Subarray 58. Length of Last Word","title":"Algorithm"},{"location":"week/2019/0714/#review","text":"","title":"Review"},{"location":"week/2019/0714/#oversubscribing-apache-spark-resource-usage-for-fun-and","text":"Apache Spark is quickly being adopted at Facebook and now powers an important portion of Facebook\u2019s batch ETL workload. While Spark is typically more efficient than Hive, we continue to search for opportunities to further reduce hardware costs. Recently, we have started an effort to apply custom resource oversubscription for every unique Spark job. We often observe that system resources (e.g. CPU / memory) tend to be underutilized in Spark jobs. For example, when the data can not fit in memory, disk spill may dominate overall performance. Since the default configuration allocates one CPU core per Spark task, this can lead to situations where Spark jobs are not using all the CPU resources allocated to them and as a result, the overall cluster CPU utilization can remain low even under peak scheduling conditions. Similarly, for memory, depending on the input data and shuffle sizes, the job might not fully utilize its reserved memory and a significant amount of cluster memory can be wasted. In this session, we will describe the CPU and memory oversubscription technique we use to increase overall resource utilization of our Spark clusters. We leverage a historical stats based resource oversubscription algorithm that considers the historical resource usage of each unique Spark job and predicts the ideal resource allocation to minimize unused resources and increase the cluster utilization. We\u2019ll also explain the changes necessary to Spark and the resource manager in order to support oversubscription. Finally, we will conclude by sharing our results and the future direction for this project. \u3010PDF\u3011Tuning Apache Spark Resource Usage For Fun And Efficiency","title":"Oversubscribing Apache Spark Resource Usage for Fun and $$$"},{"location":"week/2019/0714/#spark","text":"CPU/IO\uff1aMetrics\u3001Efficiency Memory\uff1aMetrics\u3001Efficiency","title":"Spark \u8fd0\u884c\u6a21\u578b\u3001\u5185\u5b58\u6a21\u578b\uff1a"},{"location":"week/2019/0714/#history-based-resource-auto-tuning","text":"\u9700\u8981 CPU \u6838\u652f\u6301\u5206\u914d\u5c0f\u6570 \u5468\u671f\u8fd0\u884c\u4f5c\u4e1a\u8d44\u6e90\u4f7f\u7528\u7684\u65e5\u5fd7 \u67b6\u6784 \u9884\u6d4b\u4f5c\u4e1a\u6240\u9700\u8981 CPU \u548c\u5185\u5b58 \u4f5c\u4e1a\u83b7\u53d6\u9884\u6d4b\u7684\u8d44\u6e90\u8fdb\u884c\u7533\u8bf7 \u6570\u636e \u4f5c\u4e1a\u8fc7\u53bb10\u5929\u8fd0\u884c\u7684\u5386\u53f2\u4fe1\u606f CPU \u4f7f\u7528\u65f6\u95f4\u3001CPU \u7533\u8bf7\u65f6\u95f4 Executor \u6700\u5927\u4f7f\u7528\u5185\u5b58 \u4f5c\u4e1a\u6807\u8bc6 \u7b97\u6cd5 \u5185\u5b58\u4f7f\u7528\u91cf CPU\u4f7f\u7528\u91cf \u95ee\u9898 CPU \u4e0a\u4e0b\u6587\u5207\u6362 \u5185\u5b58\u4f7f\u7528\u8d85\u9650\u989d\u88ab Kill Kill Job Result CPU\uff1a\u7533\u8bf7\u3001\u4f7f\u7528\u3001\u5269\u4f59 Memory\uff1a\u7533\u8bf7\u3001\u4f7f\u7528\u3001\u5269\u4f59 Backlog\uff1a\u5ef6\u8fdf\u3001\u79ef\u538b Resource Waiting\uff1a\u8d44\u6e90\u7b49\u5f85\u65f6\u95f4","title":"History-based Resource Auto-tuning"},{"location":"week/2019/0714/#tip","text":"","title":"Tip"},{"location":"week/2019/0714/#spark_1","text":"spark.executor.cores=4; spark.executor.memory=8G; spark.executor.memory.overhead=4G; spark.task.cpus=1; spark.sql.shuffle.partitions=800;","title":"Spark \u5e38\u7528\u53c2\u6570"},{"location":"week/2019/0714/#share","text":"","title":"Share"},{"location":"week/2019/0714/#spark-sql","text":"","title":"Spark SQL \u89c4\u5219"},{"location":"week/2019/0714/#reference","text":"","title":"Reference"},{"location":"week/2019/0721/","text":"ARTS - 2019 Week 7-3 \u00b6 20190721~20190727 Algorithm \u00b6 66. Plus One 67. Add Binary 69. Sqrt(x) 70. Climbing Stairs 83. Remove Duplicates from Sorted List Review \u00b6 Efficient Upserts into Data Lakes with Databricks Delta \u00b6 Databricks Delta, the next-generation engine built on top of Apache Spark\u2122, now supports the MERGE command, which allows you to efficiently upsert and delete records in your data lakes. MERGE dramatically simplifies how a number of common data pipelines can be built; all the complicated multi-hop processes that inefficiently rewrote entire partitions can now be replaced by simple MERGE queries. This finer-grained update capability simplifies how you build your big data pipelines for various use cases ranging from change data capture to GDPR. \u80cc\u666f\u53ca\u95ee\u9898 \u5408\u89c4\u8981\u6c42 \u6570\u636e\u53d8\u66f4 \u6570\u636e\u5220\u9664 \u6548\u7387 \u8d28\u91cf \u652f\u6301 MERGE \u547d\u4ee4 \u652f\u6301\u66f4\u65b0\u53ca\u5220\u9664\u6570\u636e\u6e56\u4e2d\u7684\u8bb0\u5f55 \u7ec6\u7c92\u5ea6\uff1a\u6587\u4ef6\u7c92\u5ea6\uff0c\u800c\u4e0d\u662f\u5206\u533a\u7c92\u5ea6 \u9ad8\u6548\uff1a\u8fc7\u6ee4\u65e0\u5173\u7684\u6570\u636e \u4e8b\u52a1\uff1a\u652f\u6301\u4e8b\u52a1\uff0c\u5e76\u53d1\u8bfb\u5199 Tip \u00b6 Flink \u5e38\u7528\u53c2\u6570 \u00b6 jobmanager.heap.size=8g -- JobManager \u5806\u5185\u5b58\u5927\u5c0f taskmanager.heap.size=4g -- TaskManager \u5806\u5185\u5b58\u5927\u5c0f parallelism.default=1 -- \u4f5c\u4e1a\u7684\u9ed8\u8ba4\u5e76\u884c\u5ea6 taskmanager.numberOfTaskSlots=1 -- TaskManager \u7684\u5e76\u884c\u5ea6 state.checkpoints.dir=hdfs:///checkpoints -- \u8bbe\u7f6e checkpoints \u76ee\u5f55 state.savepoints.dir=hdfs:///savepoints -- \u8bbe\u7f6e savepoints \u76ee\u5f55 state.backend=rocks -- \u8bbe\u7f6e\u72b6\u6001\u5b58\u50a8\u7c7b\u578b state.backend.async=true -- \u4f7f\u7528\u5f02\u6b65\u5feb\u7167 state.backend.incremental=true -- \u521b\u5efa\u589e\u91cf\u72b6\u6001\u5b58\u50a8 Share \u00b6 Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 7-3"},{"location":"week/2019/0721/#arts-2019-week-7-3","text":"20190721~20190727","title":"ARTS - 2019 Week 7-3"},{"location":"week/2019/0721/#algorithm","text":"66. Plus One 67. Add Binary 69. Sqrt(x) 70. Climbing Stairs 83. Remove Duplicates from Sorted List","title":"Algorithm"},{"location":"week/2019/0721/#review","text":"","title":"Review"},{"location":"week/2019/0721/#efficient-upserts-into-data-lakes-with-databricks-delta","text":"Databricks Delta, the next-generation engine built on top of Apache Spark\u2122, now supports the MERGE command, which allows you to efficiently upsert and delete records in your data lakes. MERGE dramatically simplifies how a number of common data pipelines can be built; all the complicated multi-hop processes that inefficiently rewrote entire partitions can now be replaced by simple MERGE queries. This finer-grained update capability simplifies how you build your big data pipelines for various use cases ranging from change data capture to GDPR. \u80cc\u666f\u53ca\u95ee\u9898 \u5408\u89c4\u8981\u6c42 \u6570\u636e\u53d8\u66f4 \u6570\u636e\u5220\u9664 \u6548\u7387 \u8d28\u91cf \u652f\u6301 MERGE \u547d\u4ee4 \u652f\u6301\u66f4\u65b0\u53ca\u5220\u9664\u6570\u636e\u6e56\u4e2d\u7684\u8bb0\u5f55 \u7ec6\u7c92\u5ea6\uff1a\u6587\u4ef6\u7c92\u5ea6\uff0c\u800c\u4e0d\u662f\u5206\u533a\u7c92\u5ea6 \u9ad8\u6548\uff1a\u8fc7\u6ee4\u65e0\u5173\u7684\u6570\u636e \u4e8b\u52a1\uff1a\u652f\u6301\u4e8b\u52a1\uff0c\u5e76\u53d1\u8bfb\u5199","title":"Efficient Upserts into Data Lakes with Databricks Delta"},{"location":"week/2019/0721/#tip","text":"","title":"Tip"},{"location":"week/2019/0721/#flink","text":"jobmanager.heap.size=8g -- JobManager \u5806\u5185\u5b58\u5927\u5c0f taskmanager.heap.size=4g -- TaskManager \u5806\u5185\u5b58\u5927\u5c0f parallelism.default=1 -- \u4f5c\u4e1a\u7684\u9ed8\u8ba4\u5e76\u884c\u5ea6 taskmanager.numberOfTaskSlots=1 -- TaskManager \u7684\u5e76\u884c\u5ea6 state.checkpoints.dir=hdfs:///checkpoints -- \u8bbe\u7f6e checkpoints \u76ee\u5f55 state.savepoints.dir=hdfs:///savepoints -- \u8bbe\u7f6e savepoints \u76ee\u5f55 state.backend=rocks -- \u8bbe\u7f6e\u72b6\u6001\u5b58\u50a8\u7c7b\u578b state.backend.async=true -- \u4f7f\u7528\u5f02\u6b65\u5feb\u7167 state.backend.incremental=true -- \u521b\u5efa\u589e\u91cf\u72b6\u6001\u5b58\u50a8","title":"Flink \u5e38\u7528\u53c2\u6570"},{"location":"week/2019/0721/#share","text":"","title":"Share"},{"location":"week/2019/0721/#flink-cluster-mode-on-yarn","text":"","title":"Flink \u4f5c\u4e1a\u6267\u884c\u6d41\u7a0b\uff08Cluster Mode On YARN\uff09"},{"location":"week/2019/0721/#reference","text":"","title":"Reference"},{"location":"week/2019/0728/","text":"ARTS - 2019 Week 7-4 \u00b6 20190728~20190803 Algorithm \u00b6 94. Binary Tree Inorder Traversal 144. Binary Tree Preorder Traversal 145. Binary Tree Postorder Traversal Review \u00b6 Fast and Reliable Apache Spark SQL Engine \u00b6 Building the next generation Spark SQL engine at speed poses new challenges to both automation and testing. At Databricks, we are implementing a new testing framework for assessing the quality and performance of new developments as they produced. Having more than 1,200 worldwide contributors, Apache Spark follows a rapid pace of development. At this scale, new testing tooling such as random query and data generation, fault injection, longevity stress, and scalability tests are essential to guarantee a reliable and performance Spark later in production. By applying such techniques, we will demonstrate the effectiveness of our testing infrastructure by drilling-down into cases where correctness and performance regressions have been found early. In addition, showing how they have been root-caused and fixed to prevent regressions in production and boosting the continuous delivery of new features. \u3010PDF\u3011Fast and Reliable Apache Spark SQL Engine \u76ee\u6807 making high quality releases automatic and frequent \u95ee\u9898 \u6bcf\u4e2a\u6708\u6570\u767e\u6b21\u63d0\u4ea4\uff0c\u9519\u8bef\u4e00\u5b9a\u4f1a\u53d1\u751f \u9700\u8981\u6295\u5165\u975e\u5e38\u5927\u7684\u7cbe\u529b\u8fdb\u884c\u6d4b\u8bd5\u5de5\u4f5c \u5355\u5143\u6d4b\u8bd5\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u6b63\u786e\u6027\u548c\u6027\u80fd \u65b9\u6848 \u6301\u7eed\u96c6\u6210 \u5206\u7c7b\u4e0e\u62a5\u8b66 \u6b63\u786e\u6027 \u751f\u6210\u968f\u673a\u67e5\u8be2 \u751f\u6210\u968f\u673a\u6570\u636e \u9012\u5f52\u67e5\u8be2\u6a21\u578b \u6982\u7387\u67e5\u8be2\u7c7b\u578b \u67e5\u8be2\u7b97\u5b50\u8986\u76d6\u7387\u5206\u6790 \u6027\u80fd \u57fa\u51c6\u6d4b\u8bd5\uff1a\u8d1f\u8f7d\u3001\u57fa\u51c6\u3001\u6027\u80fd \u6839\u6e90\u5206\u6790\uff1a\u706b\u7130\u56fe\uff08\u6162\u65b9\u6cd5\u3001\u65b0\u65b9\u6cd5\uff09 \u603b\u7ed3 \u81ea\u52a8\u5316\u5de5\u5177\u4fdd\u969c\u6b63\u786e\u6027\u4e0e\u6027\u80fd Tip \u00b6 HBase \u5ba2\u6237\u7aef\u4f18\u5316 \u00b6 scan \u8bbe\u7f6e\u5408\u7406\u7684\u7f13\u5b58\uff1ascan.setCaching(1000); get \u4f7f\u7528\u6279\u91cf\u8bf7\u6c42\u65b9\u5f0f\uff1ahTable.get(getList); \u8bf7\u6c42\u6307\u5b9a\u9700\u8981\u7684\u5217\u65cf\u6216\u5217\uff1aaddColumn\u3001addFamily \u79bb\u7ebf\u6279\u91cf\u8bfb\u53d6\u7981\u6b62\u7f13\u5b58\uff1ascan.setBlockCache(false); Share \u00b6 Flink \u5f00\u53d1\u5b9e\u8df5 \u00b6 Reference \u00b6 HBase\u6700\u4f73\u5b9e\u8df5\uff0d\u8bfb\u6027\u80fd\u4f18\u5316\u7b56\u7565","title":"ARTS - 2019 Week 7-4"},{"location":"week/2019/0728/#arts-2019-week-7-4","text":"20190728~20190803","title":"ARTS - 2019 Week 7-4"},{"location":"week/2019/0728/#algorithm","text":"94. Binary Tree Inorder Traversal 144. Binary Tree Preorder Traversal 145. Binary Tree Postorder Traversal","title":"Algorithm"},{"location":"week/2019/0728/#review","text":"","title":"Review"},{"location":"week/2019/0728/#fast-and-reliable-apache-spark-sql-engine","text":"Building the next generation Spark SQL engine at speed poses new challenges to both automation and testing. At Databricks, we are implementing a new testing framework for assessing the quality and performance of new developments as they produced. Having more than 1,200 worldwide contributors, Apache Spark follows a rapid pace of development. At this scale, new testing tooling such as random query and data generation, fault injection, longevity stress, and scalability tests are essential to guarantee a reliable and performance Spark later in production. By applying such techniques, we will demonstrate the effectiveness of our testing infrastructure by drilling-down into cases where correctness and performance regressions have been found early. In addition, showing how they have been root-caused and fixed to prevent regressions in production and boosting the continuous delivery of new features. \u3010PDF\u3011Fast and Reliable Apache Spark SQL Engine \u76ee\u6807 making high quality releases automatic and frequent \u95ee\u9898 \u6bcf\u4e2a\u6708\u6570\u767e\u6b21\u63d0\u4ea4\uff0c\u9519\u8bef\u4e00\u5b9a\u4f1a\u53d1\u751f \u9700\u8981\u6295\u5165\u975e\u5e38\u5927\u7684\u7cbe\u529b\u8fdb\u884c\u6d4b\u8bd5\u5de5\u4f5c \u5355\u5143\u6d4b\u8bd5\u4e0d\u8db3\u4ee5\u4fdd\u8bc1\u6b63\u786e\u6027\u548c\u6027\u80fd \u65b9\u6848 \u6301\u7eed\u96c6\u6210 \u5206\u7c7b\u4e0e\u62a5\u8b66 \u6b63\u786e\u6027 \u751f\u6210\u968f\u673a\u67e5\u8be2 \u751f\u6210\u968f\u673a\u6570\u636e \u9012\u5f52\u67e5\u8be2\u6a21\u578b \u6982\u7387\u67e5\u8be2\u7c7b\u578b \u67e5\u8be2\u7b97\u5b50\u8986\u76d6\u7387\u5206\u6790 \u6027\u80fd \u57fa\u51c6\u6d4b\u8bd5\uff1a\u8d1f\u8f7d\u3001\u57fa\u51c6\u3001\u6027\u80fd \u6839\u6e90\u5206\u6790\uff1a\u706b\u7130\u56fe\uff08\u6162\u65b9\u6cd5\u3001\u65b0\u65b9\u6cd5\uff09 \u603b\u7ed3 \u81ea\u52a8\u5316\u5de5\u5177\u4fdd\u969c\u6b63\u786e\u6027\u4e0e\u6027\u80fd","title":"Fast and Reliable Apache Spark SQL Engine"},{"location":"week/2019/0728/#tip","text":"","title":"Tip"},{"location":"week/2019/0728/#hbase","text":"scan \u8bbe\u7f6e\u5408\u7406\u7684\u7f13\u5b58\uff1ascan.setCaching(1000); get \u4f7f\u7528\u6279\u91cf\u8bf7\u6c42\u65b9\u5f0f\uff1ahTable.get(getList); \u8bf7\u6c42\u6307\u5b9a\u9700\u8981\u7684\u5217\u65cf\u6216\u5217\uff1aaddColumn\u3001addFamily \u79bb\u7ebf\u6279\u91cf\u8bfb\u53d6\u7981\u6b62\u7f13\u5b58\uff1ascan.setBlockCache(false);","title":"HBase \u5ba2\u6237\u7aef\u4f18\u5316"},{"location":"week/2019/0728/#share","text":"","title":"Share"},{"location":"week/2019/0728/#flink","text":"","title":"Flink \u5f00\u53d1\u5b9e\u8df5"},{"location":"week/2019/0728/#reference","text":"HBase\u6700\u4f73\u5b9e\u8df5\uff0d\u8bfb\u6027\u80fd\u4f18\u5316\u7b56\u7565","title":"Reference"},{"location":"week/2019/0804/","text":"ARTS - 2019 Week 8-1 \u00b6 20190804~20190810 Algorithm \u00b6 100. Same Tree 101. Symmetric Tree Review \u00b6 How to Extend Apache Spark with Customized Optimizations \u00b6 There are a growing set of optimization mechanisms that allow you to achieve competitive SQL performance. Spark has extension points that help third parties to add customizations and optimizations without needing these optimizations to be merged into Apache Spark. This is very powerful and helps extensibility. We have added some enhancements to the existing extension points framework to enable some fine grained control. This talk will be a deep dive at the extension points that is available in Spark today. We will also talk about the enhancements to this API that we developed to help make this API more powerful. This talk will be of benefit to developers who are looking to customize Spark in their deployments. \u3010PDF\u3011How to Extend Apache Spark with Customized Optimizations \u6269\u5c55\u6848\u4f8b \u6027\u80fd\u4f18\u5316\uff1a\u53c2\u8003\u4fe1\u606f\u5b8c\u6574\u6027\u7684\u7ea6\u675f\u3001\u7d22\u5f15\u6765\u51cf\u5c11\u6570\u636e\u626b\u63cf\u8303\u56f4 \u6574\u5408\u7b2c\u4e09\u65b9\u5e94\u7528 \u95ee\u9898\u4e0e\u65b9\u6848 \u5982\u4f55\u5c06\u5b9a\u5236\u5f00\u53d1\u5e94\u7528\u5230\u96c6\u7fa4\uff1f \u5408\u5e76\u4ee3\u7801\u5230\u4e2d\u5fc3\u4ed3\u5e93 \u4fee\u6539\u4ee3\u7801\uff0c\u7ef4\u62a4\u81ea\u5df1\u5206\u652f \u4f7f\u7528\u6269\u5c55\u63a5\u53e3 \u6269\u5c55\u63a5\u53e3\uff08Extension Points API\uff09 Spark 2.2 in SPARK-18127\uff0cSPARK-26249: API Enhancements \u53ef\u63d2\u62d4\u3001\u53ef\u6269\u5c55 \u901a\u8fc7 SparkSessionExtensions\uff0c\u6269\u5c55 SparkSession SparkSessionExtensions \u901a\u8fc7\u94a9\u5b50\u673a\u5236\uff0c\u6ce8\u5165\u5b9a\u5236\u65b9\u6cd5 Spark SQL\uff1a\u89e3\u6790\u3001\u5206\u6790\u3001\u4f18\u5316\u3001\u7b56\u7565\u3001\u51fd\u6570 \u901a\u8fc7 withExtensions \u6216 spark.sql.extensions \u914d\u7f6e \u53c2\u8003 https://developer.ibm.com/code/2017/11/30/learn-extension-points-apache-spark-extend-spark-catalyst-optimizer/ https://rtahboub.github.io/blog/2018/writing-customized-parser/ Tip \u00b6 HBase Rowkey \u8bbe\u8ba1 \u00b6 \u8bbe\u8ba1\u539f\u5219 \u957f\u5ea6\u539f\u5219\uff1a\u63a7\u5236\u572816\u5b57\u8282 \u552f\u4e00\u539f\u5219 \u6392\u5e8f\u539f\u5219\uff1a\u6309\u7167ASCII\u6709\u5e8f\u6392\u5e8f \u6563\u5217\u539f\u5219\uff1a\u66f4\u5747\u5300\u7684\u5206\u5e03\u5728\u5404\u4e2a\u8282\u70b9 \u907f\u514d\u6570\u636e\u70ed\u70b9\u65b9\u6cd5 Reversing Salting Hashing Share \u00b6 \u5143\u6570\u636e\u96c6\u6210 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 8-1"},{"location":"week/2019/0804/#arts-2019-week-8-1","text":"20190804~20190810","title":"ARTS - 2019 Week 8-1"},{"location":"week/2019/0804/#algorithm","text":"100. Same Tree 101. Symmetric Tree","title":"Algorithm"},{"location":"week/2019/0804/#review","text":"","title":"Review"},{"location":"week/2019/0804/#how-to-extend-apache-spark-with-customized-optimizations","text":"There are a growing set of optimization mechanisms that allow you to achieve competitive SQL performance. Spark has extension points that help third parties to add customizations and optimizations without needing these optimizations to be merged into Apache Spark. This is very powerful and helps extensibility. We have added some enhancements to the existing extension points framework to enable some fine grained control. This talk will be a deep dive at the extension points that is available in Spark today. We will also talk about the enhancements to this API that we developed to help make this API more powerful. This talk will be of benefit to developers who are looking to customize Spark in their deployments. \u3010PDF\u3011How to Extend Apache Spark with Customized Optimizations \u6269\u5c55\u6848\u4f8b \u6027\u80fd\u4f18\u5316\uff1a\u53c2\u8003\u4fe1\u606f\u5b8c\u6574\u6027\u7684\u7ea6\u675f\u3001\u7d22\u5f15\u6765\u51cf\u5c11\u6570\u636e\u626b\u63cf\u8303\u56f4 \u6574\u5408\u7b2c\u4e09\u65b9\u5e94\u7528 \u95ee\u9898\u4e0e\u65b9\u6848 \u5982\u4f55\u5c06\u5b9a\u5236\u5f00\u53d1\u5e94\u7528\u5230\u96c6\u7fa4\uff1f \u5408\u5e76\u4ee3\u7801\u5230\u4e2d\u5fc3\u4ed3\u5e93 \u4fee\u6539\u4ee3\u7801\uff0c\u7ef4\u62a4\u81ea\u5df1\u5206\u652f \u4f7f\u7528\u6269\u5c55\u63a5\u53e3 \u6269\u5c55\u63a5\u53e3\uff08Extension Points API\uff09 Spark 2.2 in SPARK-18127\uff0cSPARK-26249: API Enhancements \u53ef\u63d2\u62d4\u3001\u53ef\u6269\u5c55 \u901a\u8fc7 SparkSessionExtensions\uff0c\u6269\u5c55 SparkSession SparkSessionExtensions \u901a\u8fc7\u94a9\u5b50\u673a\u5236\uff0c\u6ce8\u5165\u5b9a\u5236\u65b9\u6cd5 Spark SQL\uff1a\u89e3\u6790\u3001\u5206\u6790\u3001\u4f18\u5316\u3001\u7b56\u7565\u3001\u51fd\u6570 \u901a\u8fc7 withExtensions \u6216 spark.sql.extensions \u914d\u7f6e \u53c2\u8003 https://developer.ibm.com/code/2017/11/30/learn-extension-points-apache-spark-extend-spark-catalyst-optimizer/ https://rtahboub.github.io/blog/2018/writing-customized-parser/","title":"How to Extend Apache Spark with Customized Optimizations"},{"location":"week/2019/0804/#tip","text":"","title":"Tip"},{"location":"week/2019/0804/#hbase-rowkey","text":"\u8bbe\u8ba1\u539f\u5219 \u957f\u5ea6\u539f\u5219\uff1a\u63a7\u5236\u572816\u5b57\u8282 \u552f\u4e00\u539f\u5219 \u6392\u5e8f\u539f\u5219\uff1a\u6309\u7167ASCII\u6709\u5e8f\u6392\u5e8f \u6563\u5217\u539f\u5219\uff1a\u66f4\u5747\u5300\u7684\u5206\u5e03\u5728\u5404\u4e2a\u8282\u70b9 \u907f\u514d\u6570\u636e\u70ed\u70b9\u65b9\u6cd5 Reversing Salting Hashing","title":"HBase Rowkey \u8bbe\u8ba1"},{"location":"week/2019/0804/#share","text":"","title":"Share"},{"location":"week/2019/0804/#_1","text":"","title":"\u5143\u6570\u636e\u96c6\u6210"},{"location":"week/2019/0804/#reference","text":"","title":"Reference"},{"location":"week/2019/0811/","text":"ARTS - 2019 Week 8-2 \u00b6 20190811~20190817 Algorithm \u00b6 104. Maximum Depth of Binary Tree Review \u00b6 Smart Join Algorithms for Fighting Skew at Scale \u00b6 Consumer apps like Yelp generate log data at huge scale, and often this is distributed according to a power law, where a small number of users, businesses, locations, or pages are associated with a disproportionately large amount of data. This kind of data skew can cause problems for distributed algorithms, especially joins, where all the rows with the same key must be processed by the same executor. Even just a single over-represented entity can cause a whole job to slow down or fail. One approach to this problem is to remove outliers before joining, and this might be fine when training a machine learning model, but sometimes you need to retain all the data. Thankfully, there are a few tricks you can use to counteract the negative effects of skew while joining, by artificially redistributing data across more machines. This talk will walk through some of them, with code examples. \u3010PDF\u3011Smart Join Algorithms for Fighting Skew at Scale \u6570\u636e\u503e\u659c \u6570\u636e\u5206\u5e03 \u6b63\u592a\u5206\u5e03 \u5e42\u5f8b\u5206\u5e03 \u5f02\u5e38\u503c \u4ea7\u751f\u95ee\u9898 \u901a\u8fc7\u5206\u4f4d\u6570\u8bca\u65ad\uff1a\u6267\u884c\u65f6\u95f4\u3001\u6570\u636e\u5927\u5c0f\u3001\u6570\u636e\u91cf\u3001spill\u3001gc \u70ed\u70b9\u5206\u7247\u3001\u8bfb\u5199 \u6570\u636e\u52a0\u8f7d Join Shuffle Spark Joins Shuffled hash join Broadcast join \u89e3\u51b3\u65b9\u6848 \u503e\u659c\u6570\u636e key \u589e\u52a0\u968f\u673a\u56e0\u5b50\uff0c\u5173\u8054\u6570\u636e\u6269\u5f20\u5bf9\u5e94\u500d\u6570 \u6539\u8fdb\uff1a\u53ea\u5904\u7406\u9891\u7e41\u9879\u5bf9\u5e94\u7684 key \u81ea\u52a8\u65b9\u6848 \u9884\u4f30\u9891\u7e41\u9879\uff0c\u81ea\u52a8\u8c03\u6574\u6269\u5f20\u6bd4\u4f8b \u4e24\u8fb9\u90fd\u503e\u659c\uff0c\u5206\u522b\u751f\u6210\u968f\u673a key \u548c\u6269\u5f20 key Tip \u00b6 Redis \u6570\u636e\u7c7b\u578b \u00b6 STRING \u5b57\u7b26\u4e32\u3001\u6574\u6570\u3001\u6d6e\u70b9\u6570 GET\u3001SET\u3001DEL LIST \u94fe\u8868 RPUSH\u3001LRANGE\u3001LINDEX\u3001LPOP SET \u65e0\u5e8f\u65e0\u91cd\u590d\u96c6\u5408 SADD\u3001SMEMBERS\u3001SISMEMBER\u3001SREM HASH \u65e0\u5e8f\u6563\u5217\u8868 HSET\u3001HGET\u3001HGETALL\u3001HDEL ZSET \u6709\u5e8f\u65e0\u91cd\u590d\u96c6\u5408 ZADD\u3001ZRANGE\u3001ZRANGEBYSCORE\u3001ZREM Shadowsocks \u52a0\u901f Github \u00b6 \u914d\u7f6e\u4ee3\u7406 # Windows git config --global http.proxy 'socks5://127.0.0.1:1080' git config --global https.proxy 'socks5://127.0.0.1:1080' # MacOS git config --global http.proxy 'socks5://127.0.0.1:1086' git config --global https.proxy 'socks5://127.0.0.1:1086' \u53d6\u6d88\u4ee3\u7406 git config --global --unset http.proxy git config --global --unset https.proxy Share \u00b6 \u5143\u6570\u636e\u4ed3\u5e93 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 8-2"},{"location":"week/2019/0811/#arts-2019-week-8-2","text":"20190811~20190817","title":"ARTS - 2019 Week 8-2"},{"location":"week/2019/0811/#algorithm","text":"104. Maximum Depth of Binary Tree","title":"Algorithm"},{"location":"week/2019/0811/#review","text":"","title":"Review"},{"location":"week/2019/0811/#smart-join-algorithms-for-fighting-skew-at-scale","text":"Consumer apps like Yelp generate log data at huge scale, and often this is distributed according to a power law, where a small number of users, businesses, locations, or pages are associated with a disproportionately large amount of data. This kind of data skew can cause problems for distributed algorithms, especially joins, where all the rows with the same key must be processed by the same executor. Even just a single over-represented entity can cause a whole job to slow down or fail. One approach to this problem is to remove outliers before joining, and this might be fine when training a machine learning model, but sometimes you need to retain all the data. Thankfully, there are a few tricks you can use to counteract the negative effects of skew while joining, by artificially redistributing data across more machines. This talk will walk through some of them, with code examples. \u3010PDF\u3011Smart Join Algorithms for Fighting Skew at Scale \u6570\u636e\u503e\u659c \u6570\u636e\u5206\u5e03 \u6b63\u592a\u5206\u5e03 \u5e42\u5f8b\u5206\u5e03 \u5f02\u5e38\u503c \u4ea7\u751f\u95ee\u9898 \u901a\u8fc7\u5206\u4f4d\u6570\u8bca\u65ad\uff1a\u6267\u884c\u65f6\u95f4\u3001\u6570\u636e\u5927\u5c0f\u3001\u6570\u636e\u91cf\u3001spill\u3001gc \u70ed\u70b9\u5206\u7247\u3001\u8bfb\u5199 \u6570\u636e\u52a0\u8f7d Join Shuffle Spark Joins Shuffled hash join Broadcast join \u89e3\u51b3\u65b9\u6848 \u503e\u659c\u6570\u636e key \u589e\u52a0\u968f\u673a\u56e0\u5b50\uff0c\u5173\u8054\u6570\u636e\u6269\u5f20\u5bf9\u5e94\u500d\u6570 \u6539\u8fdb\uff1a\u53ea\u5904\u7406\u9891\u7e41\u9879\u5bf9\u5e94\u7684 key \u81ea\u52a8\u65b9\u6848 \u9884\u4f30\u9891\u7e41\u9879\uff0c\u81ea\u52a8\u8c03\u6574\u6269\u5f20\u6bd4\u4f8b \u4e24\u8fb9\u90fd\u503e\u659c\uff0c\u5206\u522b\u751f\u6210\u968f\u673a key \u548c\u6269\u5f20 key","title":"Smart Join Algorithms for Fighting Skew at Scale"},{"location":"week/2019/0811/#tip","text":"","title":"Tip"},{"location":"week/2019/0811/#redis","text":"STRING \u5b57\u7b26\u4e32\u3001\u6574\u6570\u3001\u6d6e\u70b9\u6570 GET\u3001SET\u3001DEL LIST \u94fe\u8868 RPUSH\u3001LRANGE\u3001LINDEX\u3001LPOP SET \u65e0\u5e8f\u65e0\u91cd\u590d\u96c6\u5408 SADD\u3001SMEMBERS\u3001SISMEMBER\u3001SREM HASH \u65e0\u5e8f\u6563\u5217\u8868 HSET\u3001HGET\u3001HGETALL\u3001HDEL ZSET \u6709\u5e8f\u65e0\u91cd\u590d\u96c6\u5408 ZADD\u3001ZRANGE\u3001ZRANGEBYSCORE\u3001ZREM","title":"Redis \u6570\u636e\u7c7b\u578b"},{"location":"week/2019/0811/#shadowsocks-github","text":"\u914d\u7f6e\u4ee3\u7406 # Windows git config --global http.proxy 'socks5://127.0.0.1:1080' git config --global https.proxy 'socks5://127.0.0.1:1080' # MacOS git config --global http.proxy 'socks5://127.0.0.1:1086' git config --global https.proxy 'socks5://127.0.0.1:1086' \u53d6\u6d88\u4ee3\u7406 git config --global --unset http.proxy git config --global --unset https.proxy","title":"Shadowsocks \u52a0\u901f Github"},{"location":"week/2019/0811/#share","text":"","title":"Share"},{"location":"week/2019/0811/#_1","text":"","title":"\u5143\u6570\u636e\u4ed3\u5e93"},{"location":"week/2019/0811/#reference","text":"","title":"Reference"},{"location":"week/2019/0818/","text":"ARTS - 2019 Week 8-3 \u00b6 20190818~20190824 Algorithm \u00b6 107. Binary Tree Level Order Traversal II Review \u00b6 Deep Dive Scheduler in Apache Spark \u00b6 As a core component of data processing platform, scheduler is responsible for schedule tasks on compute units. Built on a Directed Acyclic Graph (DAG) compute model, Spark Scheduler works together with Block Manager and Cluster Backend to efficiently utilize cluster resources for high performance of various workloads. This talk dives into the technical details of the full lifecycle of a typical Spark workload to be scheduled and executed, and also discusses how to tune Spark scheduler for better performance. \u3010PDF\u3011Deep Dive Scheduler in Apache Spark SparkContext \u00b6 \u4e3b\u7a0b\u5e8f\u5165\u53e3\u3001\u63d0\u4ea4/\u53d6\u6d88\u4f5c\u4e1a SchedulerBackend\uff08CoarseGrainedSchedulerBackend\u3001LocalSchedulerBackend\uff09\u3001DAGScheduler\u3001TaskScheduler Scheduling Process \u00b6 RDD\u3001DAGScheduler\u3001TaskScheduler\u3001Worker RDD\u3001Stage\u3001TaskSet DAGScheduler \u00b6 RDD -> Stage Stage -> TaskSet TaskScheduler \u00b6 Batch\u3001Barrier FIFO\u3001Fair TaskSetManager \u00b6 locality-aware = delay Handle Failures \u00b6 Task\uff1amaxTaskFailures Stage\uff1amaxStageFailures SchedulerBackend \u00b6 \u7ba1\u7406\u8c03\u5ea6\u8d44\u6e90 Worker \u00b6 ExternalShuffleService Improve Job Performance \u00b6 Break long-running tasks into simple/short tasks Broadcast small hot input files Tip \u00b6 Yarn Scheduler \u00b6 FIFO \u5148\u8fdb\u5148\u51fa\u961f\u5217 \u96c6\u7fa4\u8d44\u6e90\u4e0d\u5171\u4eab Capacity \u901a\u8fc7\u5f39\u6027\u5c42\u6b21\u961f\u5217\u7ec4\u7ec7\u8d44\u6e90 \u961f\u5217\u5185\u90e8\u4f5c\u4e1a\u91c7\u7528\u5148\u8fdb\u5148\u51fa Fair \u901a\u8fc7\u5f39\u6027\u5c42\u6b21\u961f\u5217\u7ec4\u7ec7\u8d44\u6e90 \u652f\u6301\u4e0d\u540c\u8d44\u6e90\u8c03\u5ea6\u7b97\u6cd5 \u652f\u6301\u62a2\u5360\u8c03\u5ea6\uff1a\u7b49\u5f85\u65f6\u95f4\uff0c\u8d44\u6e90 \u53c2\u8003 YARN\u8c03\u5ea6\u7b56\u7565\u6bd4\u8f83 Capacity Scheduler - vs - Fair Scheduler Share \u00b6 \u65e5\u5fd7\u91c7\u96c6 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 8-3"},{"location":"week/2019/0818/#arts-2019-week-8-3","text":"20190818~20190824","title":"ARTS - 2019 Week 8-3"},{"location":"week/2019/0818/#algorithm","text":"107. Binary Tree Level Order Traversal II","title":"Algorithm"},{"location":"week/2019/0818/#review","text":"","title":"Review"},{"location":"week/2019/0818/#deep-dive-scheduler-in-apache-spark","text":"As a core component of data processing platform, scheduler is responsible for schedule tasks on compute units. Built on a Directed Acyclic Graph (DAG) compute model, Spark Scheduler works together with Block Manager and Cluster Backend to efficiently utilize cluster resources for high performance of various workloads. This talk dives into the technical details of the full lifecycle of a typical Spark workload to be scheduled and executed, and also discusses how to tune Spark scheduler for better performance. \u3010PDF\u3011Deep Dive Scheduler in Apache Spark","title":"Deep Dive Scheduler in Apache Spark"},{"location":"week/2019/0818/#sparkcontext","text":"\u4e3b\u7a0b\u5e8f\u5165\u53e3\u3001\u63d0\u4ea4/\u53d6\u6d88\u4f5c\u4e1a SchedulerBackend\uff08CoarseGrainedSchedulerBackend\u3001LocalSchedulerBackend\uff09\u3001DAGScheduler\u3001TaskScheduler","title":"SparkContext"},{"location":"week/2019/0818/#scheduling-process","text":"RDD\u3001DAGScheduler\u3001TaskScheduler\u3001Worker RDD\u3001Stage\u3001TaskSet","title":"Scheduling Process"},{"location":"week/2019/0818/#dagscheduler","text":"RDD -> Stage Stage -> TaskSet","title":"DAGScheduler"},{"location":"week/2019/0818/#taskscheduler","text":"Batch\u3001Barrier FIFO\u3001Fair","title":"TaskScheduler"},{"location":"week/2019/0818/#tasksetmanager","text":"locality-aware = delay","title":"TaskSetManager"},{"location":"week/2019/0818/#handle-failures","text":"Task\uff1amaxTaskFailures Stage\uff1amaxStageFailures","title":"Handle Failures"},{"location":"week/2019/0818/#schedulerbackend","text":"\u7ba1\u7406\u8c03\u5ea6\u8d44\u6e90","title":"SchedulerBackend"},{"location":"week/2019/0818/#worker","text":"ExternalShuffleService","title":"Worker"},{"location":"week/2019/0818/#improve-job-performance","text":"Break long-running tasks into simple/short tasks Broadcast small hot input files","title":"Improve Job Performance"},{"location":"week/2019/0818/#tip","text":"","title":"Tip"},{"location":"week/2019/0818/#yarn-scheduler","text":"FIFO \u5148\u8fdb\u5148\u51fa\u961f\u5217 \u96c6\u7fa4\u8d44\u6e90\u4e0d\u5171\u4eab Capacity \u901a\u8fc7\u5f39\u6027\u5c42\u6b21\u961f\u5217\u7ec4\u7ec7\u8d44\u6e90 \u961f\u5217\u5185\u90e8\u4f5c\u4e1a\u91c7\u7528\u5148\u8fdb\u5148\u51fa Fair \u901a\u8fc7\u5f39\u6027\u5c42\u6b21\u961f\u5217\u7ec4\u7ec7\u8d44\u6e90 \u652f\u6301\u4e0d\u540c\u8d44\u6e90\u8c03\u5ea6\u7b97\u6cd5 \u652f\u6301\u62a2\u5360\u8c03\u5ea6\uff1a\u7b49\u5f85\u65f6\u95f4\uff0c\u8d44\u6e90 \u53c2\u8003 YARN\u8c03\u5ea6\u7b56\u7565\u6bd4\u8f83 Capacity Scheduler - vs - Fair Scheduler","title":"Yarn Scheduler"},{"location":"week/2019/0818/#share","text":"","title":"Share"},{"location":"week/2019/0818/#_1","text":"","title":"\u65e5\u5fd7\u91c7\u96c6"},{"location":"week/2019/0818/#reference","text":"","title":"Reference"},{"location":"week/2019/0825/","text":"ARTS - 2019 Week 8-4 \u00b6 20190825~20190831 Algorithm \u00b6 108. Convert Sorted Array to Binary Search Tree Review \u00b6 Tip \u00b6 Kafka \u00b6 Share \u00b6 \u6570\u636e\u96c6\u6210 \u00b6 Reference \u00b6","title":"ARTS - 2019 Week 8-4"},{"location":"week/2019/0825/#arts-2019-week-8-4","text":"20190825~20190831","title":"ARTS - 2019 Week 8-4"},{"location":"week/2019/0825/#algorithm","text":"108. Convert Sorted Array to Binary Search Tree","title":"Algorithm"},{"location":"week/2019/0825/#review","text":"","title":"Review"},{"location":"week/2019/0825/#tip","text":"","title":"Tip"},{"location":"week/2019/0825/#kafka","text":"","title":"Kafka"},{"location":"week/2019/0825/#share","text":"","title":"Share"},{"location":"week/2019/0825/#_1","text":"","title":"\u6570\u636e\u96c6\u6210"},{"location":"week/2019/0825/#reference","text":"","title":"Reference"},{"location":"week/2019/0901/","text":"","title":"0901"},{"location":"week/2019/0908/","text":"","title":"0908"},{"location":"week/2019/0915/","text":"","title":"0915"},{"location":"week/2019/0922/","text":"","title":"0922"},{"location":"week/2019/0929/","text":"","title":"0929"}]}